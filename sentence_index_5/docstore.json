{"docstore/metadata": {"23a01a5c-17be-4dd1-b7b5-6b15967f05f1": {"doc_hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3"}, "fbf1ada9-b5fa-4bdb-9909-137b8f28e1e8": {"doc_hash": "5e1823792e4ab2cf160fab242d13769fe8de66833b09aad83979e3168b919ab9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1c6c1b0f-c818-44af-a4d5-6797baed1e72": {"doc_hash": "a9ec6141d40a4e2f35928ba4044abb0d29c3384bef8612c95082e28331fec340", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d69b7e17-ac48-40dd-8d20-6b2425044f2c": {"doc_hash": "8e33deb0d805b4eee03b1e3fa8dd3465ad5276ceb1a91db57752b059b12d1520", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "73cc978a-73e4-4fd9-96a5-cef57959dc0e": {"doc_hash": "a5f30bd904b0f38ee53318bf75ed642e4b2bae91f30502961e9ffa1785862efe", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "46176f33-de2a-41e4-9b60-ab672142c89e": {"doc_hash": "f7844a41d9051ea7701979f5d148ecfa6a039f54e3794e4a4af94afeac02dea7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "48ddae5c-ce38-4210-9ce0-2dce0b585376": {"doc_hash": "e964bf187f8d4d7f2c848e537a9cf3fbbc7e785fd9f2344d67a7426f8b076a29", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "14182cd4-0589-4368-83ab-3cc5841caec0": {"doc_hash": "ff3f2ce1766d6dda49efb44719a5a66a7957454ad50b1445838547cd97f69686", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "77fafd39-1cfc-4f58-9e2f-b84f19e2d8bb": {"doc_hash": "ccd6fdf26660523d98dc8bf95f2edf10e6ee2b2b0a53ebfe98fd571677a0be3d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d39027f7-8f6c-4991-a104-f6cde2aa6d58": {"doc_hash": "28b02882a2ff5d1a9f2de0f9acde8ae0656a592b1ffc3653394d6c3c280837af", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "89d47952-5df5-4ca4-bd99-eb2669de5e21": {"doc_hash": "53e47e9684ff26192f1efb450cf1d0f03a83c178e57ed782122a9fde67488ca1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ba08fbda-b05f-4fb2-b051-bb8c5d9f2852": {"doc_hash": "f154e982a3fa0d0a48f20ca39228d8e8442edf9665e363a8d148a13891e57f86", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1557720e-3684-46ef-95bc-79b8c00fa8f8": {"doc_hash": "60b2342b24e8c84d7461dc9561013e683628686822598142acd51a95eaf84ca5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "330d0e94-f923-454f-b8c2-a90fa48b7baa": {"doc_hash": "f5e2da2431d671ca57ba58192c0ea1c5f46269b89d3420b6989d133c1f64b7a0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fadb5d61-d36b-4138-8d0c-b74c519348a3": {"doc_hash": "1ab7c6f339dc6422975efe20fbf4cf2b75b35d77c7dd462a252313c09966c65f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2782c7d2-28f4-4105-9e7f-402ac34a8a86": {"doc_hash": "d9170f93d8c5573d278cafeddbf8944dfddb11e1824eedebbc2364b70c62ff48", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d5198ce1-8410-4ae9-a311-38bc88e6b051": {"doc_hash": "d4374fd591580adb7a75eb46dd1eb7a7d9a4950599c7e28633eef196a19f22f3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ba2a2850-00ac-441c-be3a-85307791c162": {"doc_hash": "0b7b9ee04a180777584687b2b2fa33effecf3acd1c288ce8f15a2c3edec6f8ee", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6b1e2466-31cd-4660-bbee-f4edf97f3af8": {"doc_hash": "df2ab770302b0fc9121f354e449d4194eab82c039421431040001c193536bede", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "371c53f3-de43-44bc-8eda-c6807ef8d67f": {"doc_hash": "26dda9eff788d0a2a899235f7d13678107c170a34815391f634f38581c8f8303", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ce37c297-3fff-4105-a18c-ee23461555db": {"doc_hash": "8ed3766843245efd58680a5e5082eb3862bc1a3ffd788c757bbb3e9c38e1bcc7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ba392562-f719-4af7-9fd1-947511931409": {"doc_hash": "42f73e03aa3563215c227545fe21a611cd2af3913214104008f1447370461947", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "df08fe46-57de-48e2-9ee6-b2e751bc026d": {"doc_hash": "2a049156ee4c75d5742914245b6d15d6f350d23bbca22a005468f7d2a7f17391", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "aa537df5-57c0-4812-848d-d7aedc9ae24d": {"doc_hash": "00e53856eb6271873b8bf5e19d3b024b7bba6a344578bab150d90a203e5cb1e2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "12383c91-984d-4be1-96aa-23db2c0b63d7": {"doc_hash": "e027a852e0d1daba5004ab6c15360ac01ec0825b37b54f6d0c8b395b0d0e33b3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fb639edb-9f25-4fa5-b57a-80ebeb15d389": {"doc_hash": "97ae6c98e432491a7987be2264b4442137a6ba0754955934aa2149750270228e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4ae70e01-90d5-4f4e-9e42-e0bc6a26cc42": {"doc_hash": "4d1259926078c84dab52d246976ce82cc0b1e710ce32ce0ce6688bc792b41d1e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d76a60ad-edc0-41f3-b74a-1c88f10046c9": {"doc_hash": "d94db416bacca523b69bb0b37f68a4ed9631e2ad7c349f6c9f2f48a2a51123c7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f5b2e791-1e16-4086-8897-386995a6082a": {"doc_hash": "cb647343f90c78d935658ec4f7465c3ef641e2a6f0a14fd966820dd838a56f36", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a827aa0e-397f-4b0b-bb14-7358b7193722": {"doc_hash": "1300384dbd351e11fc3d4040d7aa628e47dca4b64a4b583d048a74e92a1ee969", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "acb27c0f-39c3-48d6-9539-e59ef42a900a": {"doc_hash": "8cf1f5463adc06d1bf54b4c74386f5eea2eee9990d184ab4b5f7980d2c1c3f65", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bb39c138-c38b-482e-aca8-5558676ba6bd": {"doc_hash": "1f3c3190f08a53c5be5c5f12465c76c2f6a15e756e7d84ac64796e5ba265e6a5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "14892dd0-f5bd-45c9-b3d9-cab15f14fa81": {"doc_hash": "7fa8542fcb0e2f6e3c2c1642a72e3f4be540f421c5fbd1300a9632f670196634", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1a66548c-d067-4aa0-8c6f-51ced06f0931": {"doc_hash": "fc998577260c0cf2356dbfcecaa6e2c76dbf597cb99f447af72e8fe428118eae", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9112c04e-f1c3-4c7a-8279-cf7cc673c07c": {"doc_hash": "fe36880e9df284fa93f1631a42983ecad63349544c586b1f5c8c0844f11585af", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "de25c6d7-3445-4cee-a313-b679a0d47fb0": {"doc_hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2f5baa1d-e9d3-4152-8ffe-617d077e37ff": {"doc_hash": "4baed37683e2cd5af3fe16e5d3bf9cbb53d6fdc4881e9e84ce3e0f9e73bde22b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4ac92cf2-7fbc-4679-87dc-76c58bef1f5f": {"doc_hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "58ad6948-5d3c-410c-aafd-2c7e005318d9": {"doc_hash": "36990fc3775d06ffc09bffea98865a6ce85b76a7540949d617eb87525e90d09c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "81ad316d-3411-426f-8fdf-6500d6554154": {"doc_hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "409dae7a-87be-4b54-a369-ee20fe75fa0b": {"doc_hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9d48d5a6-2c27-4674-bb4e-7e0374c78464": {"doc_hash": "7d109ff8a007c1d0f1b16a3e7f24a7ccd1e9bb1b864caeb9d0865aea1bbd930d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ece3f660-e1ee-4a0a-83a9-c9b04d373199": {"doc_hash": "6c2e4690ea2134ea76f2004e5a7d0054df8cfa729cb5d003bdbe0e9a2bb63d0e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7cdbe830-9cb7-4927-ad86-f37dd824a1ca": {"doc_hash": "c2b5b1c43b5cc3506bfcae3f5291ca3dca63489e4dc8187ffb2199dd2465e1ea", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "edb3cb5e-dac4-4bf9-9dc2-155adecfa763": {"doc_hash": "1bad1725ebc0a1b4d941c02da57ae65d2238e0930a92e59135ab5cb8e453c93e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d0e25a07-9982-43a7-bd8b-4ea383cfe81c": {"doc_hash": "8b2274bf1434009c295b7eaa4738a80679607dc493b8570447ceb09915ac289d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3ec785d2-72ea-41d1-ae3e-868873270333": {"doc_hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a8789715-3a48-4d70-a63f-ce61b96ecdfe": {"doc_hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "69d5a32f-7274-475e-b79c-f1ff184be0a9": {"doc_hash": "02650eb046ba7a259fbc1bce19271b32aabba7aef914579d935aa8838edcccbe", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "abc0e169-74ac-4aab-87c2-7f167b8e054b": {"doc_hash": "3775a6a845ef72358b94ad618175e281f6e71aff15460a96ff4fca75c2b9a14f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c63e20e3-7c3b-453a-9013-864088b107f0": {"doc_hash": "983cab6a97550570e68a2499d81934f4d690189e90704cc28829bfeedd851155", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "08fc9c23-e41d-4fa0-af6a-28126471dc0f": {"doc_hash": "7c797806c4942896b3717953102d61326a085954b8818c0dc2c4635684b066b2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1bab64b2-0091-4922-83a9-85b37582bdc8": {"doc_hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1245df91-a0f3-45be-833b-e3870540e8ae": {"doc_hash": "2c9b0516746043c3938a801c3325f911192eadb56eb546b5643d4e979097081e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "05784733-673b-4a76-931a-f45479a49ba7": {"doc_hash": "630ffcc3ca949495326d36f1a0991d6b10838cd454e5a71f7db5d756b5410258", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "eeeae031-8f68-4318-bbdf-a0cedf24db28": {"doc_hash": "de523ec9b875e975a9cc978f6e98c5ae9846f0d6d35d0d9d238bf22c627c31b6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bd2b0e5a-5b68-4817-91c2-b83c066837df": {"doc_hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ecb917f1-9ae9-43dc-a978-5729d54d0fde": {"doc_hash": "a554f212fee44bdcc4100f5d194a8c0b988d3055e58893cc5a49a291f8c108fc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d2a1ab1e-6d3c-47b8-9793-66d5a43413cb": {"doc_hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "852f5349-fc66-4037-a43b-82fb37900f1c": {"doc_hash": "35d91844bac536866f90c23204f831ee099d7cf31d90c2b8cef29a4262f9a09a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cfa56a96-82a1-4352-8e7f-653e80cb2bd0": {"doc_hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a2b8191f-e78f-424e-aee2-a9205c05d40e": {"doc_hash": "31f6f982c7f3bac1ce485efa6d885edc8b483c9a8d0bacf3543b2319f6e74c29", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b5423250-608d-4fd0-a28b-dafe99e23a4b": {"doc_hash": "3705ad1d727462bc70cf098a9e22d44a826fe907d8bf2102784bd6c59008dba6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5521157b-1012-470a-bd03-83849e265f18": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "079b3d1e-6872-480f-b4c3-25173d15daf8": {"doc_hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "29614fb0-02ae-4f51-b53e-dd7291a02e19": {"doc_hash": "45b080814d27b340780db197c311010500338864bdbab7ad5568297ae30e618c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "be4cb9e8-ac61-4e76-a136-68b99fb9aa59": {"doc_hash": "780f567470ac616c15302be2f99fbaafa87309706c13c265693f74cbc29054b5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "64d207b4-6214-45a0-bd3d-4ff7f9a949bd": {"doc_hash": "f49c991c0949d74ddebd63f19a518d31d1b6715adac342b07a9aaa1e0a879aec", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bc00279f-14a2-4f02-b314-0cadfa05ab92": {"doc_hash": "37b98f57f7e4dd825302a412a9821346c3e5ae08dd86110f5add1c94eb58b169", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "739917e5-73d7-447d-913b-b8ec8e81f009": {"doc_hash": "be381e4e6386c5bb8077717dd1346571766ee6fffca7997dd28fca9fdc4c43ab", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "97a957d6-d9da-45fd-bdba-d4c6155bdc60": {"doc_hash": "9a26111bcd8d1b9f67b7dd6d552f3e095a2bde338c34882fcc17dfe636cffe4a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a12dec1e-86bf-427f-9ee1-f5d811d912d2": {"doc_hash": "f4fd6ad79e18f60585d7b4f3d86e4284ecca21e095bb94682e802630bd3d586e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b3a99b78-b28e-4a45-b364-9ba95ec3e816": {"doc_hash": "d3272aa4d4cd9eb1f6843078bcae74e7750f9c88a3e55e36c1f003184880a22c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f1ebacbc-defd-4059-8c27-02a46f9ba11c": {"doc_hash": "b7d9f9db28f723c5bc5d6343025ce7db7a77c57e98d5eae3cbd5e287c8ae1d80", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a69f557f-853f-4953-a46a-deb1f7ff7726": {"doc_hash": "b8a589b1b3fa8733b7fdc5825875f3037e97ce31afe4f9e594be851168943875", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3f7e73a5-69b8-45b6-9239-a576b1bc6acb": {"doc_hash": "6cffd8ea99595be0d571b88525149eeabff1b1ddc98e592ff16e190f44be85f9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c81b6ab2-bc6f-47f7-8da6-487fa4cc1f52": {"doc_hash": "8055f9b7b432ab35893453b8c1fe6cefbe5f77a30e16a706b25f8ef01c340307", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "806fbdf1-0dc1-438a-bcf6-1613e6d7fe0e": {"doc_hash": "35f4c9e6686ae001e9cae48115f4f8f63be807b9d26cac5d1734c64e9d878e3c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "97ce680d-4b8a-4e46-838a-d857b8f3bbbe": {"doc_hash": "6252ab60c1ee7c01c29789def485861dc2e76a96605fc3bd381fa016ff267665", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d16acc9f-ef1f-451d-8cf0-e3dfb7bff45a": {"doc_hash": "19f49b496dc527d32930be659cb290e06c7c93061acf89306b4be1e32f9a8ce9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "28fed53b-6ee5-48ed-9cb4-a978cfbe7434": {"doc_hash": "149867184a95a552e3ce0d684fe4641eead75a707083bc5a71bebe73a9a6be30", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1fce667c-c143-4167-9886-3eb9b8cafb5d": {"doc_hash": "c660f148e86674141400b92ed8df9a294cafdc5c3a5ca4578d06a640dbf19848", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b4ed09af-1b81-47df-9d6d-d6640b666d78": {"doc_hash": "8992c19fa63308504f0e733894d830a8b08587c725f98c74732dd221c1b6f752", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "832089fb-ae76-4182-a389-a539669d8a8f": {"doc_hash": "a55d68af6247dd1b8ca69c59164225d4d40076980662e704a0f5707f48dffa5f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b0caad91-0adb-486b-8ac0-f6469d776d70": {"doc_hash": "373ac7250623cff283358639230c04276e97010e1383a32d434935fbf5475d4b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "15f3b207-bdb8-4a58-881a-22f28a8067da": {"doc_hash": "e7a8bbcebd4aad54e220e9cd189c8e3a99cde582c46b384dd07d4a1568ebbe06", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8c355ac2-e588-47e1-a35c-c4887640db32": {"doc_hash": "e166475c2d1537d30733f2344bbe827a256dfd3ba2c36876c2476d7f9c66a3fe", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6d9bf82f-2a03-4ac5-b256-bdc87a16db79": {"doc_hash": "e322d679aeccdf6b29d7a794be69de681b301a37531fe620f8664312e4074fcf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "67e7e0f1-5c4c-4f35-ad12-a0eb46264e49": {"doc_hash": "e124307d98d1f8cb615b9056b96484d321e7b4f1fa1e3a50d70bffb24bebda42", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ba529973-7093-4808-87ea-aa839f96716f": {"doc_hash": "2632da7484eafccd12db97c204731bfd76fc0050c9155ca0dda48f823dbb25a4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ac19a687-8daa-4832-9534-85587ef13d60": {"doc_hash": "aa38b67014b129f5414485a3aeb6d173bf064b197ca42059afe2a36a42c6d62f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "905a0c4f-785c-4642-8b4c-26aac4624f1e": {"doc_hash": "ed644052d0431fd578736dd16044366769260dea5de2a58640c126a1b9adf1de", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b79cd5dd-16d7-4d58-8e08-285d3d96c41f": {"doc_hash": "fb396cec1c03f8d33bdeee48eeda94a9fd311f974515f3b9c5c251a8e7690a1a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6a6f92a5-e827-40c4-a6b1-88a1e4e36cda": {"doc_hash": "792ba69dbd6f1df7f307167a44188bb8f267a6c4c12da97cc1bdfc3c48c157ff", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "50c8e165-a00a-4d10-b21f-8787dcfcf71d": {"doc_hash": "478fdbdba95a0648eab979831a1c7f8ec6bfed36756a482f11679ffb4b4024df", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7e472862-192e-4b42-ac12-fa06aa0f55d0": {"doc_hash": "b2d0f1cc4805120dfdd11cd33573ef685dd06aa3a98e3e36e2fa4d54c9176d8e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "468274fc-2062-4428-b75e-ea271626ca50": {"doc_hash": "e48a0a686cc5fda81a5884e05c9a0d847b2ba0bd870c462bd253a2d5918cfcd7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c815abe7-aa83-459d-a855-7c6d3146aa52": {"doc_hash": "366b32be06a4b260adccdee7c7fe61a7ae333ab024b2c719c2420e787895f7b6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "310c4dc0-fdbe-4439-b842-93bb6b56fe40": {"doc_hash": "5d15bacd3b41e6b04aa84536d80c3884cadf5577c8cd16e32e53228805aadb26", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "53612ea8-f03a-4003-b9ec-fefc2f8e6c90": {"doc_hash": "b0719490f57904724f0a9f513a354b979e878a91028cd7c93cdda567be43176f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bdaa5ec9-5491-49f1-b6e2-1f3cfc2222b2": {"doc_hash": "332dd20a59159e1866cd11c287eb463b16c064cbeb626989a65583848417d14f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f4d57d34-b415-45a2-b3f1-7f1cb877b243": {"doc_hash": "35dbe75be7c9c195fd6e545dca2a33a08a38236f8dbce64eeaf2924e32c71709", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "88b5d06b-4c20-4b09-b1c5-e0b555854488": {"doc_hash": "b3f7d56353f838b31a7aaa4f326ae1c25be94f12e12ef062be9f0d67007746fc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "707e4f64-596f-4f5d-adf2-6c105cd2781c": {"doc_hash": "ef7853d2f8320c37609ef07aeabf19cce7e093ee141521f2b04911e5834183ee", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c8da8742-a327-4c2b-ba3d-cc81b8709673": {"doc_hash": "25dc039807c69294322af865fa638fe5260a15aab4b2709f563700e485b57d76", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "71c7e64a-e396-4147-8c62-754832b3ec70": {"doc_hash": "38005dac6bcdb1778f061d0555cede3ca9f8ff3798f75e9ee2a58ea8472b4140", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a8eea312-60f8-4b10-96ab-b6d2d920bf41": {"doc_hash": "275d54dd7cba191f7e38821176409ec5123b1e22a87055561a58feb6809252f1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "90efa3a3-8eec-4bd5-a57e-10edd2b3fc91": {"doc_hash": "2a5132fb9f7922d5e1e5d085ee0de808c40007d1ef0fc730f9be55462a663a52", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a568f1c5-01cf-4c4f-bb59-cbcf68c630ac": {"doc_hash": "38716384e6fd21f3332a53b5ca0d8102db8c7d3c1b7f522b2b9b257db5dfc1ce", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "736b0947-88bc-46ec-ac5f-8def163c6cdb": {"doc_hash": "58ecfb8b4d0a2eb02952b50ad3c5f2b42a891e4ce05be54976145e97a89fc9b3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e8059fbe-8c4e-4c28-a42d-b361ff0a0cb1": {"doc_hash": "79d0ed17d93bfd08ad53aec1963f50b930124267c68efe496a97aca5b582dc7b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e9356c27-9f45-469b-b3e8-92ccc77e8479": {"doc_hash": "7c3a9efb8f83590719dfbf3e70e7da5c8be27e50b77794f1f0324213e4a79d9f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0de43831-200d-4c50-b3b2-92a15040f35c": {"doc_hash": "252d00679af40a9428e76683d8184cacf74dd4044aae49bdf59422c1145f4878", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "329470c1-b402-4402-a19d-2180fa89a01b": {"doc_hash": "8c2c138944f1d2bc503c1d5c2ae851c6f2be9a06c96c61d47a8152fc2c58c37d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a5c15082-c1db-4f6d-95b1-9e53b9ccd2f2": {"doc_hash": "325ed0caecdb468ce59082534aef58ddb29eb442df07a55e65fcea4357c7ab77", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d9bccb95-1fa9-4a3a-9f4d-ea090ceb281a": {"doc_hash": "c0b47bf5a1379db32fc52b3ac93be17368eb25731fc0acc7ea74cf55fba9cdf1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5b25156a-87c4-45cc-8da4-5f78ba11596f": {"doc_hash": "8da2a6131a75e31c4f8605b2e0332d0f0a2cabf3674328ae987b5661d1952e75", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3a4ed568-3f83-4d91-b199-5fb596bafd79": {"doc_hash": "41119db85e11c66ef2dd168250f427d858c17e362b6b2904a288939394b6c68f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "093c4841-0ea8-45e3-b0ca-fdffd036809e": {"doc_hash": "babf30762a3910234322bd5d22d87cba778e206d794218babe78d18408073ad2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "28a8b6a9-9b90-4ec5-9edb-a7d39175c033": {"doc_hash": "e1c8db573561ffa6e8360211747cd371e7163184acc06b58cef3a0a91e5571b4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4be2f053-ba7d-401b-84f6-54efa75a7b78": {"doc_hash": "0f65f96eda9be06dad9c20d24d51e39406f35d705301bb3b938121adb4fc9a86", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "10664c78-cdd1-4c89-8fd7-39e4d9aab81f": {"doc_hash": "0d4f80f91ce5af6b210ec9aa67b8213d216640b06d60f5f46311fe2e3b669184", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f6a722f7-69a9-4fec-a6ef-e3cef9737c8f": {"doc_hash": "e37ad0782fe67afa62670a813d456b2b4f67fa3320f22a1ec77ec374ffd4d0dc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2c8b557b-a681-4607-86c3-a7e16ea70f61": {"doc_hash": "af78ebe5e609e60c0759a00bbd3e62ab168c60f2f9fe000bdacad5513fe9e0c4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7c79b0f3-6f6e-4afa-91ac-deef120efe4c": {"doc_hash": "512b9452c4e2b2db9252959e66dae351b2ac53266ba2d873f24f47bd96c53f6c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "20bd9b90-8e3b-496e-9379-ff6600fdc27b": {"doc_hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5f2095ed-0e7a-45a2-be37-2ae7e95f602e": {"doc_hash": "5f624f5da3476c4174129fd9db4ae7a0b21a7394fbde61fe4f15daf6e6e8281d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "695b6bd6-23e5-4675-b640-3a3988140948": {"doc_hash": "d29fe48b2827af88ef5fbc95ee9d51507bd35d19e9895bb565d45d5eed003cad", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "193ec0eb-b51c-408a-8f27-ba22a38aa190": {"doc_hash": "6a81bd19e4a2fdfb6b8eb5a300b3a164867dd163bc1a8c293b1ad9a407c3d45e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f38b633b-21d5-432c-a636-71faa7f152c3": {"doc_hash": "77187f450437342a6d1173cdc2d69aab041b98a673ac62943af515d751a83cd2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b312024a-d71e-4a14-9d51-5a79e83e8883": {"doc_hash": "4ded5921b11e4cd7699e173c870cf090ff7766dbc2de9a2020b3af1914a4f974", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "99d38753-bf42-4bfa-be49-bc069b1bf3c0": {"doc_hash": "d0fb0d3d853162c8d47b8444815bfd895b9d3a03d53b7939c1bb86e928d99606", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9825dce6-857f-4691-9d0b-eda34ec5a59c": {"doc_hash": "b7bf448a62bb45f2c5e98b9a134613aa9d638f6fc90d8a226026a187b43e62a3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "32c0b547-6fc7-4d93-acdd-e27cb4e6713f": {"doc_hash": "81cd72c0cadcbe040ba9dce23a386d547b1d359c9992a2de754483a5410f2f31", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9d9e08a0-c0c2-431d-8150-63dea9fced95": {"doc_hash": "ccdd17dc9bab2ddbfb833a9680b9d2bfec80af485c9fe6d0a364257c0d991386", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "75476202-adfe-4271-8c29-841dc4eb40e2": {"doc_hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a7e43216-402a-4e5f-8bc3-c8afd91a486e": {"doc_hash": "978ceaa043b4c877105058188db373d2d82cfffad5e1f684b52a4051f33959cf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "40b7204c-42fd-445e-a7d4-eb9c37349df3": {"doc_hash": "6204e0f648c2f8d26069e13a2d7be3daa1505446bdda2ce1f0fb6a540856fafc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "069a68a9-8c48-412c-a905-47fa844abe5c": {"doc_hash": "14201af3029eeffca6b3d1d6b82983748cef02e0814fd19333abe3dd2d827d92", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a94b49b2-0fa5-4553-8722-7eb606a5e0b3": {"doc_hash": "5f90d581d18aa0ff7d4b1bf13cf46b1f10b51b81dfaeb74b12757dcb9b37b3f4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "704467fd-d748-4ef7-8349-273e6ca7bd31": {"doc_hash": "c797adaaff7e967fea55e2ed7e0cb3930b1f5df94efaa18a1bd3e8fd2674705d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "caa31d19-4204-4f77-b059-0b6ece766507": {"doc_hash": "c75e610a0b59f3d2d7e3f69b951772444862dd410f0775b975d525c3e6e86e93", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1de041b1-402d-4ff8-947b-55adf606e27a": {"doc_hash": "c03f535ff069f20f8ea7e0f2bf0b2adfc27b79ee6a963fe35678845514a94939", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ac89c9b1-1603-4ab5-b97d-efb8cdc0c81c": {"doc_hash": "e6944e029e9219cbae2461b23f2fc48314874965977af026f7c1ea220169ca34", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d7751d0e-2b82-40bf-a8a3-10a1b85712cc": {"doc_hash": "a176b485c02927bb422af8d1a059a84b0c1631d5bb47559d3de124aeaa742081", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "403d83c8-ac17-4031-8791-21ea76fdbd3e": {"doc_hash": "2e2f608cebd2ab973d186feb5f8ad84b76c7b6bae5d07477612b4540a7bab4e2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bb57749f-2246-406f-88c1-d804bbd5eacd": {"doc_hash": "19239c50803ca0c879bcab875cea2163c87a2c0a88a96a0da7459d562b88f190", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "236594cb-ed86-4d43-beea-006c536fc76a": {"doc_hash": "24d337f3f0bb636e9d023db2ce6e81bd83dfae27a8f13128e74eedffb0e2af90", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "de431448-acb7-46f9-bd12-233cb1addd63": {"doc_hash": "f6247fd518ca9e85507041c8f668fbb489c1b0b99ab4a42c48362e98e19b4673", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "87c0ab7d-357b-45d0-ab10-78eec8f77c7a": {"doc_hash": "2e33b43df6f10b5460a247dec0a5a8739d501f882aef4071674d49367003e93d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1b473ec0-2c18-4de1-bec0-a980859fbec0": {"doc_hash": "8c09b056adc96e6e98c87be1ef1e205d80353994134cd796e923a1f14ee7fd5d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a1ac08c1-0a3b-4efb-8221-78e598994e4e": {"doc_hash": "e91d5878a625634a76f8d684a51ed79c5adb9dc434624a5d2a52444e4468feab", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "80320470-9e88-4c01-aef4-f675b2ca397b": {"doc_hash": "0470656dfefcf59e49f7eb6db9c0e58edd330230b4d44ab8357a6df19b2e81d8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9b4fd04c-6bd3-4564-b51a-110e8edb324d": {"doc_hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a73d5032-2f9a-431a-9ae8-66b0963683cd": {"doc_hash": "a9d3cf8c80ae11f6f27efa3e2c004b30fe00022b3854d674ea5dc14fb24d1507", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a887d294-892f-44ca-9566-71b947afd593": {"doc_hash": "629768138a239b88cba8f9e492ac354cfbc3328626afde09d922fa94185f9030", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cfd90cfe-88da-440b-a9b2-4199146e60d0": {"doc_hash": "70b15765324a2d6e589b30fabc394b81438635ffca95ab15e7f5c147141ea5b3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "89b67a36-f4c2-4dcf-b2f9-ccfb2a290ee0": {"doc_hash": "eae9883a8d381e24ce6be6fdbf06110aeb2d8d48c564ce48346a24296ffb7060", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "49ad0228-e032-4666-8850-38a1f56bb08e": {"doc_hash": "030c027fded7123828c393b2efecbe382430ba87e89e907e13ba1ba134e27a49", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f3718338-8d51-4ed1-afbf-1c4d4288b0d7": {"doc_hash": "b90d0748c37581b35613b030d9ec8debd35d21eb6b3e8bab37f19cc4d3269833", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a0cfd113-5c1b-4a88-88a4-0cfe35e267ef": {"doc_hash": "d89000a860ad34d2eb86eb0ab67d4d48e71f2b01a3c9b7ca9e94b3dd0815a6e2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7809fb49-ecd4-4151-8796-56948da8da35": {"doc_hash": "ea38683ae172d2eca57bba280955106c2e5c2e5e353a32d05459ac90f7d88a5a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "634eaebd-c564-4fb2-86e4-3fd2ee3c9797": {"doc_hash": "8060c588e1c957742da115c03f5e7441043263f9d16fc7527e0555c0e63ab34b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a057f2ec-fd3d-4232-9a4c-6e9cc1efbf74": {"doc_hash": "bc27b1c0fbf3141edcf5a68c5594850c59a4b144c43466bec4791be7df2927b8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3ce0d9d7-2762-4e1a-8392-c3f83c8ec350": {"doc_hash": "f882f9825617e9a71f61ef7f7c73297484e0cd9bc04d92ad25f5245f0fc38a42", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "32440711-f759-4f1b-bb0c-ab6fe7feb73f": {"doc_hash": "54315a4e5c55a9a073cb12273b12fc9dfdb5b882019eda68163723db6f1524f8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "525fde1b-aa29-4b7e-83ea-f4d320d339d9": {"doc_hash": "5afb5eb56d6c7adf3a176a34f9ae5457f49013e551d578b8bd1c4f3f6d8bcfc0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "beef7256-e300-4986-b448-cf9d1ca31dd2": {"doc_hash": "9bd7685852af2d1d61c7cf7d2b14c05fb226e68568ab34cc740ba7cc5c4a1380", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e8b85381-adb6-46e7-b05b-90179f5acd35": {"doc_hash": "17a77857a8056b25ecb578d34ce1670c077aadd85341ee587f136e998de1f5be", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "66e45215-e79e-4a67-bc8b-2242b3236779": {"doc_hash": "d0ad1a54ec2ba946977625803d7983a629edebbedd5510dc54f33efc01010479", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "04dcedee-6a25-4d37-bac9-18ac5b0e27c3": {"doc_hash": "071581ea9b962996a5088749aac76a0d39ea4b8af62bdcf8550f6f7614d1249f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f3b3a4d4-f2a8-44b6-a6d4-93af015ee702": {"doc_hash": "a17fbe51836ec773cd3b063bd006d9cddf18135c9b48d2afa1693300ac7f1cd3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0d1f7385-c314-4b80-84ee-e3267c675f91": {"doc_hash": "4561dea3a69a92e7fa1f942bf18a4b9cc1fae1d8bda25058ac26688a853b5577", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "155a5b0e-d579-4055-9517-58dbfc56a5bb": {"doc_hash": "11bba99265e089eebd13b2e69f7b5254779a0ec96ecea544f0fb441807032aaf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ded4819e-4ef9-4736-bd64-7fa62b5b253f": {"doc_hash": "d37b30b3867b3a2958462a4d18eaa74b5f3487c582ee0a5f0cd4fda576ccf661", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3cb9d746-a900-4bd0-a68c-8385ef6f8865": {"doc_hash": "d4994dda97148fe055429c73a13afce2accb20ca0f81d57a457184f2d89a4a5f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "11763e29-7b0c-4871-8f24-4fe5d0eefe2e": {"doc_hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "30eb16bd-ea86-4751-bfc0-982fd4368e67": {"doc_hash": "7b109cc70bdf95925a20df6e2f5845a3255d2308048de4f820c3d4e035e75c1c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d70e34f2-f0d3-4b55-bc33-6936021a7071": {"doc_hash": "8d5cd39a4aac4d992046427b13c0a6bbd2887f8201d4fd583a367d49d213ce76", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e07d5df5-5bb3-4e61-92de-071acc10e170": {"doc_hash": "7f41cfa428d8b8c09eba7f07afad2dea814dcc37a871b2d47cdeab44d321f981", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3e059260-9d9a-41ec-95c8-c4031c2b24e4": {"doc_hash": "2b4d6b5a05ec0ad15c6b789f55d4e5e2c449da6080ed3f7bbd209507b2e2abaa", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cc0fe5c8-ba3c-4185-b984-bb6373576732": {"doc_hash": "72fb581640563d25931c9d38954a5568031b921a3d267165b23cd6d1c45b00dd", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1de0d645-1f8e-469b-811b-1c9afc3dbb69": {"doc_hash": "43d73780e92166418280b844d50691d522be8a0a39dbfc4a07f4107dc6bf8241", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "61f4d134-c4d8-45ce-b8d2-638bae48b9ce": {"doc_hash": "b580f7d587eabbf1d36df27b413abdf415b98fae786051a5af6dfe4cae0aaccc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "828ff51a-7f12-4d8e-ac15-5e8c74b4ff19": {"doc_hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6d70b1cb-1f72-47c5-a8cc-f016938078dc": {"doc_hash": "5eafc3dc0803d95fb2b56283f6289c23143baa30451e276bf8b098b59d2c0069", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8706beab-0055-44c0-9a77-08910e8adc56": {"doc_hash": "de7eee609be433fcc8d8691cf3098d805b116ddb762946e991a62e20c1c89c76", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "35ccc861-0059-4acf-a7a8-ef0a6c9c92e9": {"doc_hash": "46aa22f53a1da0b29ae4d47500750a7022a3221ee9b560d89ffd41f383b7e1d8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "910cac67-793c-4b24-a81e-9aa96c3bb663": {"doc_hash": "db5c63fedd37421f8f9c3f19a9e159f62f938ddbf0cf86759ab4688ecf87186d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2fc42a5e-71e2-48e7-bb56-15d2cd04600e": {"doc_hash": "1701488d18e522e3782448f9f358711448f4568f3ddfab031a366156492b770e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ea32b5e4-cbd7-4a1c-9e71-1acdd79c02c5": {"doc_hash": "bd4edab755109ac5704c7dde6fc7e8313293f0fdf7208fc9065082b64fb44f9f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a532e9b5-8c59-4fa3-9f09-bf0011d24a1d": {"doc_hash": "b1142436834078bbc70a0370a1172ded041f117002579d116bb16da512b0dfc9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9ddbe670-4043-47da-aa02-6349f53851fb": {"doc_hash": "4b01f92f6588ffe0f9c45d120f24ff455a5d9e4e291c63c278739960021f59b7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c70c51f2-bbf0-42a4-a9cd-acc9025d1474": {"doc_hash": "7a2cf4d5c6c6ece996c9bc6e55f4b427d7c9e9603fc06cf28ab5c16c0b7f058b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3623d2b6-9c56-455e-aefb-593f55f26e30": {"doc_hash": "0d09dd3dcc5824afeccae93f062a77b921eceb795f266661578cc7e1ed563ce5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "77199c7c-349f-46ff-be92-58092e2ef7a3": {"doc_hash": "296ab43358e4d9b9641b86ac6af3ce618bb072c1501ead69274a8c446cfad9f4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a9da18de-b3b4-43f6-b49e-12399dbf5493": {"doc_hash": "77ddac329c9609ded850255372794880307198b728cc2f1c2eb015fcd6c702ba", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d972bf5a-6e28-46f9-9c83-bc47753f1ab5": {"doc_hash": "d055d58bff889ce829c8a39757ea18c6214bcf1f3312322f7416df7b80feadec", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "979503fd-7488-4d64-8817-13fbb161895a": {"doc_hash": "2af5f8022ce6634a59c6b9c281a3b7c9979a7416e6a786f39d1f71e7bfbe2a7d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fdbf51a6-b01c-4d36-a5ac-e9b3761a9ed4": {"doc_hash": "0984ee79ac23493d9bcf4d411fdb58da7207ca498b6afb00893e52fe5cd5067b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4262fe4b-d936-4814-bf4d-de9fcf732949": {"doc_hash": "b9f2af44f5a7a761a34561e2b944f5f8ef5b44641d82f78a88fb27f3572071c1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6279660c-0d22-4b21-bcc3-983340ac5d23": {"doc_hash": "03c93675d2d81414ee214e639d15cecc17138e746b5cd4ec13792fceb3ff0e4a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fdb40385-4472-4484-ad57-29858ef66959": {"doc_hash": "a074fad27c9d17cb4fe24593afe8fe96ce4c5484143ab03320f4c3198a767a3d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3243e697-6745-4191-bd0c-444df7098494": {"doc_hash": "c57149b3d8bc33fadc553594a269834f40b2d98644b3bd7ff95f1570b6b455da", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a8ab6cc4-216e-4ab6-a84b-e5e78533ad97": {"doc_hash": "34475234759f60492d75a3c21232132dce2ab375875985ea80ff123d6ba15c1a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "96f06b1f-cff6-4862-befb-cd100a32f5a6": {"doc_hash": "96735df2449852c511edab5ed0302df111185cecdf0c057182e87ca50fb4d464", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b2962b0b-ff6f-43ed-a321-8287babaf40c": {"doc_hash": "42d221281d172c8bf2c7b4229bf8c554cebfbffa449a024ec2f1a36d8fe274bc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "97fa3c9c-f905-4039-bd16-bd3068d3c6ab": {"doc_hash": "3381d2b28c815f2b77dafbea91181a42771c28de2876e125ffb263d6055e9870", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b5e94c4f-fd73-4863-8977-1bf4fe6f4eae": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "613b5561-62fb-41a7-96bc-502ff81d1468": {"doc_hash": "b883747af9c937e6c2a3d658de1370ff5f4d3b43c6c5cf9bda2617ae47be095d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "71b1670f-aa9a-421f-978c-3c43fa532100": {"doc_hash": "059923215a1d23cab80e4b645183b507630209ca7339046ec2f8fbb4d8985147", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "43307305-5e91-4c91-9af0-9df87e1a9fdd": {"doc_hash": "904740b4f74faf3c90eb6e4ad80ff2fa7c27f5fa3b137cfee149b2976fcc50f5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "63b16e47-29ae-4093-8259-179f73b7c312": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cebdbc01-d8da-481d-b17d-aee7e42b4d9b": {"doc_hash": "248f956f28d8406b9d76c5fe740dbc7868300d91e2eb6a274d6c1afda08332e5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2c2895b8-7e55-42d2-97c3-699682340e52": {"doc_hash": "44f6d27801e8bec02188184a2284946c3b31f1883ec3ca26b5a72799541cc7c2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4cb5359e-f761-4f67-a993-e880a9f9d331": {"doc_hash": "f9a084d3801d7e635e7c01357918602ef59b8bea14d307e635d7f31a0a2bbc75", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b7a5d215-beb8-43ea-adfa-d972d70c6698": {"doc_hash": "f561c5a9e4b2e206fdae9bfff49ef15590a969fdf55972ff0fe7e011f4239619", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ba7b1151-d6f3-45d1-9864-79967049b725": {"doc_hash": "b6d63ce131383956b53a9afdc853a87728b0aae4bc2615f595f345fbf1792b1c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e678b697-79c9-4918-a2bf-1bc308aa74c6": {"doc_hash": "5db6b2e2bd44f3dc130833d17b79c475308d3b2c6a431c3891a0e3aa9e91a214", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "67fbcdf1-9470-4fff-83d4-bd83801a4c7e": {"doc_hash": "5da26343627e167a0457dfb1dee1715172a31805f2e49adaf6ca9f5bdad5abf0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "21b579f3-bbec-4d6e-a56c-de1e735d3964": {"doc_hash": "b3d4a56b32c57a42ba07f13837ff7a7dd8f7909fc2e45d90b179d985c05c5998", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9c6ee044-318a-4e1c-8596-a40d8df09394": {"doc_hash": "94ce4e98817ec39220f912c71980cb7937db01ecfde1c724e07e2a3ff9aa4f48", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "04f31385-beeb-49ce-b950-f154c3af6749": {"doc_hash": "3aa3bc91826c72679d58b2f37516208cff42f6493b338d66a541c5f115bb8ee2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cbec7fb8-bbca-4e24-826e-4227f23e6410": {"doc_hash": "1a7f3532d48a957438fbf9d321b7af3d012a7972d62e424700fa4bcadf3806e5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "27fae339-fe59-43dd-a1bd-1f35d3caeaa1": {"doc_hash": "c856df51ebc1110c77e98d0f5325edd858d1bf67ae220eb1e251d2a841a9ef35", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "42a19f85-8cb4-48c2-8e5c-f448143db5cd": {"doc_hash": "d750815cb858630c89d5b6c27a64abc6662b5ce8255b65e4e71568f62df3ed99", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "dcf46624-2589-4f4f-a2ac-fdded3287b34": {"doc_hash": "265619cf5f24b64996b48f4789ea88fdb32be24f8b25c33e4c5798baa10ddfe4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "51394643-2cad-41d5-8560-7ffe119b9a01": {"doc_hash": "cfea2e8adc061d7af0e584bc6e3fea4274a4cb457aea0dd7402a9c3cf2bc2839", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c60f60a6-2f47-4b2f-9869-4f78404377b8": {"doc_hash": "7425195511886f19b92452880f70234153263281836177ff1f17a0f2bc98c297", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e113a4a4-3c9f-49a9-8a9b-7d9514ce3758": {"doc_hash": "57643ff4578c50f4a04d36a493aa235b518590b3e31070fa5e6a6008118cb02d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "44f6b920-46d0-48b7-8926-fa1e3c5370d4": {"doc_hash": "91f3207227a0d1ff56c56040e3ed7c7afa6ce3b4578b6482fac9768955daf244", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "35d38511-4694-410a-9bbd-fdb7e92f766b": {"doc_hash": "37a840efc198461a9680f4e1956a90347a015eaf7eda25f7d41d3ed0ad839965", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8363622d-49a1-4e80-8e76-901b73846325": {"doc_hash": "4a37f5cb444f9b3685f9c25f538d00ea49c9ba2dcb59149ec666987d2086a726", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4068a141-349c-49c0-ae7a-4e7c91970b5e": {"doc_hash": "84a86e297e3e7102d1fa45426d759bd9befdb2f1335873b264b98ce99c39ff6a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9909d7e4-bb59-4f6a-a329-225f699e70cc": {"doc_hash": "4920528934840f8a76bf13456f155723b0c991fac69eb0c25d983aed7e25e7ff", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3bc30b87-869d-4ae6-8916-66e917294fc7": {"doc_hash": "936cfcf1e4879a111656cd3b974513905aff92ee63e7db63051b722ddd78635c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ec29f5f1-2c36-4aff-a31f-edf7630f7b51": {"doc_hash": "f252503d7c51b455ae51685f537e9a3efc32d4c655f0432008cdd7172cabfa83", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a2102f03-d10a-4d44-ae00-fda7dc4edfeb": {"doc_hash": "dafb8522cc2cc518ad0031d849c2acf5cdf66fbd11f260bb1fe4e5566cd3d4e6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "54e5eff1-8ad2-4eda-8be0-7c8ba0e0ad59": {"doc_hash": "cd1147a99bf127a0c6341bac475eb734873db0c69b620f4acaa38aa048aafca0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "81f7c04a-7200-4495-8658-0be80b3aaaac": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "af2459ad-e308-4c5a-ad5f-660a9d34682e": {"doc_hash": "f60d0281c8cb1cc45777afaec0d0b758c7649feb8851f9d2a0a34a3ca0be24af", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b07d6d19-618e-4c11-9b18-e9a8c9911d63": {"doc_hash": "112e23fcc3d433f7f0cc2e054c2789472c5ca93a38cf4112ae2605afaa19c52f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "92d4c178-cc23-453d-abaa-97385495533f": {"doc_hash": "09cff1dfdecc95b0bdb6d08ecea74a3544d652cb054b5e8ddb02071d13bb2371", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e764e927-e752-4a03-b86f-58634e751ff7": {"doc_hash": "622fbc8ce36cf8f5b0c365ae18f491a8ceba1136dcc2fe840d23afd02ac0ebf1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "84dcebc1-2b55-4ce5-80ca-612e9428e47b": {"doc_hash": "209e018c28b9868f139312906a5f553fcda42917b6a77a209bc657b785581674", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0bba52b5-54a7-4839-abdc-8d3a2f600998": {"doc_hash": "56d9199bbf8dfa6ed9e9f8803dbba04eaaec125aae5ec149a4cf9a0cb792965a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a8c5f989-1f9d-47cc-9dc3-a8f3f8c4dcd6": {"doc_hash": "c8340150f074ca6d3101f902b7f6e6a7cf6edd3aff08fe1f2dbef6aaa9384c15", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ca62825f-4161-4bb9-a40e-e21735d0965b": {"doc_hash": "6caf08d1ea9959d9d1b9f7f870e7fd53d532bd90de02e7aab1b7464a85363fa7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "25874d31-a647-4518-b7d7-dfa7835bb3c8": {"doc_hash": "11b95ad1ef65cbc5608e249eb4f13b97c11e3a6bd32abb17689b73dcbd849833", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ee221613-118c-449c-8e60-693cf911487b": {"doc_hash": "d3a16bdc0f5ccf2f01f5fc3f8b9ddc21e3b032c1b8ce5342e62439841cd4359c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "08ab1390-5664-4c72-bb4e-eff0190b29d8": {"doc_hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "67336796-0460-4d8d-80b8-ba0a3b52fd60": {"doc_hash": "47560d612eb3626e9f7040ffd2f1ecbfd9eb6f6d85fcbc05082f4a23d36c57dd", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e298afc5-aab8-49e8-ba0d-9ac3ff6472f8": {"doc_hash": "6a618855b492c206aacdb4b579de841f0e5be09d2d9b546d091013271f23b602", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "252be990-a8e3-4425-a48d-e92f12f7538a": {"doc_hash": "fd3973677aeb12abf79000e0a1ea36392e2941f8c4e6f6478b2a534edc8e7840", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8218ce64-45e7-48d7-97ac-9463d7059266": {"doc_hash": "d6d8f925758160986fe05252ab735b5ec627339d692e95415b24300f0e18208c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5401eef0-2bbe-4894-9bca-a6188088b6c1": {"doc_hash": "5b64145f5bdcfd598163f53696f5722a9e78ed4a3758a08b5aa762987c52988d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "054971db-481f-42fd-876b-c393c2c7b897": {"doc_hash": "9d9dcbf03121fb904c1ef7e766da2e2fec0087316a409b56015d926cbee83416", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "67e62451-bac5-423c-a8ad-c5aef43f199e": {"doc_hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d0ef445c-da19-41ac-ada4-0a7805d1f960": {"doc_hash": "948a5a2b86355d72963c05a1136c024f5cc2197a3bb2794ee5e1d75e5369a2c5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6c87b7a3-ffb8-4e1f-9e6d-b620c2a40632": {"doc_hash": "e2e049121a994e2583642bd869ad3e31374cc55786e7077740b63f94027ea587", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8c77ecf5-c14e-4884-8812-cd2155b39201": {"doc_hash": "9f5d107744512434adcdce4aa19520f3cd5aecb805e298686484f32cb3614a53", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "42de9c82-463c-4ebf-bbcc-41580abfeef2": {"doc_hash": "15440b00c7dc791f4f724c02d7a7e4e3fdca335d7edc875c3aa38bc268721882", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "373dba26-600a-4ed4-875f-8bf326292e21": {"doc_hash": "7cb552d952e611550ebbbda05e049eaada1ba627a910891f1bbd74476c40d3d0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "adc72803-b12f-4b0b-aed0-4394228f8951": {"doc_hash": "ab24ad0fc75f36e826730ae378f67b5b7cfbb64413b540c7457263bf079b1dab", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "50405a5d-6cc9-426f-a102-3ed604fff919": {"doc_hash": "a7bb13e8a4b775b799e52b29aa10fbe74ac9424623d016bf837af51cd29db082", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bc524ca9-2cad-4760-ba2c-b99fe0406f9f": {"doc_hash": "2a4ee7cba5339320f9ee4b608857fa43e74cf3e0fe4e870be6f41339b1136019", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ad439c6f-0873-411a-b4a6-c9bc9c6917e3": {"doc_hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7ce58424-61bb-4898-bb9b-7bd506cf4be0": {"doc_hash": "6809c43326473b1cf2214f5a47654e9d103dfbfe2ca4371814a40d4e134627f7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0e080014-3ecd-40cf-9cbb-d1960ee5cc31": {"doc_hash": "73e926040df32d66b6c50bd24b4700924d9d473234f64a181f50d02da15b25b1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0eee668e-a6ba-4b39-86b7-3e3d99a50353": {"doc_hash": "c57864a154383a0d023ffceac8a47fe84d65584c215824f454a12a0a7045980c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0ef4c38a-4dca-49fa-be11-07db6b12bdd1": {"doc_hash": "a180f2173055cf08d15b5f94c29fb66b1c74140ab0a5ea967979594dd0d34b20", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c3734bd2-7746-47b2-a46e-803cfd4a079d": {"doc_hash": "a342be0bea5b70a8083692169fa1ec1d7cf6f34c7e621aa9f8a4dcb94ffd25a8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0a958387-558f-4844-b2db-dab6b4551adc": {"doc_hash": "1299c16dce13957b5dcf738f489bcece8aa83d649ca77cafe775dac18b0db222", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e1227ac8-7ad1-40e3-8f9c-068d250de59e": {"doc_hash": "d4ee850b32c0f40ea1fa6163aa5517171a7d62a4e4127d9b4b05d1571fa3752d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6f969084-1db0-4ca8-b160-29778c662ad5": {"doc_hash": "2433c9871eec33d7525ab49017fcabc8791189500bceb8b205de36b4be6bf62b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b43632ed-ec41-45ec-985a-43a065cb005c": {"doc_hash": "2c1f4d531ac8f889f66a245c03db9d650eee40b8a27c14b6bcb610c7d2937bb2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "56569be7-5fe0-4d83-8fb6-12215d31d229": {"doc_hash": "ded8cdb8b728f43e6f778692644564622b4405b6bc1d19ca50db7b1458bb4ba0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "16695142-6e3b-40f2-b3e1-d0eba4e50ba1": {"doc_hash": "6e891042570a6df8ae55985800735b73b9fc7eb86d0d8eb3ff889174b61c770e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d7fa3de7-e1bf-4501-b46b-8b9a892e920d": {"doc_hash": "7fe487c9c00e47baafd41d6bd2fe55b12b68b962a042d7f6e67b0ba48f39aa80", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2093060e-029d-4fda-ba72-30d184000110": {"doc_hash": "25a932c92889f475d490c3221cbc0371724dbfbbf32fba1bf7dfc43076c5a721", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e9264d9c-2877-460d-bf32-e40dd1c3ee00": {"doc_hash": "dcce54556c73c35a5f0239214a5af506780556c9f5fdd4791071ba2c94e2c735", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "96d32e80-6438-460b-a9c6-5bd08d0ba45a": {"doc_hash": "d33b2f8350d6934a52d497df78a7c433c57733b3986b8007f9effec0f764fe2d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e7666f87-c6a0-4619-aa9e-f7817982bb5c": {"doc_hash": "b7489754e841725e23d257f2e36de1de0db1552e3297dc90922ad57130089baa", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "dfa109d8-42dc-4895-ba13-073baa55b5e7": {"doc_hash": "781f398ca0eede664e5e174b52188a04f6f7ec2c278b0f2d8b94e05b74b115a9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cf829cbc-0002-421d-a1fc-9b7b27d6f842": {"doc_hash": "12342bcee9f44ceaca3dd5f4eb4fa9ae88dfd78f0c919bad184b498054e00c88", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5db2958a-c8b4-4678-93ee-7734fb878db8": {"doc_hash": "3c4863ef2f5ea00d9ea1db5955998117470a617547439a6f103f3037220f87fa", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8e984d72-23c3-4a78-9c08-a196b7d673f3": {"doc_hash": "a1d2c072d0008beaee99cd5e15ec19c4c4525b2fe8bbe7c8eebb8898780fdcc3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "092c305b-839f-48d0-94c8-622d9580af9b": {"doc_hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "510b9171-c206-40b0-85b7-b9f6022910df": {"doc_hash": "659a4f747207c72fd9c1b14f2c0f0bd44f95dade3a449913ad111e5784320a59", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bf85a60c-9fbf-4e01-8f52-086b9a521948": {"doc_hash": "fe28f3979c8f08b246482519774f9bab99334a4610bb72d543bd990ea780d723", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fbf2cb4e-998e-4b2e-8205-bd4bf073a697": {"doc_hash": "1905c79600fb4c5277f315abd83460e0a2a9d0d8aa028ec1b21a73af5731bf18", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "83f2e9c3-c196-4bc3-b702-b3860ecd7c2b": {"doc_hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "342aab5d-7892-4b81-b850-077ebc8a2a6b": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f59754b6-d749-4251-a90d-996373696a7b": {"doc_hash": "28aade4aa9c58e834c36d27514100d082361e17507c6ebdc42673cef6257e05e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "59999ab1-a9af-4c8c-bca1-7ca826e6d79d": {"doc_hash": "806ab0e5882b32c2d6760b9647a2547fa489eb738ba5d58ad50d660f70d57178", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "202864df-a567-47c3-9d1d-aa3c7d251e98": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2189dffd-ac61-4087-aade-14a962618de4": {"doc_hash": "6714af9b8fb7be252722744606d70feb4f7e6a9518ff8e1ef0a36c41e0fee049", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "222d9279-f6fc-49d3-a9b3-b2f7c167c672": {"doc_hash": "bce951a7d0cba18805dd2b360e8bf3fd3aa5980cc5179ff333b6bf2caa2493ae", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c28a0364-cab9-4c21-95e1-f2723674570d": {"doc_hash": "4fedbccede58a414ca239a8db20e13fdbd42a9e46e055d187cd347c67fec85fc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "088d796f-a556-4721-b0c5-33b4e74c0765": {"doc_hash": "c11dd6c7ab7f70b7b98fe56b4afdeeb9fbbe95f863e89fc8bb3659d37a2d32e7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ccd4e2f8-2b5b-4ed6-9d48-7e01aebce9ec": {"doc_hash": "55c67e17fae87f73b6073b48078dd5f864070b5ac839903b49b2f96abbe0351b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ddc08779-eacf-47f9-bb6e-e635439bd951": {"doc_hash": "23878ab960ccc3cd30b24213e7675ff5aae0dd6b9b4a80e363fa94d6c95e2059", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8526cdb7-54bb-40d4-9450-77c8f096783f": {"doc_hash": "7e2a783ee55ca291c073b05927cc684af3f4517fdc2d6e74bb407dcf945d4490", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7d15597e-f6d6-403c-bdc1-9afb9fd305d2": {"doc_hash": "c43f8fa28b91ad8825fbdc370fbc51e6cd3c5370071c3aab03c5eb50e2aa79ef", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a6f2a966-7781-466d-afd0-9a5ba4405863": {"doc_hash": "ac4bdd17d4e560c40b596fd63bbc22fd5646720c321c3d11a2561d875ba3d486", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bc9b0375-2447-4653-a6d0-22a4af575a13": {"doc_hash": "eb966a58ea5dc3227bf9c8d7c40db5d18b9c78ef00a9d32f36f8b63dacff40e1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "167e91f4-3528-4f83-b480-877d996449cd": {"doc_hash": "f0b29b6fc2e6e694a5d54224d28040290a05f2ad7f65a67c9a4d057b9c0c16b0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "633f72b6-a13f-4b79-93c8-95e408f14726": {"doc_hash": "2d9e30d6129397c26a509d729a9287331001c3a46837fd92e245cb4a53b11a91", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b724a9ee-da0f-4b78-874b-a2d3ec1b8b3f": {"doc_hash": "c51152fe2b65b5b1daf83b5fd4c3e1d2e6c0ba12297777822e00ebdf6c25a401", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e6fd3c46-e3b6-406c-a1ea-b9e23c1e97fe": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f2a1fe0a-d52b-4982-8d5c-249783e3aaa3": {"doc_hash": "186b19de15623c636960f74ef198cd367e99309ace52c527c401f1cbc929bd93", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "42536a61-7fec-4ce6-8d17-68f22096d746": {"doc_hash": "8e781df4c9bceccb40b0ff165889def472e3db2bccc3c7ea86d94c6643a389c8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "86a5c506-2cf2-4c86-a456-6406eaf045cd": {"doc_hash": "5f601a2c5dd38b29399683bb70eddae1746eddd0a27e02bda08e39066e422796", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3061d59a-5cdb-411f-b7c0-02758b27e31a": {"doc_hash": "23c1f2ced0050ab0cb42972ac2f4a480b4b69b9cfbf1d9f1cee6c1f2f5668c8f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8bc8da4d-88db-45f4-ac10-2a1d19a34075": {"doc_hash": "036aea1dca4a7a639c9773dede5a327fca8f8c03073a35e0e95ce2d8eb85d8b2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f1c568b3-641d-43aa-bd1d-f140fadd0032": {"doc_hash": "f97f448c296307792cdcf2298d5dd2984aa6841b85fc32ca6a138d35a3109210", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c1f5b154-1cb3-40f8-b5a6-5c9947c2dd56": {"doc_hash": "ffee4d7cd7350e8af1b0fc899bf6a84078aaede784b8c0b225f04c1b6ea339f9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b8ee043c-5dfb-4cf9-b080-56dc31385179": {"doc_hash": "f1cb325d7c9f36d79aed15da5d8a1b0e003d675f3fdf48a0f80c1f55d0eeaf61", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f5643665-1982-4f0b-802b-8ca1b05d6964": {"doc_hash": "6112f6b824b2ae3d9f67935f25510359e815cad7f9cdd013b00a5ac65e144d54", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "92c50d46-b1b2-4017-baa1-ec721536d0ea": {"doc_hash": "fc81766f594f59ebe8f0248bd4a16f21b6d6e5e2ec729d901c8e3bb840e6934f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "01b92a2a-24d8-404f-b126-7eddc6c6a93d": {"doc_hash": "73400ec00989ef8a1a08c7cddf4042543fddcda19e11c26d567cd49eaacdba1d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9192c182-3451-4d87-83c2-76a71dd483b1": {"doc_hash": "72dca34d784c72a51cf0cad049a345bbdd97363c73cfbcf677b86a250f10b12b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "56f9ab29-1a2b-49d4-89e5-4073ee42b7d8": {"doc_hash": "c175a8b9b5f7bc0cd0fb5a7b9efd2911fbeb58ad342e7517a25fc794a54555d9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c70e0e1e-73e4-4a64-af16-150b8aa13cfc": {"doc_hash": "e46463a566c62ea7bb453c78f360540d2c8bade3f441d219acb15ddc935420f2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3823b812-c038-409f-8e10-6e89752ccb85": {"doc_hash": "e6610b164558c9f38792d8feeea57af2b9259ed7bb664f84213fe0b460fe29c0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6ce1f887-dfce-4e46-89f0-01cdaba3a4af": {"doc_hash": "2a43db64338f978076abb3cdadf983dffaa00a9454fc5c15b861d8b11f49ae52", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "436f8801-c6bb-4343-ab0e-d2d0feddc612": {"doc_hash": "e4d412b65ff634a9912308caf776f3cb476089092edbae2f809b640b2e5f2f1b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7b9ae755-5bc8-4e1c-b5dc-fdcc924de302": {"doc_hash": "fc83963dfeff5245c99a5dae9bf690136e4f322174dda48669089ce2f20f83ea", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "173df658-519d-447e-9b4e-fab76b0f50eb": {"doc_hash": "81e804312c30d77f23bc9602507eb9b2878e41d9378ad43d24ce31bb1c2e0053", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fe36dd03-859c-4c65-bb1e-30774442eec6": {"doc_hash": "2765217b620dfdef7f2a589de83a47370da100d8dcc07a9b38cd2b5d0034749f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "940653ce-c065-4558-ac0b-08b5c6c85974": {"doc_hash": "92110bf823cd7fbe60ce5d5801d4e2f7a56186ec5b41ec389fe587434e9a7b69", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4b321be4-a0d4-4b5c-a13d-a15b99f964f3": {"doc_hash": "1ba9b428a29a9c85375a5032641ff89d3fb661fcb9e3f2a0417cf140e0c9f52d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4d9c5d5f-b3f9-43c6-9c35-fc794c435a88": {"doc_hash": "8734f5f2827e3dbd04dc3a62f66eaf37c63eabbad2cf453328ac09b4129f7432", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1b63ba5b-d487-4c00-a9e5-aaf9a0436c44": {"doc_hash": "f4e8b5f5d74d4bc25a30565d14b8d467bb89c80cbf497dcc909af9b37a38c9e7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1b6491ac-10a1-4a1b-a2e4-6071e53b4337": {"doc_hash": "66b701fef33780ca1855e71bc893711ca964070dd9dad858c4e6bb8a069656b3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "92787f47-1f73-4a61-8d9d-000c47ec75a0": {"doc_hash": "009b46198304b82263b804aa2aa12bdfae5be4ec10e436282cc8822e70570ef9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4f9d255d-30d6-4f1f-9694-a993ac9fb1c3": {"doc_hash": "3d3f1a95a95d3d036b75fa904e1812f351aadb857be59e90936f6221eda7c8f9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5f92d030-6ba9-46d2-9756-52f544518590": {"doc_hash": "c77617c9694b45f02a9cb17120f9938079523398502828cdf5f2e218c88807f4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6ca2e4da-aecb-43fb-9185-247a5c059b67": {"doc_hash": "8f072edcd67834e4574013689285f0fce8176b308d62e6a28bc59354677a8eb0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "233127e7-1d18-42da-83d2-0f5b3169a373": {"doc_hash": "65c42ea16b715c5b70ed18d05912d434267b134f3e7784aa02ff10a81c63eaa6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fb5e3eba-31b4-41da-96ea-cc4e2ea537db": {"doc_hash": "f629cf30639120fbee2dc68b2c9caafd4ceb02d2e94df1bc1b33c93fe4b69434", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fc1447ff-258a-40e2-a1c7-635500249f04": {"doc_hash": "877cd2560357e024cee2b1ccc3e28fd6482e5ebee6371087ae3b81eba01d6126", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9f63144e-ec88-411a-a0fb-a886305105f7": {"doc_hash": "0a4f12a12e6fb9bc43ec2dd6199ddc6fdb97e90bb281878899df13dbc4d6e013", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e405a364-12dc-45a2-972d-f4a81135e7f4": {"doc_hash": "ff0af035b794f8233ef567fb5bce33e6175e19efe78ba176e1ca679aeb393c35", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7fc85ab9-e8ac-45a6-8861-35dd6dc25ff5": {"doc_hash": "37cf3512823511238f4773f7c73fc52aad000c219bcd89481ae1abcbeded5f8d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "81b6366b-4a6d-482b-8da2-dcef2cb4998b": {"doc_hash": "efe62d4649e19937d16243d3592db3dc4ff34a40681114d3c124403acf6f7e3a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8fbe5fb7-5d72-458f-a803-318a4d623be7": {"doc_hash": "59edb531b3120b32907adeee58381ee841981b55e05cc1e986dc7a09f17c2291", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "560fe639-663c-40c1-ad8f-4bd5cedea4a8": {"doc_hash": "64f3c1e936da8bfba140b2356af0b9870dac41cc38a2967df732c8386ffbc323", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5be39312-f6a1-45f5-bce9-40f55948454d": {"doc_hash": "12654b841c363bd8e953d386cc4fdc6adb28124a784aadbdd237287a7a192d52", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d0e25442-e36c-4a65-a817-7c7ad165a7fb": {"doc_hash": "7ac1295f9b7bb605adea5060dc02774da15e6352a0003a65e76bd659f9151c90", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c258e92f-9976-47b2-bb00-85a1d4e4c87e": {"doc_hash": "a592fd82559002f381e7fd532c1ae4d0cca1867917ca670e113298ad69b0bbb3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bf3be2d7-0ffe-4c4e-821a-21ebb08c69d8": {"doc_hash": "adbfd70a304b475a8333a8d1e36b22c95b0e231fa8284c57ef99ac064b9c2639", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6b6556c8-8c54-48c4-ad26-159e2713f3b3": {"doc_hash": "e851997c0cb8cd8b127c48576ef4661028e75e5c8bc05627e6d2b9cd95d39a4c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "be5fc25b-491b-4caa-93fd-1543644d6d88": {"doc_hash": "ecbbe0e2e441e96c37da354240415274e668b46137e3664dfb87e06d6fab12de", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "20866efb-a8e8-4d1d-898e-96192bd3cb0f": {"doc_hash": "04eab4d797a395ee3cab75de85fca5c7521e1a07794d2b77d309bb71e9d5bf5f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "de64ba66-3be1-4902-a820-51ab63ac5643": {"doc_hash": "d2e9e36b405676227ba832e95ee2180fc4131cf0fe3cca77d03f2be76147e259", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9aeaff09-d364-46dd-a6c9-a350dabf81a1": {"doc_hash": "2b8059fb226bc49748d4a02723814ad78898004ff23b8ea482cdf87a535cb9bd", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "087e092c-d370-4dfd-a980-6ab272206c3f": {"doc_hash": "8cc5458e92d0cc9a03620f101388bda5d76922013495738923af9239f1d05887", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "da8efc37-025e-4b0a-9aa2-794a383b9d07": {"doc_hash": "f620e731b36871b288b0ae19f801955b499ace2982e6636c7c1a11776f8897ab", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "72ad0e16-f164-4fa7-b74e-e089b6f92717": {"doc_hash": "9db80a4139a0f60c2d972b050a7239326aa142ff43363866894dd303552c36e8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "57c667c7-0943-47ad-a4f7-ffde6251281f": {"doc_hash": "046753b58ce5c131f9175045d36872f4bfea25372065da19b0d5fb399dc45501", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6692aadd-d554-4ee9-aef6-231be019b66c": {"doc_hash": "1f6396c1b4fd41c07fd6c1e8506b51f1363ca262748a0d43cf27b31499350321", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "84de6c86-6af8-41a6-8181-6dd5916ca4a6": {"doc_hash": "b82f603a2eb38005d80ccd423cd0db28dadcda94dcbba922d023fc135ae726b9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "18d709f6-df82-43db-bc32-711bacb2f7a8": {"doc_hash": "f2b66b58cdee9996bd28402b1b369d64dc94cba7a9f3d246cc7800ab3cd8e1e4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ca94a2cc-7c2a-4849-8ff1-87eb54daae6e": {"doc_hash": "d5c763c42ab07898d86a2d35063a71c0233a1adb182414ea986aba522c1c596f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "692f7dd1-740b-42a7-aebb-42688ec8a792": {"doc_hash": "ce90bcb69a6bbdcc288ca472bc5b28011fbc24db62d0eb64b820661d8dec0810", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "418d1b80-a717-4020-be1a-14a37375a174": {"doc_hash": "6621d82fb1e80cc2c9ddf01f51e3ec1c9f612606715d91b404c21c0fbca9d965", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e680e814-8244-4e03-84fb-556ed89daa91": {"doc_hash": "599d80f3c5cb74a6823438773c89757e6981927097c91795fd0bb8561281aa00", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5c9d8608-7408-429f-898b-cbe4de1c8846": {"doc_hash": "b130e450deccf85f32793ed6aba5c54928a957a22fedc8ea7933cca7c74425d7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ab63e732-32d1-4e6b-a901-845538228cdc": {"doc_hash": "5a6367a2ddb49be08830ccbc4f540e1b1408a6208d13241e3cab1cbb4a5fb706", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4f06b19c-3f90-4eb3-b89b-a1fa8cc7ebe0": {"doc_hash": "add437646668e48ae7f48a4897b0fa6405ecfd7c0e259ebba6d21f7ff8fa13b6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c24bce16-a880-448c-9a25-ea7c4e148edc": {"doc_hash": "19f962cd27253f2a7ea4139525046170de5942b4b6bd63948d71a884932a4177", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3103ed96-c9cf-4e27-9f0b-b253d5a1dc94": {"doc_hash": "c919ed73177d2e686c2d9fd3f26880bda5548f55c31d6143a221a2a2015232f6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f0d9448c-3ff0-4712-90a5-5fad151780c4": {"doc_hash": "01ef874c7ee4bedd8036d4fe794385e6ccc063e841f21658aa7e8ebf996611d1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "eeb60c27-6864-4a27-8bf2-8f2d857ba9ae": {"doc_hash": "c4d3f5118a726147f64a44aed66f17657c5eaf7d7c196106d17e7ad3ea024a00", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c7afa542-95d0-421b-bd0c-56e3954aad6a": {"doc_hash": "a6ccf01a00c3adae25ac853d88882d7b64936b6c0cde0e9798051d53ccd75df7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "11d94d92-0455-40a1-99ac-13c774d3355a": {"doc_hash": "11417dc76e6a6a4091e44c1de3b9ac875a9c6f87222e6c14652181987916eb96", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "41540f32-0ae6-4666-b963-634be7e46146": {"doc_hash": "e8137a0db6057487260f3b0d60c52cd2e82a85b670b179cae80e4424b093b7ea", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f6dea187-d1ab-40fe-8785-25acdf617b8d": {"doc_hash": "a9f97362c8d9f4fef407970d45212e9bb7b60e494fa4bc0283cbf2a3daf3bc60", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "144e7f35-12a9-446f-93da-e71c4e088046": {"doc_hash": "dc5676023a4c780889fb08b2506227b025f56a2fc49cbda8e6aefec52c9e74f6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8550c8e9-fd10-457b-a1b0-bd30e395d05d": {"doc_hash": "d5b9ead188aa957d53c28487fca0be1a9b7aa2958446d60f6340c76eb106edcc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "36ecde01-ba9b-4092-99be-c9577624eacb": {"doc_hash": "4e53a77b54ee8e828849ac8d0b28227c15f7c3d6fa02b4664edabcc8d5dbc146", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "24d7b725-95bb-431f-a966-3641b5ada72e": {"doc_hash": "edfb22834a546e27d2bd106c4345a0f040948b61540708d080e7cad866339303", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "339b4c76-d2dd-4929-ae07-ddd75afcf4bd": {"doc_hash": "64ad6e01bec688ec42fed333fa9ca77e3f68e66c1a682b96bc0e692a6e52f7d6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ef2b315b-f5e5-4764-9346-44401deaa9e6": {"doc_hash": "329c11a7fd5e2321ed084c10c843b0b10e7f77e56dd13d3690642ad65605af21", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "926d456f-2d6d-4932-be8f-22be58c213a9": {"doc_hash": "ac3c1f742d717b891e7c2a8a06103a877d4e6f71b1b8b9bd15c8b64f8667dd91", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d64b4e76-312b-4831-b984-b3408a12cea6": {"doc_hash": "b99824bbe7c8201f9ea8c89ba70a5f1d3c021d214cf2f4362ca3b5ef794de5b9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8a8a46e6-01fd-4ee0-8bab-6cb098725c9d": {"doc_hash": "6a8972033710004847fac1051cddcab12b7c453d099adebb9ac6c11b3ccf5f1e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d92d143b-ccbf-4462-9a95-3b9973b48b87": {"doc_hash": "c78c3ce7afe417844d0cecf861c604b83547efd0322e0c0bf95fdc98f719ff63", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2242af92-bb44-4207-807c-a9027e2c9585": {"doc_hash": "83808c8ba1412d021170c1934006b2cbaceed5c16eb1f947f9c9c7b3547dc8db", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0ccd42ad-3d3f-4b86-9a3d-787f313b20c2": {"doc_hash": "f7ec68c9e8afe4b37a186605b78589db2df0cfdb1e9366732ce5e60285b49be7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bcb6cf75-f2d2-4218-b9f8-71bc9ee53fcc": {"doc_hash": "62889d0f6cd692b7a4af1eb44c05d28f0453d035144fe9c646edcde034ded73a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "732acb59-a2ac-4a12-93bf-922b4ef5270c": {"doc_hash": "969cd85f33162c2b9d71fc397762e40efe1f5888ca44098a756b103ecaff465f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f439b10c-3b1e-43ea-ad96-ed2d44a0c3c8": {"doc_hash": "d1a0e8ccb0149ccd99943c047d111773019619e1c32a46cdb54e0867fd81b372", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "778bd68c-daa3-4cf3-8b51-766bac119c05": {"doc_hash": "3e5f850d03e2d5e92d57b24487232b01bb0ecac5b037af68c24748891e4a46db", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3bb5ad0a-fac3-48cd-b0ac-0451ddd824c2": {"doc_hash": "599a0294c2e4715f8eac4e9aca256a2b92174c4db8d05846f3911690e6cf52b0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6132fbc7-d4fa-45a1-958b-9d1c4a7ac645": {"doc_hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "df32954a-04ff-46cf-94e9-39fedc4845ad": {"doc_hash": "f7e9d8dcec7512dca2f82a1a3ec145fdfcfe75de52ce68f82922f748c7b05070", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ac2c8288-61dd-48d4-9ee2-e1880a4f0724": {"doc_hash": "b02988ef6f4c4558353324f01b022d4a2bbf7c20265b3b9dc95075b387066a75", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1270da3a-094f-4006-b59c-08a4892d32ee": {"doc_hash": "b0d81a90c4321e9e5bb024c8f7034fc17f42d2200b348ddc8d5fe3f73a48a5f1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0054ff19-4620-4fbc-8091-0abff10bcab1": {"doc_hash": "eb9bc42ede1c2e2cdfbe0fa2af4e70e4f932d94c30f5f9fde94203c8f991e475", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e10d4641-e92a-494e-ae7b-6f1ec7ad560b": {"doc_hash": "2faf84063737da66f7b3a657b14cbaeeb34f3053477e88ca7e256681986bca1b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9d15d05d-6121-40f1-ab35-1f843a840ee0": {"doc_hash": "b9caf13abb84ad164072ca97e857dfda44c94defaedd29332d1c720caeedf9aa", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d542a4a1-b4f2-4d74-a155-a44eeaee796d": {"doc_hash": "da58b73141274a1d6ec0e74ffb650db62ae95a409bcf2e710a4354f3af0b8137", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b648b065-f0df-4a40-b864-022526b37a0c": {"doc_hash": "cdc0236678f456942559f9a6b7a49add382387c1fff1aeb877df06b954973859", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "41c42bab-5810-41ff-9fbe-8709b36ff151": {"doc_hash": "4794a954cdd430f05bc0274e63e8f02c5226aa902e6011ffb03379fa09378cd4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a299e07c-d0ff-41bf-83cd-195bf2c73ddd": {"doc_hash": "876724f0067f8e5ee94e59cb982f31a46073e2875234effcf702fb15bef9c824", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "66b23811-3342-4c37-b6bc-fc6655ba2ecd": {"doc_hash": "78b7794d4832e61cb43bf9d9f9561fad7b5997187836292e3d36558ad4cc8e7f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "286d4f42-1413-44f5-91e0-b955d067f53c": {"doc_hash": "3bdc268af92c2b05d4fa98faa9f82fd3fde99c6e63ec95c3c7c04bb4b88caaee", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "085cda97-eded-4233-aecd-96744be432c4": {"doc_hash": "8fdc1277ccf8c758da4a768a43d249b092d6eda86f226d5d538e2d82a791439d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e58933d3-afb0-463a-8a67-f0f7cd95ab59": {"doc_hash": "6fe16fe0b3b9eb25aa56cf9031daae88789342ce0d6e5c715a4f027195d5ff36", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9beea8fc-0965-4aca-8f16-d0d0fed58602": {"doc_hash": "04662661afa3ad11b2f4f0d0a2a46fb62bfbacdc0eeaa5896f3ba22ecb8bce4f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d778fa72-34b2-4eea-9e9e-080da81f538e": {"doc_hash": "b235ea683fd164b5b509138430c78affde70b1b96eaa37ace0ef0aec5a7f8908", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "18ddd055-d736-471f-8e9f-1fa061893ddf": {"doc_hash": "1754b6017a6a02d29f4a03f6d8301e0754ac8e447267f5f452951e112c1c99fc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4b5f1d69-b790-4686-8a2d-2e5081daf461": {"doc_hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3c7c31fd-7bf5-464e-bf47-42024ac494c7": {"doc_hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "eb70804b-2a0f-4d5d-947e-2e284b97a90e": {"doc_hash": "9ec100e9137f487f6fb0ca6cd29d07140ea7535d4aefac208bb40325f8262af7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "36a946af-4b99-4ff2-b58d-f61b55d087e4": {"doc_hash": "712717584dc1cad6affaada21a8ee27035aa3910d15c5b1637508f3500a17156", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "be7ee631-fb27-4901-947b-b325fbcb59cd": {"doc_hash": "f70115f0256f299cf3a54ea497857cf8b1ea5f391b18e50c063ab9aee435ce9e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d7fa810e-a159-4df5-8cc0-b2e0f3a40cac": {"doc_hash": "b1967fe32c93a3f9f17cfd687f1042524b847fc01c200b0977d2ae29fec5f7af", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "41ad974d-bf03-4445-8cb0-e22fb0095360": {"doc_hash": "fdb4260c3e62967a8f0b5dfd61d90113ab044b8c89f4a76a08650ad2a2650b4e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c2549741-0810-455b-8770-30048844b9b2": {"doc_hash": "237aa0c62a167aae7f5c55eb59c95781ba01dfea4d5b370cac1ad5855d7ee5d6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0ec52283-91d0-4f75-a040-2e9e507e4c5f": {"doc_hash": "520e6df8e215200d9047c4dcdcdb65786ea0de090a0d25212e2330012aaa4897", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "49935200-0531-4650-aa00-97cf76483a78": {"doc_hash": "4ff80fad36417596e4631fc6aca91b55af386c741c8f954be0a877fd033ee4f4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d21e7529-693e-484e-8246-2611c2e54a50": {"doc_hash": "de4c8aef74243cacd2d995782541b6f1d93873fa38a5b002f92774fd8aae4c7a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "89ed93e3-813e-4abb-9c87-c749b2e4a427": {"doc_hash": "6f0885b565e8e5cbba43db26ac9c279278e692d78f285b94a29f48d74c664d72", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "40433071-83e9-4793-a71a-9185fde18a16": {"doc_hash": "ec93af5e770e227bde224aa29f09d11de4d831bfc03ce0da6513e3a0339b2c16", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "668ae3d0-60a9-4bd8-aca5-1c07db435bba": {"doc_hash": "b977490a5edf3febf606f84dd7ec9f4388c891eaf435d8b0eb34282c13bca45c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e14ae856-39fc-47b4-95df-90f9b12ec9e1": {"doc_hash": "c9de5ee4c59f098a34324a4861609c0081c31608863c7f66c9fe20fc7dba5ec2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f19f2877-7b3c-4649-8670-80a7125c9f13": {"doc_hash": "dc65df04b4b0da51cfd1250d1d3bc581e475aeeec40956a68fdf30f1eb0db8b3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9c70af8e-8005-420e-86e3-b5b1a05056ff": {"doc_hash": "094f5f5fe3e61cf7a43306de2bd724c153c1fd82d36e79d78e34f5bf571902e6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "32b52772-c87d-44b7-b26b-bd304a448f62": {"doc_hash": "49234b89091676bc8d7725197db28a705b5e1a1ca1628338997fb89e6a914185", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c7443d33-d878-4b74-8a32-920171f26844": {"doc_hash": "c4319e6ace791be9fab4488dd7aa6092e9ed2865918fc9bf85d0ab40ee00dcdf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2c37c76a-9ec5-4ce0-843e-fddd965e5ca7": {"doc_hash": "eae1c7ea9d2520b189c50dc97a6bb716d10cb5d0384a1d64cb4eb52d477c76f1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "016e716e-d121-422f-8d45-48233f6b8769": {"doc_hash": "1520fbb8001424d80d4be0511b723caedfab1e76110a94f2307f4d8a4235ff87", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8cdca243-2939-4fcd-8b27-9f82fd1ea045": {"doc_hash": "7cb079561b9595c84f366b2841a778ceb2f8760cd96c8ad5d8d3f8c763d97f20", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0b656cb2-4d3d-4a95-a705-e6e29bda12d0": {"doc_hash": "f5f1b79b36cde8dc264706cf88cdbf4a063b970ce17a2b25a8fad9f891ed7d40", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bc4ca96c-758b-4816-830e-c30ed5de9340": {"doc_hash": "cc57e25eed17ffcb3a86beb5191111265c5693d463a66f5053edc07ebdaf5dcd", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "47532ce1-e3d7-444d-9685-9e5a8b7d3f83": {"doc_hash": "aedf8ead2d08d9d9258e280e35e42271f7ff0a01745b4153eed5123f8b948c13", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "eb36cdcb-67b4-42a3-b8d0-51145d5438ef": {"doc_hash": "d37c714072f0ff1bba1ae8cd304ba9ba89cc6968e61eef1d1556dfc2fb19b24b", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4e19a358-74fd-4fc5-9c6d-269a181be261": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f60e269e-b019-4b20-8208-9b0505915eb4": {"doc_hash": "cfb1ab1f852095280005011f0e31b36b8bf1ae24f1731588b2916bb7754a871e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b67a7c17-88cc-437f-aebb-2d98cabbc956": {"doc_hash": "3be103ba54b43510033d286fac3894b8cff51735ca627fabe83f1f7259339152", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "821d00ce-3ffb-4a6b-b5e4-d4328e55ab9d": {"doc_hash": "663af597180a96119b3e166e212745b3df1b549b902dc54978a91a70919a696f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a025ee01-765a-4fe7-b987-70773f892c75": {"doc_hash": "628fee9eeac2652f0e3d51e1a1d04d8efc5f33b14784075ac71d515145e0401a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "80b64f2e-cc2c-485c-a303-99c05e29be66": {"doc_hash": "6c9422041a1a16c6671ccc50b5df455ce4a26e444efbda7d632c230607b943c6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "34f167fc-3499-4134-acba-1988337f4014": {"doc_hash": "a84f01eaaad1980ba17345264e7c554fa5ae259b8e25c38cf7488e13762a332c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8948b952-3e7c-4e3c-990b-821406c6ba8d": {"doc_hash": "c476dabc8ab6294be6190aa8d0ee3713d3f607eb24b110de615a32e679ecfa3d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f5e04ee3-8481-4d7b-9b84-4cd8a4615601": {"doc_hash": "4478fed26e581e48ff49f14d4748d3485df536270592ebc184d52e10b12c3d70", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "003ce0ec-b725-45ec-969c-7dc9ac2945dc": {"doc_hash": "4664edb799eb32e1ad2c625e5284af0ceffad28a2d15423bb4b8946f2696191d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a56689fe-cb60-48f5-9974-2b31636bfb4e": {"doc_hash": "9cab8dc571715a53c852ecfbfd1f371e50b635c42fd3c18f25f2cae0986b2b52", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0133695e-aa59-4eae-b537-737685d8e209": {"doc_hash": "4d3e68bca90ddaf8c09462831b3a76341205036ed73f7ae3fed29e9afa7e3224", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6387dec4-f4ab-4dda-86a5-23ebe90b7283": {"doc_hash": "245f15fa6efb799d0399961fcd9d2e2b126a9d4d67df6dc7031bc9dab2451a54", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "61599069-a903-44ea-a6ea-42cdfbe2a107": {"doc_hash": "e2c68395e1d3bce76e502a5884191e48d67e5681d74e925a188502405902d958", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8d6e6d5b-cc78-4dcf-ba37-6427ebcaa824": {"doc_hash": "17e5a6256d7b7f241dabf9c5888a696408ddade62c93267b169c432274321880", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4009c188-a9f7-4a4c-a539-88c403736979": {"doc_hash": "19d7803d4e92a1c49038c0fa16784713e36af8d7b027305291b204e2751e5721", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4d98686a-7ef4-4ae6-9679-a7b953702686": {"doc_hash": "02654bbc9b21b836094ff408227b04df1ba53fab12df334b2fb2699f753dcd56", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bd65e785-b470-4072-a8d9-190ef2b55db4": {"doc_hash": "b64fb74b1a7074724578cf3b52ac8de8f32ce3acf8e6b232685f789127540ab6", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3ba13b95-dee9-42f1-b93e-668a642afad5": {"doc_hash": "b101565de032ed58ebfbbae890574ecd6e4c08df3ee814f716a403ebb9bc2b60", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "79052100-532a-4b26-9577-17897bf09126": {"doc_hash": "dc39eafef4ccb98ca9afcbaffffdd728b87035f1b5aebfc84eca225c8d9c7626", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d7c22f2e-5c90-463d-9074-d050017b3afa": {"doc_hash": "75944f91bc00fe8df8ccb9a7bc7a24fc6404fca126883353d794516d0625a920", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "cd5e0a38-7c94-4362-9fcd-a49b6ef3be69": {"doc_hash": "5f95dee6f3fc74f1eb7de33dc7df3515de30a267ecc242f3a4748d437ee18352", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ad40ef08-fe7f-440f-ad47-6a9e7999266e": {"doc_hash": "a1b6faa6f1780401dfbf43a41296ae2c9df826d4fbdacc12c54262707e2cab4d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "9bd9e65a-9730-42a5-81ce-f0f08ba0d537": {"doc_hash": "e3c502311d5d164ce82240673a0ce2afd4e8e34d891372449163a581826b5998", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "31097176-a6bb-48e9-b7c4-080c23e41a19": {"doc_hash": "937c8852282fd0cd963683da47806d8d9c3289c7c30199529ac921ad46e1b2f4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d0967524-b167-4853-895c-f7ff2187318f": {"doc_hash": "9d59165d0ba84584fbbb332d43dd5371e2c4693fe270d1825896052f4927f361", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "f405114b-0c09-41b4-a745-c4caeb18244e": {"doc_hash": "aa2e4f5060c54eb6aee99c9ec55433a39745b98c2a79293af409eb5a605028da", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c6209543-41b5-4916-924e-4bef4e71bb49": {"doc_hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "6e831f2d-ccd0-4d5c-a6df-7d6606a8b5ac": {"doc_hash": "c572cab48c5c772689d1c71866ce65252ac6cdf2ec96f8fcbd4c7c37fd6e56e4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8af56677-6a79-412d-9a9c-98456dbf9933": {"doc_hash": "ee326d0220abbd6886d5475e394780d138c3ac21e94f1d117a28364616e62d19", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "057900af-1e3c-4afe-b627-4ac8660d9ddb": {"doc_hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7ad35477-1f37-4b3b-8220-c27b99cdf6ed": {"doc_hash": "7f864011ca2abed74a63be9291179ecc648825bd5a9141b2d71a88e286a7fbeb", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3e7feb7b-06a7-47c9-aa1f-d8f8e62aa6b6": {"doc_hash": "9b21a54c65a40dca2743e4efc2f6f05d4faad0cdfd77f2591a49161cf9f2c96c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "86bc81b4-9486-4f9f-92da-607f8b0a168d": {"doc_hash": "aa31f22de3377344bcf7684a12bf232bff241f46a665b3c36ebe9276b4cebf59", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "59275517-0fdc-4ef0-8bf2-22def175c743": {"doc_hash": "c64755992237cf053f479c9a28344970b59dcb634c004f99564860ea797f8390", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8b85a21f-58c7-4e0f-8bcd-9fc4dfcf4aed": {"doc_hash": "8547aac6d5ccba064a4fe45a620ff26737c97977ed6b332d8772c8b10b8e7279", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "10c1a307-f21a-40c1-a459-65f1d06d9c41": {"doc_hash": "92737c1ad3978baf1e18470d893a7110e585475fece5a7193b786e86312082ad", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "2eb93384-2b05-4da1-b53b-4e73d02573d0": {"doc_hash": "4f81e5e3e2ce89cc469a82f00c3782ed839727270b19e2d72dc599461ebf71da", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "83806ec3-73c2-4e87-aacc-517c3ab16877": {"doc_hash": "682495d85b155541a1da3d39d03dbb4cf98bb018ee385bcd6358b5a2e241c0be", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d5008c32-f6b9-49cd-96b3-9c2d7cf4aab2": {"doc_hash": "d9076c956840ca00c15564250e61bc2b69b45d4393e8407420d04332ceb86eb9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8fbc366c-bc39-4f97-b859-33a79e7fd685": {"doc_hash": "81226f8affeb9de5cf0526f969138cda58ccea3a8db94fbe4def8f09714dd632", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a411b52b-bb58-4382-870e-217bcb5b81fa": {"doc_hash": "e7482d764881734d5d751dadc6539e681ff580448d63d9b9e6fc077b636abaa8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0ddea6a0-05e2-4e12-afd3-85e6ce38e757": {"doc_hash": "a8e8ce4dad57f94e25bd2abab1fa3f4334d425b189565cac5a5f710e6e64d6c5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4397cb9a-e019-4716-a1d0-428e8e4e65c8": {"doc_hash": "03dd9ad89da3909cbe8ff47d28cc4c12465518b70dd97ad99a292c19ca9cf1e4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0d7e4190-fbbe-49cf-b68b-0bef30ca18e6": {"doc_hash": "e300fc5f9ce90594e6550d6922fc4d856abfccf8f445b5b716c2556c21be1573", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "10e30a37-a5d2-4d63-9bed-5b23c4c2b229": {"doc_hash": "1ff59c6a4f3423fae6daf08f5adcd4a678a81a971d5f7ed2436a94d8fdb548cd", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "61d4ac09-1616-4ef6-9da4-bc667b80fc36": {"doc_hash": "e9ecb12431527e7f50bc2370d31d88feab8a8adcfc6e79c7af5b7611b31b3a24", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c6dcb669-6062-4697-b33c-a6dc178c6209": {"doc_hash": "4a148e137b6e61602e4114cf17cad834c02eaf2e94f83912caf69bdafdc34e8e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5b90fe03-22d6-4391-abba-e5b2ba3160c2": {"doc_hash": "9377239efe936d1e99f0580cfbebb693d7147130c5e446c49ee30d484700883f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0ee1a5e4-982a-4375-a2cf-a37e7f76522a": {"doc_hash": "b3117893aa8f8ad37d80331614e1f52c4334e4001de79ec17426767fd6d68f97", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "77c0091a-2c76-41f0-86f9-52936a868e64": {"doc_hash": "2e1aa23100fa28ed191e06f85a3c963ce5512858b773b039c09788b5e55fe000", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "205c0f5c-4b3c-4c07-87bb-67b32a5395f4": {"doc_hash": "e3f826d1bc3f97276f8b6c466b4ece6ce4e8513f88df33d8f24d174df2b8bd93", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "74e8ad44-9342-4678-bc38-f414260e273f": {"doc_hash": "ba11988e06a314516dc62c3225b2cd74676cd9eb55657f3194475abf2f499d22", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b1b7f387-444d-4da5-bf75-b81db50a6899": {"doc_hash": "ce9046d01c231123e244039d8058a6cf37f23943fe29d8f8947dfbc42154b81c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d207d505-8b33-4e1a-a4c8-e5eff83267a3": {"doc_hash": "f1267097af7f6c5f9a83417084c1b7e518afa9f8a47e01b323da91b55c9bff64", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7d60c778-b27b-48f5-aa33-542d52f91a53": {"doc_hash": "c727d2cd285c0abdbe220dfa7ba6f70f652592f16328050a16c7a8ffae969c9c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "ada38f8e-2e9a-472a-ba94-d5ed986e9a91": {"doc_hash": "f33bddc19ec892452fe6e36e56e37812412a10e76a4475879a25f16ec7d05d72", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "46428e41-91c4-4931-bd20-898cf1a558bf": {"doc_hash": "90ab486e095f1953bf73c17886286bcc92f778713420b9ebb7923f062958e2d1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d99e1ddb-7207-4abe-b602-8915661659c4": {"doc_hash": "9fd81b1439174a6bc90081d52d9066e40f11e3acf861997a0a918ef9b813cdba", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7e3a7263-28f4-4c21-9c51-651f8232d09b": {"doc_hash": "f979b15ce6e9bdb17629bc287609ef6cc222dcc24976e3dbc1a09113aac91dfe", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fca0d17e-7caf-4884-ac2f-26f79e5968f1": {"doc_hash": "14000368f0b85340560af0d71d1d572b8d4df429b80553bd36479bd97e33ac25", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7c3ed4ce-6902-4813-bc31-154fedb8b376": {"doc_hash": "79fed37ca5b3e7d7684d4f1f1c91e4d1d67af586721b7c8874d411afdf53ee01", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "378fdc45-0a08-4097-b1a4-4fd1e6fab40a": {"doc_hash": "9d42084c2234bf1ad49fcaefe26817788a7045fc6bd99daece83c09d6b22f9c9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "a7385932-f9f8-4246-ad2e-00e0d61daa3d": {"doc_hash": "4e16fb5ce729aeaf3625b216ebb89a4445121e72f05e2e274502a066ea91f4d5", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "37c6f2cb-2d49-42fa-b405-f66a5eb41b4c": {"doc_hash": "4ce786ec31347ff454348b07a1a9be523fbd91e558d5043bf2daffc839cfc08e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d4c75c62-5f3a-487b-a71a-b750c850a13c": {"doc_hash": "adaa13d8f265638c8a3cc48e29f7c46372c83274ec5ef4b78eee3dfd7e88a1f8", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "abfc6c53-f39f-4fdb-97cf-9b3f9b04e4d6": {"doc_hash": "752aa588f163754efeb665347bb069b0808b11e4ea485dae1b5298b8d3be37c1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8fe18b2f-456f-4631-aa68-2f1e23205720": {"doc_hash": "1b3b9be60ef4612610424ae4c326b5b379f6f2dd3888d4c1b59c55f1da7739f9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d1ebddad-ddda-4fc3-8cc0-11b8e67229c1": {"doc_hash": "001360b22d8e3c03e22f8fd7d326fd6744880726cb5290a64ace3455d909c368", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "868fe20c-5c21-4961-940a-94d6a66684ad": {"doc_hash": "f13ae490fec51da5c3544f912fed786bd5a66c58cd9aceecc727a8802f0fee8e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1f63d707-276c-4af6-a184-21f04b083759": {"doc_hash": "6a37fb29b741c92fe9de591de5cafd7373eb0f04dddd3cb30cdd6e4c1abc760d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "b7a06f9e-19e5-486a-b8cc-d20ffc6c7fab": {"doc_hash": "5ce2db8d5024add74b12fd56481f60f1726ef152a0740b2640f92c8d06f79093", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5a1b7b22-b773-4b0d-9077-9a09c567e1f1": {"doc_hash": "bcd948f7aef699d0af2fc601e2bd8cc66b0ce0238e8e1b53fff9c3d36324f9f4", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "94088853-bfbe-4607-942e-bf3e30f4a65a": {"doc_hash": "5d5b1658e95b6d8c02464576788051dc2680583045540ceb8ad0839f36f91369", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0f42971d-cb97-4a6b-a41a-dedff4405a2c": {"doc_hash": "5f27c8d95b0e6b772043750344549b81e5a1094880e818a6fde0ad5c68dbcfe2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0ac6a687-10e9-424b-bbc8-320416230ee0": {"doc_hash": "c8f28045512fa038b542f778bdef718d51347be89ad1bbfedbc8482e38d2f696", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "86527023-a577-4b37-857b-2b01c4341e91": {"doc_hash": "dc19b11e1b20db06c45418426c00b5552e04b7599bc691c872b449db0b2215b9", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "54312aa7-044a-45c9-9bef-7f9448d4c8f8": {"doc_hash": "76605558a9deedce0259f2417afe968c811254cb41458d346e57aa35a00e4519", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5f0686fe-7120-4088-9600-1b848170ced6": {"doc_hash": "9b43f56a8849dde80fc18d8845a062c2e419ef33af77d99fbfc6fcdd183a64d7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "41a84c3c-194e-4521-8cc3-4dff3a796248": {"doc_hash": "c6f010cf3195243f9ed45992ca5ce07e52c17d5995fd8cd7cbb527fdb646770a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "20df0bce-3140-4cd5-9034-e5782dc668e5": {"doc_hash": "005ceeebc64939ade63c127b182aaeb6566cf38b2dd67d1e5963687ea4377829", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "37c3e884-8e26-4a06-a55a-c6d552852c60": {"doc_hash": "89ad07fa0fc275814ef88d450ffc35ac88b599bec03744e9eb732f2de729a60c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d5b7b230-699e-45ca-ade8-54ef50c52135": {"doc_hash": "5c884f715a29ffcf06b2c48f98c8e20b01bf40705c0d89d4f48e0298a1ec26ea", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "657e15f9-32ae-4dcf-9af6-f18dc5e6290f": {"doc_hash": "41ee993c3399ce53d1525174388d940d1fdf65b8b4eae3f8cd03cdbf177a5520", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "135007c4-1491-4d85-b67b-aad08d78a014": {"doc_hash": "5c793f7c9eceb10ab0deb5281fedd3ca7adee15cad3300b1e110ce5a554bedf1", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "45be72a1-9844-4a61-83c7-b8f62b3b7fce": {"doc_hash": "a1527a2107f213758a35b6d3a30ceae6a01d829babf568d5b8a2d0a4a4d006d0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "4496f13d-01c2-424f-ada4-2402684b397c": {"doc_hash": "75913c94d4a582b4a7e06469c943fb524c02570858703853145fd3c2910fcc1c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5f3c9b8e-d4ec-40d7-a96a-ae88e8fba960": {"doc_hash": "6bc6a20950722d78b552ac174abc9fbfd8dd20491c1518b2857a0e0cdc8fbf2f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "7dd014dd-2c69-46b4-8de1-edb7ea78758c": {"doc_hash": "028f8c9d60f8cde710c2bcaad14a7208d19214f5334312a5dd336e1fe16a5b2c", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bbc42688-7a29-4884-9335-5916d9b8809d": {"doc_hash": "d7be0b52d6455369a353379c1d4cf38774c141f9a5749b373b47736e2620c82e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "8260d82b-7803-4b19-b09e-991bf6eb32b4": {"doc_hash": "4be3058a898a7333048e0777677e4ecfc383f83a46e07d3a8802495297d71146", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "bc4880ab-e6d7-48e4-8815-5d1517ffd9e6": {"doc_hash": "c351be24d701fa89d8001797ba056e52d98290dbc35f977804e9a0d45f64138d", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5758d178-bfae-4561-94a3-01142a9ac845": {"doc_hash": "66d33352950e6c0d46bf18eebee7895a5b08fe252205f8cfea69653d0abf29b2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "934d37e6-d4df-4a02-91e0-e563e477b146": {"doc_hash": "7551886360bcb57219e48bb1cfc004e1a1038c1e251ef64bada1d50f073177d2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "81ab4f59-1ea0-42df-ba57-edfbce96af8c": {"doc_hash": "52c5193f108dcab428ca3875e41d551d1f69a4e1041d11c2c187d262817e9a3a", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "e056924c-4bad-48d7-993e-71c8abaad9f7": {"doc_hash": "d35ec3a9f714705d7c60c8dce02a6abfcfc4b8277468ac2e321e70216847cec2", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3de7c9ba-d537-4ae8-bfaa-8c36c823645d": {"doc_hash": "529d9dca4509b1460abb387077a325fa3f8e51870e6610b5b9976bdae776c440", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "543cc845-65c0-4f36-976f-8874379558f5": {"doc_hash": "a3e70a55fdfe6ecd8981ab355904a1dd324063c72783480f9d907428690e7fe0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "d90418e2-eb02-495c-9831-ce5fb5345745": {"doc_hash": "977fdc3f47be50883e6c9e7f66c3a780e61aafdd3f5df1527754ee49a44cd5a0", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5ef1c983-f163-4f76-b56d-102b4cd2acbc": {"doc_hash": "f0fec05f3729a862ae4ffde34d5873104a06fbf531d34a55681181e7b3296bcf", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0b30b3ae-f213-42b3-b748-faa04ab06321": {"doc_hash": "fa51cda505fa1f07751378d6e668c1af90a9af408397624abb849cf3839e8abc", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "3a72d28d-202c-4423-9e52-805161ab2254": {"doc_hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "65f8b72e-041e-4a38-aabe-46781ddf6433": {"doc_hash": "c597cf8d8eb3ba32113a88d0113eef41e481a8664dfac68263a60fd2f7efe2d7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "5b50cd93-a97e-4f11-9666-d949a199c344": {"doc_hash": "331fb33155ea7353641f88083e5c234bb6a31e6322d9c3bd7cf807211dc9f2d7", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "99ef7dfc-d0a6-474f-8734-a6fada38b9eb": {"doc_hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "c3619c96-f3a0-4b4f-ba03-1c778d4fc32f": {"doc_hash": "4709f7f0e221636ac0b6c38a22ab2b28df0192176a598807ae341f1a3b348125", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "dc8b0b8f-094f-4b46-a119-a208e768161d": {"doc_hash": "a1df4cdea06246322234fe44bdf25c7e1d83a3bbe0ea6dbaa937e4f9c4b12f7f", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "fc9254bd-5a22-449a-9b26-14d19ad0eb34": {"doc_hash": "db3965551b39f16ffd01941f149d38e0deceda396fadf9f56603eb238c6f8220", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "23894e40-7abd-40ad-9130-26f1a4da2733": {"doc_hash": "a72d085feea5982cf88e4277f61d9df363d8f1fe82408338c8b3ab0507b5a401", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "43cf5c8c-54b6-493b-8110-fbe582fb0bbe": {"doc_hash": "c13f960147f8d10441401fe425a54fd478d301222a84b88df8b0832ec842bac3", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "eceeb8d3-1590-4457-8134-e3fa44120cf4": {"doc_hash": "6495019f065f70289fec47a67cfcc8fd16d80fa93b779edae7b7af2c83fe7f44", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "0971720b-a10f-4309-9d43-4b5f71952244": {"doc_hash": "80ea2e6c491f48a81650265b0dab88d7f35a24d69e7d0871c626b63edb738d5e", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}, "1437fbb7-9acb-4554-84bd-cc80d45c722c": {"doc_hash": "e02cdcdd660abc69207166afef7896d8fa4a4c071fe0e7a6e1d0e41c9db8c0eb", "ref_doc_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1"}}, "docstore/data": {"fbf1ada9-b5fa-4bdb-9909-137b8f28e1e8": {"__data__": {"id_": "fbf1ada9-b5fa-4bdb-9909-137b8f28e1e8", "embedding": null, "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. ", "original_text": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c6c1b0f-c818-44af-a4d5-6797baed1e72", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. ", "original_text": "Good morning. "}, "hash": "a9ec6141d40a4e2f35928ba4044abb0d29c3384bef8612c95082e28331fec340", "class_name": "RelatedNodeInfo"}}, "hash": "5e1823792e4ab2cf160fab242d13769fe8de66833b09aad83979e3168b919ab9", "text": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay. ", "start_char_idx": 0, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c6c1b0f-c818-44af-a4d5-6797baed1e72": {"__data__": {"id_": "1c6c1b0f-c818-44af-a4d5-6797baed1e72", "embedding": null, "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. ", "original_text": "Good morning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbf1ada9-b5fa-4bdb-9909-137b8f28e1e8", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. ", "original_text": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay. "}, "hash": "5e1823792e4ab2cf160fab242d13769fe8de66833b09aad83979e3168b919ab9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d69b7e17-ac48-40dd-8d20-6b2425044f2c", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class. ", "original_text": "Welcome to CS229, the machine \nlearning class. "}, "hash": "8e33deb0d805b4eee03b1e3fa8dd3465ad5276ceb1a91db57752b059b12d1520", "class_name": "RelatedNodeInfo"}}, "hash": "a9ec6141d40a4e2f35928ba4044abb0d29c3384bef8612c95082e28331fec340", "text": "Good morning. ", "start_char_idx": 59, "end_char_idx": 73, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d69b7e17-ac48-40dd-8d20-6b2425044f2c": {"__data__": {"id_": "d69b7e17-ac48-40dd-8d20-6b2425044f2c", "embedding": null, "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class. ", "original_text": "Welcome to CS229, the machine \nlearning class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c6c1b0f-c818-44af-a4d5-6797baed1e72", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. ", "original_text": "Good morning. "}, "hash": "a9ec6141d40a4e2f35928ba4044abb0d29c3384bef8612c95082e28331fec340", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73cc978a-73e4-4fd9-96a5-cef57959dc0e", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n", "original_text": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n"}, "hash": "a5f30bd904b0f38ee53318bf75ed642e4b2bae91f30502961e9ffa1785862efe", "class_name": "RelatedNodeInfo"}}, "hash": "8e33deb0d805b4eee03b1e3fa8dd3465ad5276ceb1a91db57752b059b12d1520", "text": "Welcome to CS229, the machine \nlearning class. ", "start_char_idx": 73, "end_char_idx": 120, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73cc978a-73e4-4fd9-96a5-cef57959dc0e": {"__data__": {"id_": "73cc978a-73e4-4fd9-96a5-cef57959dc0e", "embedding": null, "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n", "original_text": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d69b7e17-ac48-40dd-8d20-6b2425044f2c", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class. ", "original_text": "Welcome to CS229, the machine \nlearning class. "}, "hash": "8e33deb0d805b4eee03b1e3fa8dd3465ad5276ceb1a91db57752b059b12d1520", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46176f33-de2a-41e4-9b60-ab672142c89e", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. ", "original_text": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. "}, "hash": "f7844a41d9051ea7701979f5d148ecfa6a039f54e3794e4a4af94afeac02dea7", "class_name": "RelatedNodeInfo"}}, "hash": "a5f30bd904b0f38ee53318bf75ed642e4b2bae91f30502961e9ffa1785862efe", "text": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n", "start_char_idx": 120, "end_char_idx": 276, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "46176f33-de2a-41e4-9b60-ab672142c89e": {"__data__": {"id_": "46176f33-de2a-41e4-9b60-ab672142c89e", "embedding": null, "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. ", "original_text": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73cc978a-73e4-4fd9-96a5-cef57959dc0e", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n", "original_text": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n"}, "hash": "a5f30bd904b0f38ee53318bf75ed642e4b2bae91f30502961e9ffa1785862efe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "48ddae5c-ce38-4210-9ce0-2dce0b585376", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.  ", "original_text": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. "}, "hash": "e964bf187f8d4d7f2c848e537a9cf3fbbc7e785fd9f2344d67a7426f8b076a29", "class_name": "RelatedNodeInfo"}}, "hash": "f7844a41d9051ea7701979f5d148ecfa6a039f54e3794e4a4af94afeac02dea7", "text": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. ", "start_char_idx": 276, "end_char_idx": 361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48ddae5c-ce38-4210-9ce0-2dce0b585376": {"__data__": {"id_": "48ddae5c-ce38-4210-9ce0-2dce0b585376", "embedding": null, "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.  ", "original_text": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46176f33-de2a-41e4-9b60-ab672142c89e", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. ", "original_text": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. "}, "hash": "f7844a41d9051ea7701979f5d148ecfa6a039f54e3794e4a4af94afeac02dea7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "14182cd4-0589-4368-83ab-3cc5841caec0", "node_type": "1", "metadata": {"window": "Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. ", "original_text": "So I'm actually always excited about  teaching this class. "}, "hash": "ff3f2ce1766d6dda49efb44719a5a66a7957454ad50b1445838547cd97f69686", "class_name": "RelatedNodeInfo"}}, "hash": "e964bf187f8d4d7f2c848e537a9cf3fbbc7e785fd9f2344d67a7426f8b076a29", "text": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. ", "start_char_idx": 361, "end_char_idx": 558, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "14182cd4-0589-4368-83ab-3cc5841caec0": {"__data__": {"id_": "14182cd4-0589-4368-83ab-3cc5841caec0", "embedding": null, "metadata": {"window": "Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. ", "original_text": "So I'm actually always excited about  teaching this class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "48ddae5c-ce38-4210-9ce0-2dce0b585376", "node_type": "1", "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.  ", "original_text": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences. "}, "hash": "e964bf187f8d4d7f2c848e537a9cf3fbbc7e785fd9f2344d67a7426f8b076a29", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77fafd39-1cfc-4f58-9e2f-b84f19e2d8bb", "node_type": "1", "metadata": {"window": "Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. ", "original_text": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n"}, "hash": "ccd6fdf26660523d98dc8bf95f2edf10e6ee2b2b0a53ebfe98fd571677a0be3d", "class_name": "RelatedNodeInfo"}}, "hash": "ff3f2ce1766d6dda49efb44719a5a66a7957454ad50b1445838547cd97f69686", "text": "So I'm actually always excited about  teaching this class. ", "start_char_idx": 558, "end_char_idx": 617, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77fafd39-1cfc-4f58-9e2f-b84f19e2d8bb": {"__data__": {"id_": "77fafd39-1cfc-4f58-9e2f-b84f19e2d8bb", "embedding": null, "metadata": {"window": "Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. ", "original_text": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "14182cd4-0589-4368-83ab-3cc5841caec0", "node_type": "1", "metadata": {"window": "Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. ", "original_text": "So I'm actually always excited about  teaching this class. "}, "hash": "ff3f2ce1766d6dda49efb44719a5a66a7957454ad50b1445838547cd97f69686", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d39027f7-8f6c-4991-a104-f6cde2aa6d58", "node_type": "1", "metadata": {"window": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. ", "original_text": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. "}, "hash": "28b02882a2ff5d1a9f2de0f9acde8ae0656a592b1ffc3653394d6c3c280837af", "class_name": "RelatedNodeInfo"}}, "hash": "ccd6fdf26660523d98dc8bf95f2edf10e6ee2b2b0a53ebfe98fd571677a0be3d", "text": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n", "start_char_idx": 617, "end_char_idx": 813, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d39027f7-8f6c-4991-a104-f6cde2aa6d58": {"__data__": {"id_": "d39027f7-8f6c-4991-a104-f6cde2aa6d58", "embedding": null, "metadata": {"window": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. ", "original_text": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77fafd39-1cfc-4f58-9e2f-b84f19e2d8bb", "node_type": "1", "metadata": {"window": "Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. ", "original_text": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n"}, "hash": "ccd6fdf26660523d98dc8bf95f2edf10e6ee2b2b0a53ebfe98fd571677a0be3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89d47952-5df5-4ca4-bd99-eb2669de5e21", "node_type": "1", "metadata": {"window": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n", "original_text": "Paul Baumstarck \nworks in machine learning and computer vision.  "}, "hash": "53e47e9684ff26192f1efb450cf1d0f03a83c178e57ed782122a9fde67488ca1", "class_name": "RelatedNodeInfo"}}, "hash": "28b02882a2ff5d1a9f2de0f9acde8ae0656a592b1ffc3653394d6c3c280837af", "text": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. ", "start_char_idx": 813, "end_char_idx": 970, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89d47952-5df5-4ca4-bd99-eb2669de5e21": {"__data__": {"id_": "89d47952-5df5-4ca4-bd99-eb2669de5e21", "embedding": null, "metadata": {"window": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n", "original_text": "Paul Baumstarck \nworks in machine learning and computer vision.  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d39027f7-8f6c-4991-a104-f6cde2aa6d58", "node_type": "1", "metadata": {"window": "So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. ", "original_text": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning. "}, "hash": "28b02882a2ff5d1a9f2de0f9acde8ae0656a592b1ffc3653394d6c3c280837af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba08fbda-b05f-4fb2-b051-bb8c5d9f2852", "node_type": "1", "metadata": {"window": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. ", "original_text": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. "}, "hash": "f154e982a3fa0d0a48f20ca39228d8e8442edf9665e363a8d148a13891e57f86", "class_name": "RelatedNodeInfo"}}, "hash": "53e47e9684ff26192f1efb450cf1d0f03a83c178e57ed782122a9fde67488ca1", "text": "Paul Baumstarck \nworks in machine learning and computer vision.  ", "start_char_idx": 970, "end_char_idx": 1035, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba08fbda-b05f-4fb2-b051-bb8c5d9f2852": {"__data__": {"id_": "ba08fbda-b05f-4fb2-b051-bb8c5d9f2852", "embedding": null, "metadata": {"window": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. ", "original_text": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89d47952-5df5-4ca4-bd99-eb2669de5e21", "node_type": "1", "metadata": {"window": "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class.  And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n", "original_text": "Paul Baumstarck \nworks in machine learning and computer vision.  "}, "hash": "53e47e9684ff26192f1efb450cf1d0f03a83c178e57ed782122a9fde67488ca1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1557720e-3684-46ef-95bc-79b8c00fa8f8", "node_type": "1", "metadata": {"window": "So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n", "original_text": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. "}, "hash": "60b2342b24e8c84d7461dc9561013e683628686822598142acd51a95eaf84ca5", "class_name": "RelatedNodeInfo"}}, "hash": "f154e982a3fa0d0a48f20ca39228d8e8442edf9665e363a8d148a13891e57f86", "text": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. ", "start_char_idx": 1035, "end_char_idx": 1155, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1557720e-3684-46ef-95bc-79b8c00fa8f8": {"__data__": {"id_": "1557720e-3684-46ef-95bc-79b8c00fa8f8", "embedding": null, "metadata": {"window": "So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n", "original_text": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba08fbda-b05f-4fb2-b051-bb8c5d9f2852", "node_type": "1", "metadata": {"window": "And so \nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \nI actually think that machine learning is th e most exciting field of all the computer \nsciences.  So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. ", "original_text": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain. "}, "hash": "f154e982a3fa0d0a48f20ca39228d8e8442edf9665e363a8d148a13891e57f86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "330d0e94-f923-454f-b8c2-a90fa48b7baa", "node_type": "1", "metadata": {"window": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n", "original_text": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. "}, "hash": "f5e2da2431d671ca57ba58192c0ea1c5f46269b89d3420b6989d133c1f64b7a0", "class_name": "RelatedNodeInfo"}}, "hash": "60b2342b24e8c84d7461dc9561013e683628686822598142acd51a95eaf84ca5", "text": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. ", "start_char_idx": 1155, "end_char_idx": 1277, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "330d0e94-f923-454f-b8c2-a90fa48b7baa": {"__data__": {"id_": "330d0e94-f923-454f-b8c2-a90fa48b7baa", "embedding": null, "metadata": {"window": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n", "original_text": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1557720e-3684-46ef-95bc-79b8c00fa8f8", "node_type": "1", "metadata": {"window": "So I'm actually always excited about  teaching this class.  Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n", "original_text": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning. "}, "hash": "60b2342b24e8c84d7461dc9561013e683628686822598142acd51a95eaf84ca5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fadb5d61-d36b-4138-8d0c-b74c519348a3", "node_type": "1", "metadata": {"window": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun. ", "original_text": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n"}, "hash": "1ab7c6f339dc6422975efe20fbf4cf2b75b35d77c7dd462a252313c09966c65f", "class_name": "RelatedNodeInfo"}}, "hash": "f5e2da2431d671ca57ba58192c0ea1c5f46269b89d3420b6989d133c1f64b7a0", "text": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. ", "start_char_idx": 1277, "end_char_idx": 1412, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fadb5d61-d36b-4138-8d0c-b74c519348a3": {"__data__": {"id_": "fadb5d61-d36b-4138-8d0c-b74c519348a3", "embedding": null, "metadata": {"window": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun. ", "original_text": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "330d0e94-f923-454f-b8c2-a90fa48b7baa", "node_type": "1", "metadata": {"window": "Sometimes I actually \nthink that machine learning is not only the most exciting thin g in computer science, but \nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \n I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n", "original_text": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots. "}, "hash": "f5e2da2431d671ca57ba58192c0ea1c5f46269b89d3420b6989d133c1f64b7a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2782c7d2-28f4-4105-9e7f-402ac34a8a86", "node_type": "1", "metadata": {"window": "Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. ", "original_text": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. "}, "hash": "d9170f93d8c5573d278cafeddbf8944dfddb11e1824eedebbc2364b70c62ff48", "class_name": "RelatedNodeInfo"}}, "hash": "1ab7c6f339dc6422975efe20fbf4cf2b75b35d77c7dd462a252313c09966c65f", "text": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n", "start_char_idx": 1412, "end_char_idx": 1544, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2782c7d2-28f4-4105-9e7f-402ac34a8a86": {"__data__": {"id_": "2782c7d2-28f4-4105-9e7f-402ac34a8a86", "embedding": null, "metadata": {"window": "Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. ", "original_text": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fadb5d61-d36b-4138-8d0c-b74c519348a3", "node_type": "1", "metadata": {"window": "I also want to introduce the TAs, who are all graduate students doing research in or \nrelated to the machine learni ng and all aspects of machin e learning.  Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun. ", "original_text": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n"}, "hash": "1ab7c6f339dc6422975efe20fbf4cf2b75b35d77c7dd462a252313c09966c65f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d5198ce1-8410-4ae9-a311-38bc88e6b051", "node_type": "1", "metadata": {"window": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. ", "original_text": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n"}, "hash": "d4374fd591580adb7a75eb46dd1eb7a7d9a4950599c7e28633eef196a19f22f3", "class_name": "RelatedNodeInfo"}}, "hash": "d9170f93d8c5573d278cafeddbf8944dfddb11e1824eedebbc2364b70c62ff48", "text": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. ", "start_char_idx": 1544, "end_char_idx": 1873, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d5198ce1-8410-4ae9-a311-38bc88e6b051": {"__data__": {"id_": "d5198ce1-8410-4ae9-a311-38bc88e6b051", "embedding": null, "metadata": {"window": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. ", "original_text": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2782c7d2-28f4-4105-9e7f-402ac34a8a86", "node_type": "1", "metadata": {"window": "Paul Baumstarck \nworks in machine learning and computer vision.   Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. ", "original_text": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language. "}, "hash": "d9170f93d8c5573d278cafeddbf8944dfddb11e1824eedebbc2364b70c62ff48", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba2a2850-00ac-441c-be3a-85307791c162", "node_type": "1", "metadata": {"window": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n", "original_text": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n"}, "hash": "0b7b9ee04a180777584687b2b2fa33effecf3acd1c288ce8f15a2c3edec6f8ee", "class_name": "RelatedNodeInfo"}}, "hash": "d4374fd591580adb7a75eb46dd1eb7a7d9a4950599c7e28633eef196a19f22f3", "text": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n", "start_char_idx": 1873, "end_char_idx": 1980, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba2a2850-00ac-441c-be3a-85307791c162": {"__data__": {"id_": "ba2a2850-00ac-441c-be3a-85307791c162", "embedding": null, "metadata": {"window": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n", "original_text": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d5198ce1-8410-4ae9-a311-38bc88e6b051", "node_type": "1", "metadata": {"window": "Catie Chang is actually a neuroscientist \nwho applies machine learning algorithms to try to understand the human brain.  Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. ", "original_text": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n"}, "hash": "d4374fd591580adb7a75eb46dd1eb7a7d9a4950599c7e28633eef196a19f22f3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b1e2466-31cd-4660-bbee-f4edf97f3af8", "node_type": "1", "metadata": {"window": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something. ", "original_text": "So yeah, this is fun. "}, "hash": "df2ab770302b0fc9121f354e449d4194eab82c039421431040001c193536bede", "class_name": "RelatedNodeInfo"}}, "hash": "0b7b9ee04a180777584687b2b2fa33effecf3acd1c288ce8f15a2c3edec6f8ee", "text": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n", "start_char_idx": 1980, "end_char_idx": 2309, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b1e2466-31cd-4660-bbee-f4edf97f3af8": {"__data__": {"id_": "6b1e2466-31cd-4660-bbee-f4edf97f3af8", "embedding": null, "metadata": {"window": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something. ", "original_text": "So yeah, this is fun. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba2a2850-00ac-441c-be3a-85307791c162", "node_type": "1", "metadata": {"window": "Tom Do \nis another PhD student, works in computa tional biology and in sort of the basic \nfundamentals of human learning.  Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n", "original_text": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n"}, "hash": "0b7b9ee04a180777584687b2b2fa33effecf3acd1c288ce8f15a2c3edec6f8ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "371c53f3-de43-44bc-8eda-c6807ef8d67f", "node_type": "1", "metadata": {"window": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. ", "original_text": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. "}, "hash": "26dda9eff788d0a2a899235f7d13678107c170a34815391f634f38581c8f8303", "class_name": "RelatedNodeInfo"}}, "hash": "df2ab770302b0fc9121f354e449d4194eab82c039421431040001c193536bede", "text": "So yeah, this is fun. ", "start_char_idx": 2309, "end_char_idx": 2331, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "371c53f3-de43-44bc-8eda-c6807ef8d67f": {"__data__": {"id_": "371c53f3-de43-44bc-8eda-c6807ef8d67f", "embedding": null, "metadata": {"window": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. ", "original_text": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b1e2466-31cd-4660-bbee-f4edf97f3af8", "node_type": "1", "metadata": {"window": "Zico Kolter is  the head TA \u2014 he's head TA two years \nin a row now \u2014 works in machine learning a nd applies them to a bunch of robots.  And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something. ", "original_text": "So yeah, this is fun. "}, "hash": "df2ab770302b0fc9121f354e449d4194eab82c039421431040001c193536bede", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ce37c297-3fff-4105-a18c-ee23461555db", "node_type": "1", "metadata": {"window": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department? ", "original_text": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. "}, "hash": "8ed3766843245efd58680a5e5082eb3862bc1a3ffd788c757bbb3e9c38e1bcc7", "class_name": "RelatedNodeInfo"}}, "hash": "26dda9eff788d0a2a899235f7d13678107c170a34815391f634f38581c8f8303", "text": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. ", "start_char_idx": 2331, "end_char_idx": 2478, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ce37c297-3fff-4105-a18c-ee23461555db": {"__data__": {"id_": "ce37c297-3fff-4105-a18c-ee23461555db", "embedding": null, "metadata": {"window": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department? ", "original_text": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "371c53f3-de43-44bc-8eda-c6807ef8d67f", "node_type": "1", "metadata": {"window": "And \nDaniel Ramage is \u2014 I guess he's not here  \u2014 Daniel applies l earning algorithms to \nproblems in natural language processing.  \n So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. ", "original_text": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to. "}, "hash": "26dda9eff788d0a2a899235f7d13678107c170a34815391f634f38581c8f8303", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba392562-f719-4af7-9fd1-947511931409", "node_type": "1", "metadata": {"window": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n", "original_text": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n"}, "hash": "42f73e03aa3563215c227545fe21a611cd2af3913214104008f1447370461947", "class_name": "RelatedNodeInfo"}}, "hash": "8ed3766843245efd58680a5e5082eb3862bc1a3ffd788c757bbb3e9c38e1bcc7", "text": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. ", "start_char_idx": 2478, "end_char_idx": 2633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba392562-f719-4af7-9fd1-947511931409": {"__data__": {"id_": "ba392562-f719-4af7-9fd1-947511931409", "embedding": null, "metadata": {"window": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n", "original_text": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ce37c297-3fff-4105-a18c-ee23461555db", "node_type": "1", "metadata": {"window": "So you'll get to know the TAs and me much be tter throughout this quarter, but just from \nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \nin computer vision and biology and robots a nd language.  And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department? ", "original_text": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning. "}, "hash": "8ed3766843245efd58680a5e5082eb3862bc1a3ffd788c757bbb3e9c38e1bcc7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "df08fe46-57de-48e2-9ee6-b2e751bc026d", "node_type": "1", "metadata": {"window": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you. ", "original_text": "I'm actually curious about something. "}, "hash": "2a049156ee4c75d5742914245b6d15d6f350d23bbca22a005468f7d2a7f17391", "class_name": "RelatedNodeInfo"}}, "hash": "42f73e03aa3563215c227545fe21a611cd2af3913214104008f1447370461947", "text": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n", "start_char_idx": 2633, "end_char_idx": 2786, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "df08fe46-57de-48e2-9ee6-b2e751bc026d": {"__data__": {"id_": "df08fe46-57de-48e2-9ee6-b2e751bc026d", "embedding": null, "metadata": {"window": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you. ", "original_text": "I'm actually curious about something. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba392562-f719-4af7-9fd1-947511931409", "node_type": "1", "metadata": {"window": "And machine learning is one of \nthose things that has and is having a large impact on many applications.  \n So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n", "original_text": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n"}, "hash": "42f73e03aa3563215c227545fe21a611cd2af3913214104008f1447370461947", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aa537df5-57c0-4812-848d-d7aedc9ae24d", "node_type": "1", "metadata": {"window": "So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE? ", "original_text": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. "}, "hash": "00e53856eb6271873b8bf5e19d3b024b7bba6a344578bab150d90a203e5cb1e2", "class_name": "RelatedNodeInfo"}}, "hash": "2a049156ee4c75d5742914245b6d15d6f350d23bbca22a005468f7d2a7f17391", "text": "I'm actually curious about something. ", "start_char_idx": 2786, "end_char_idx": 2824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa537df5-57c0-4812-848d-d7aedc9ae24d": {"__data__": {"id_": "aa537df5-57c0-4812-848d-d7aedc9ae24d", "embedding": null, "metadata": {"window": "So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE? ", "original_text": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "df08fe46-57de-48e2-9ee6-b2e751bc026d", "node_type": "1", "metadata": {"window": "So just in my own daily work, I actually frequently end up talking to people like \nhelicopter pilots to biologists to people in  computer systems or databases to economists \nand sort of also an unending stream of  people from industry coming to Stanford \ninterested in applying machine learni ng methods to their own problems.  \n So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you. ", "original_text": "I'm actually curious about something. "}, "hash": "2a049156ee4c75d5742914245b6d15d6f350d23bbca22a005468f7d2a7f17391", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "12383c91-984d-4be1-96aa-23db2c0b63d7", "node_type": "1", "metadata": {"window": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth. ", "original_text": "How many \npeople here are computer science majors, are in the computer science department? "}, "hash": "e027a852e0d1daba5004ab6c15360ac01ec0825b37b54f6d0c8b395b0d0e33b3", "class_name": "RelatedNodeInfo"}}, "hash": "00e53856eb6271873b8bf5e19d3b024b7bba6a344578bab150d90a203e5cb1e2", "text": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. ", "start_char_idx": 2824, "end_char_idx": 2949, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "12383c91-984d-4be1-96aa-23db2c0b63d7": {"__data__": {"id_": "12383c91-984d-4be1-96aa-23db2c0b63d7", "embedding": null, "metadata": {"window": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth. ", "original_text": "How many \npeople here are computer science majors, are in the computer science department? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa537df5-57c0-4812-848d-d7aedc9ae24d", "node_type": "1", "metadata": {"window": "So yeah, this is fun.  A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE? ", "original_text": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious. "}, "hash": "00e53856eb6271873b8bf5e19d3b024b7bba6a344578bab150d90a203e5cb1e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fb639edb-9f25-4fa5-b57a-80ebeb15d389", "node_type": "1", "metadata": {"window": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here? ", "original_text": "Okay. \n"}, "hash": "97ae6c98e432491a7987be2264b4442137a6ba0754955934aa2149750270228e", "class_name": "RelatedNodeInfo"}}, "hash": "e027a852e0d1daba5004ab6c15360ac01ec0825b37b54f6d0c8b395b0d0e33b3", "text": "How many \npeople here are computer science majors, are in the computer science department? ", "start_char_idx": 2949, "end_char_idx": 3040, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fb639edb-9f25-4fa5-b57a-80ebeb15d389": {"__data__": {"id_": "fb639edb-9f25-4fa5-b57a-80ebeb15d389", "embedding": null, "metadata": {"window": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here? ", "original_text": "Okay. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "12383c91-984d-4be1-96aa-23db2c0b63d7", "node_type": "1", "metadata": {"window": "A couple of weeks ago, a student actually forwar ded to me an article \nin \"Computer World\" about the 12 IT skills th at employers can't say no to.  So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth. ", "original_text": "How many \npeople here are computer science majors, are in the computer science department? "}, "hash": "e027a852e0d1daba5004ab6c15360ac01ec0825b37b54f6d0c8b395b0d0e33b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ae70e01-90d5-4f4e-9e42-e0bc6a26cc42", "node_type": "1", "metadata": {"window": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many. ", "original_text": "About half of you. "}, "hash": "4d1259926078c84dab52d246976ce82cc0b1e710ce32ce0ce6688bc792b41d1e", "class_name": "RelatedNodeInfo"}}, "hash": "97ae6c98e432491a7987be2264b4442137a6ba0754955934aa2149750270228e", "text": "Okay. \n", "start_char_idx": 3040, "end_char_idx": 3047, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ae70e01-90d5-4f4e-9e42-e0bc6a26cc42": {"__data__": {"id_": "4ae70e01-90d5-4f4e-9e42-e0bc6a26cc42", "embedding": null, "metadata": {"window": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many. ", "original_text": "About half of you. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb639edb-9f25-4fa5-b57a-80ebeb15d389", "node_type": "1", "metadata": {"window": "So it's about \nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \ntopping the list was actually machine lear ning.  So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here? ", "original_text": "Okay. \n"}, "hash": "97ae6c98e432491a7987be2264b4442137a6ba0754955934aa2149750270228e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d76a60ad-edc0-41f3-b74a-1c88f10046c9", "node_type": "1", "metadata": {"window": "I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised. ", "original_text": "How many people are from  EE? "}, "hash": "d94db416bacca523b69bb0b37f68a4ed9631e2ad7c349f6c9f2f48a2a51123c7", "class_name": "RelatedNodeInfo"}}, "hash": "4d1259926078c84dab52d246976ce82cc0b1e710ce32ce0ce6688bc792b41d1e", "text": "About half of you. ", "start_char_idx": 3047, "end_char_idx": 3066, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d76a60ad-edc0-41f3-b74a-1c88f10046c9": {"__data__": {"id_": "d76a60ad-edc0-41f3-b74a-1c88f10046c9", "embedding": null, "metadata": {"window": "I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised. ", "original_text": "How many people are from  EE? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ae70e01-90d5-4f4e-9e42-e0bc6a26cc42", "node_type": "1", "metadata": {"window": "So I think this is a good time to be \nlearning this stuff and learning algorithms and having a large impact on many segments \nof science and industry.  \n I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many. ", "original_text": "About half of you. "}, "hash": "4d1259926078c84dab52d246976ce82cc0b1e710ce32ce0ce6688bc792b41d1e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f5b2e791-1e16-4086-8897-386995a6082a", "node_type": "1", "metadata": {"window": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics? ", "original_text": "Oh, okay, maybe about a fifth. "}, "hash": "cb647343f90c78d935658ec4f7465c3ef641e2a6f0a14fd966820dd838a56f36", "class_name": "RelatedNodeInfo"}}, "hash": "d94db416bacca523b69bb0b37f68a4ed9631e2ad7c349f6c9f2f48a2a51123c7", "text": "How many people are from  EE? ", "start_char_idx": 3066, "end_char_idx": 3096, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5b2e791-1e16-4086-8897-386995a6082a": {"__data__": {"id_": "f5b2e791-1e16-4086-8897-386995a6082a", "embedding": null, "metadata": {"window": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics? ", "original_text": "Oh, okay, maybe about a fifth. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d76a60ad-edc0-41f3-b74a-1c88f10046c9", "node_type": "1", "metadata": {"window": "I'm actually curious about something.  Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised. ", "original_text": "How many people are from  EE? "}, "hash": "d94db416bacca523b69bb0b37f68a4ed9631e2ad7c349f6c9f2f48a2a51123c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a827aa0e-397f-4b0b-bb14-7358b7193722", "node_type": "1", "metadata": {"window": "How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few. ", "original_text": "How \n\nmany biologers are there here? "}, "hash": "1300384dbd351e11fc3d4040d7aa628e47dca4b64a4b583d048a74e92a1ee969", "class_name": "RelatedNodeInfo"}}, "hash": "cb647343f90c78d935658ec4f7465c3ef641e2a6f0a14fd966820dd838a56f36", "text": "Oh, okay, maybe about a fifth. ", "start_char_idx": 3096, "end_char_idx": 3127, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a827aa0e-397f-4b0b-bb14-7358b7193722": {"__data__": {"id_": "a827aa0e-397f-4b0b-bb14-7358b7193722", "embedding": null, "metadata": {"window": "How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few. ", "original_text": "How \n\nmany biologers are there here? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5b2e791-1e16-4086-8897-386995a6082a", "node_type": "1", "metadata": {"window": "Learni ng algorithms is one of the things that \ntouches many areas of science and industrie s, and I'm just kind of curious.  How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics? ", "original_text": "Oh, okay, maybe about a fifth. "}, "hash": "cb647343f90c78d935658ec4f7465c3ef641e2a6f0a14fd966820dd838a56f36", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "acb27c0f-39c3-48d6-9539-e59ef42a900a", "node_type": "1", "metadata": {"window": "Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n", "original_text": "Wow, just a few, not many. "}, "hash": "8cf1f5463adc06d1bf54b4c74386f5eea2eee9990d184ab4b5f7980d2c1c3f65", "class_name": "RelatedNodeInfo"}}, "hash": "1300384dbd351e11fc3d4040d7aa628e47dca4b64a4b583d048a74e92a1ee969", "text": "How \n\nmany biologers are there here? ", "start_char_idx": 3127, "end_char_idx": 3164, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "acb27c0f-39c3-48d6-9539-e59ef42a900a": {"__data__": {"id_": "acb27c0f-39c3-48d6-9539-e59ef42a900a", "embedding": null, "metadata": {"window": "Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n", "original_text": "Wow, just a few, not many. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a827aa0e-397f-4b0b-bb14-7358b7193722", "node_type": "1", "metadata": {"window": "How many \npeople here are computer science majors, are in the computer science department?  Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few. ", "original_text": "How \n\nmany biologers are there here? "}, "hash": "1300384dbd351e11fc3d4040d7aa628e47dca4b64a4b583d048a74e92a1ee969", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb39c138-c38b-482e-aca8-5558676ba6bd", "node_type": "1", "metadata": {"window": "About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n", "original_text": "I'm surprised. "}, "hash": "1f3c3190f08a53c5be5c5f12465c76c2f6a15e756e7d84ac64796e5ba265e6a5", "class_name": "RelatedNodeInfo"}}, "hash": "8cf1f5463adc06d1bf54b4c74386f5eea2eee9990d184ab4b5f7980d2c1c3f65", "text": "Wow, just a few, not many. ", "start_char_idx": 3164, "end_char_idx": 3191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bb39c138-c38b-482e-aca8-5558676ba6bd": {"__data__": {"id_": "bb39c138-c38b-482e-aca8-5558676ba6bd", "embedding": null, "metadata": {"window": "About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n", "original_text": "I'm surprised. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "acb27c0f-39c3-48d6-9539-e59ef42a900a", "node_type": "1", "metadata": {"window": "Okay. \n About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n", "original_text": "Wow, just a few, not many. "}, "hash": "8cf1f5463adc06d1bf54b4c74386f5eea2eee9990d184ab4b5f7980d2c1c3f65", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "14892dd0-f5bd-45c9-b3d9-cab15f14fa81", "node_type": "1", "metadata": {"window": "How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n", "original_text": "Anyone from \nstatistics? "}, "hash": "7fa8542fcb0e2f6e3c2c1642a72e3f4be540f421c5fbd1300a9632f670196634", "class_name": "RelatedNodeInfo"}}, "hash": "1f3c3190f08a53c5be5c5f12465c76c2f6a15e756e7d84ac64796e5ba265e6a5", "text": "I'm surprised. ", "start_char_idx": 3191, "end_char_idx": 3206, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "14892dd0-f5bd-45c9-b3d9-cab15f14fa81": {"__data__": {"id_": "14892dd0-f5bd-45c9-b3d9-cab15f14fa81", "embedding": null, "metadata": {"window": "How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n", "original_text": "Anyone from \nstatistics? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb39c138-c38b-482e-aca8-5558676ba6bd", "node_type": "1", "metadata": {"window": "About half of you.  How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n", "original_text": "I'm surprised. "}, "hash": "1f3c3190f08a53c5be5c5f12465c76c2f6a15e756e7d84ac64796e5ba265e6a5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1a66548c-d067-4aa0-8c6f-51ced06f0931", "node_type": "1", "metadata": {"window": "Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n", "original_text": "Okay, a few. "}, "hash": "fc998577260c0cf2356dbfcecaa6e2c76dbf597cb99f447af72e8fe428118eae", "class_name": "RelatedNodeInfo"}}, "hash": "7fa8542fcb0e2f6e3c2c1642a72e3f4be540f421c5fbd1300a9632f670196634", "text": "Anyone from \nstatistics? ", "start_char_idx": 3206, "end_char_idx": 3231, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a66548c-d067-4aa0-8c6f-51ced06f0931": {"__data__": {"id_": "1a66548c-d067-4aa0-8c6f-51ced06f0931", "embedding": null, "metadata": {"window": "Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n", "original_text": "Okay, a few. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "14892dd0-f5bd-45c9-b3d9-cab15f14fa81", "node_type": "1", "metadata": {"window": "How many people are from  EE?  Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n", "original_text": "Anyone from \nstatistics? "}, "hash": "7fa8542fcb0e2f6e3c2c1642a72e3f4be540f421c5fbd1300a9632f670196634", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9112c04e-f1c3-4c7a-8279-cf7cc673c07c", "node_type": "1", "metadata": {"window": "How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME. ", "original_text": "So where are the rest of you from?  \n"}, "hash": "fe36880e9df284fa93f1631a42983ecad63349544c586b1f5c8c0844f11585af", "class_name": "RelatedNodeInfo"}}, "hash": "fc998577260c0cf2356dbfcecaa6e2c76dbf597cb99f447af72e8fe428118eae", "text": "Okay, a few. ", "start_char_idx": 3231, "end_char_idx": 3244, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9112c04e-f1c3-4c7a-8279-cf7cc673c07c": {"__data__": {"id_": "9112c04e-f1c3-4c7a-8279-cf7cc673c07c", "embedding": null, "metadata": {"window": "How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME. ", "original_text": "So where are the rest of you from?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a66548c-d067-4aa0-8c6f-51ced06f0931", "node_type": "1", "metadata": {"window": "Oh, okay, maybe about a fifth.  How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n", "original_text": "Okay, a few. "}, "hash": "fc998577260c0cf2356dbfcecaa6e2c76dbf597cb99f447af72e8fe428118eae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "de25c6d7-3445-4cee-a313-b679a0d47fb0", "node_type": "1", "metadata": {"window": "Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n", "original_text": "Student : iCME.  \n"}, "hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "class_name": "RelatedNodeInfo"}}, "hash": "fe36880e9df284fa93f1631a42983ecad63349544c586b1f5c8c0844f11585af", "text": "So where are the rest of you from?  \n", "start_char_idx": 3244, "end_char_idx": 3281, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de25c6d7-3445-4cee-a313-b679a0d47fb0": {"__data__": {"id_": "de25c6d7-3445-4cee-a313-b679a0d47fb0", "embedding": null, "metadata": {"window": "Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n", "original_text": "Student : iCME.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9112c04e-f1c3-4c7a-8279-cf7cc673c07c", "node_type": "1", "metadata": {"window": "How \n\nmany biologers are there here?  Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME. ", "original_text": "So where are the rest of you from?  \n"}, "hash": "fe36880e9df284fa93f1631a42983ecad63349544c586b1f5c8c0844f11585af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2f5baa1d-e9d3-4152-8ffe-617d077e37ff", "node_type": "1", "metadata": {"window": "I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n", "original_text": "Instructor (Andrew Ng) : Say again?  \n"}, "hash": "4baed37683e2cd5af3fe16e5d3bf9cbb53d6fdc4881e9e84ce3e0f9e73bde22b", "class_name": "RelatedNodeInfo"}}, "hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "text": "Student : iCME.  \n", "start_char_idx": 3281, "end_char_idx": 3299, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2f5baa1d-e9d3-4152-8ffe-617d077e37ff": {"__data__": {"id_": "2f5baa1d-e9d3-4152-8ffe-617d077e37ff", "embedding": null, "metadata": {"window": "I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n", "original_text": "Instructor (Andrew Ng) : Say again?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "de25c6d7-3445-4cee-a313-b679a0d47fb0", "node_type": "1", "metadata": {"window": "Wow, just a few, not many.  I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n", "original_text": "Student : iCME.  \n"}, "hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ac92cf2-7fbc-4679-87dc-76c58bef1f5f", "node_type": "1", "metadata": {"window": "Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n", "original_text": "Student : iCME.  \n"}, "hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "class_name": "RelatedNodeInfo"}}, "hash": "4baed37683e2cd5af3fe16e5d3bf9cbb53d6fdc4881e9e84ce3e0f9e73bde22b", "text": "Instructor (Andrew Ng) : Say again?  \n", "start_char_idx": 3299, "end_char_idx": 3337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ac92cf2-7fbc-4679-87dc-76c58bef1f5f": {"__data__": {"id_": "4ac92cf2-7fbc-4679-87dc-76c58bef1f5f", "embedding": null, "metadata": {"window": "Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n", "original_text": "Student : iCME.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f5baa1d-e9d3-4152-8ffe-617d077e37ff", "node_type": "1", "metadata": {"window": "I'm surprised.  Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n", "original_text": "Instructor (Andrew Ng) : Say again?  \n"}, "hash": "4baed37683e2cd5af3fe16e5d3bf9cbb53d6fdc4881e9e84ce3e0f9e73bde22b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58ad6948-5d3c-410c-aafd-2c7e005318d9", "node_type": "1", "metadata": {"window": "Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. ", "original_text": "Instructor (Andrew Ng) : iCME. "}, "hash": "36990fc3775d06ffc09bffea98865a6ce85b76a7540949d617eb87525e90d09c", "class_name": "RelatedNodeInfo"}}, "hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "text": "Student : iCME.  \n", "start_char_idx": 3281, "end_char_idx": 3299, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58ad6948-5d3c-410c-aafd-2c7e005318d9": {"__data__": {"id_": "58ad6948-5d3c-410c-aafd-2c7e005318d9", "embedding": null, "metadata": {"window": "Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. ", "original_text": "Instructor (Andrew Ng) : iCME. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ac92cf2-7fbc-4679-87dc-76c58bef1f5f", "node_type": "1", "metadata": {"window": "Anyone from \nstatistics?  Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n", "original_text": "Student : iCME.  \n"}, "hash": "ff6ef5cf181b9e6adaf79db5d382141eb10b1074096e50e939af2aa3999b7820", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81ad316d-3411-426f-8fdf-6500d6554154", "node_type": "1", "metadata": {"window": "So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n", "original_text": "Cool.  \n"}, "hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "class_name": "RelatedNodeInfo"}}, "hash": "36990fc3775d06ffc09bffea98865a6ce85b76a7540949d617eb87525e90d09c", "text": "Instructor (Andrew Ng) : iCME. ", "start_char_idx": 3355, "end_char_idx": 3386, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81ad316d-3411-426f-8fdf-6500d6554154": {"__data__": {"id_": "81ad316d-3411-426f-8fdf-6500d6554154", "embedding": null, "metadata": {"window": "So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n", "original_text": "Cool.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58ad6948-5d3c-410c-aafd-2c7e005318d9", "node_type": "1", "metadata": {"window": "Okay, a few.  So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. ", "original_text": "Instructor (Andrew Ng) : iCME. "}, "hash": "36990fc3775d06ffc09bffea98865a6ce85b76a7540949d617eb87525e90d09c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "409dae7a-87be-4b54-a369-ee20fe75fa0b", "node_type": "1", "metadata": {"window": "Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}}, "hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "text": "Cool.  \n", "start_char_idx": 3386, "end_char_idx": 3394, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "409dae7a-87be-4b54-a369-ee20fe75fa0b": {"__data__": {"id_": "409dae7a-87be-4b54-a369-ee20fe75fa0b", "embedding": null, "metadata": {"window": "Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n", "original_text": "Student : [Inaudible].  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81ad316d-3411-426f-8fdf-6500d6554154", "node_type": "1", "metadata": {"window": "So where are the rest of you from?  \n Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n", "original_text": "Cool.  \n"}, "hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d48d5a6-2c27-4674-bb4e-7e0374c78464", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi. ", "original_text": "Instructor (Andrew Ng) : Civi and what else?  \n"}, "hash": "7d109ff8a007c1d0f1b16a3e7f24a7ccd1e9bb1b864caeb9d0865aea1bbd930d", "class_name": "RelatedNodeInfo"}}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "text": "Student : [Inaudible].  \n", "start_char_idx": 3394, "end_char_idx": 3419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9d48d5a6-2c27-4674-bb4e-7e0374c78464": {"__data__": {"id_": "9d48d5a6-2c27-4674-bb4e-7e0374c78464", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi. ", "original_text": "Instructor (Andrew Ng) : Civi and what else?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "409dae7a-87be-4b54-a369-ee20fe75fa0b", "node_type": "1", "metadata": {"window": "Student : iCME.  \n Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ece3f660-e1ee-4a0a-83a9-c9b04d373199", "node_type": "1", "metadata": {"window": "Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n", "original_text": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. "}, "hash": "6c2e4690ea2134ea76f2004e5a7d0054df8cfa729cb5d003bdbe0e9a2bb63d0e", "class_name": "RelatedNodeInfo"}}, "hash": "7d109ff8a007c1d0f1b16a3e7f24a7ccd1e9bb1b864caeb9d0865aea1bbd930d", "text": "Instructor (Andrew Ng) : Civi and what else?  \n", "start_char_idx": 3419, "end_char_idx": 3466, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ece3f660-e1ee-4a0a-83a9-c9b04d373199": {"__data__": {"id_": "ece3f660-e1ee-4a0a-83a9-c9b04d373199", "embedding": null, "metadata": {"window": "Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n", "original_text": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d48d5a6-2c27-4674-bb4e-7e0374c78464", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Say again?  \n Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi. ", "original_text": "Instructor (Andrew Ng) : Civi and what else?  \n"}, "hash": "7d109ff8a007c1d0f1b16a3e7f24a7ccd1e9bb1b864caeb9d0865aea1bbd930d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7cdbe830-9cb7-4927-ad86-f37dd824a1ca", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n", "original_text": "Yeah, cool.  \n"}, "hash": "c2b5b1c43b5cc3506bfcae3f5291ca3dca63489e4dc8187ffb2199dd2465e1ea", "class_name": "RelatedNodeInfo"}}, "hash": "6c2e4690ea2134ea76f2004e5a7d0054df8cfa729cb5d003bdbe0e9a2bb63d0e", "text": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. ", "start_char_idx": 3466, "end_char_idx": 3547, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7cdbe830-9cb7-4927-ad86-f37dd824a1ca": {"__data__": {"id_": "7cdbe830-9cb7-4927-ad86-f37dd824a1ca", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n", "original_text": "Yeah, cool.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ece3f660-e1ee-4a0a-83a9-c9b04d373199", "node_type": "1", "metadata": {"window": "Student : iCME.  \n Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n", "original_text": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems. "}, "hash": "6c2e4690ea2134ea76f2004e5a7d0054df8cfa729cb5d003bdbe0e9a2bb63d0e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "edb3cb5e-dac4-4bf9-9dc2-155adecfa763", "node_type": "1", "metadata": {"window": "Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro. ", "original_text": "Student : Chemi.  \n"}, "hash": "1bad1725ebc0a1b4d941c02da57ae65d2238e0930a92e59135ab5cb8e453c93e", "class_name": "RelatedNodeInfo"}}, "hash": "c2b5b1c43b5cc3506bfcae3f5291ca3dca63489e4dc8187ffb2199dd2465e1ea", "text": "Yeah, cool.  \n", "start_char_idx": 3547, "end_char_idx": 3561, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "edb3cb5e-dac4-4bf9-9dc2-155adecfa763": {"__data__": {"id_": "edb3cb5e-dac4-4bf9-9dc2-155adecfa763", "embedding": null, "metadata": {"window": "Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro. ", "original_text": "Student : Chemi.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7cdbe830-9cb7-4927-ad86-f37dd824a1ca", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : iCME.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n", "original_text": "Yeah, cool.  \n"}, "hash": "c2b5b1c43b5cc3506bfcae3f5291ca3dca63489e4dc8187ffb2199dd2465e1ea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0e25a07-9982-43a7-bd8b-4ea383cfe81c", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right. ", "original_text": "Instructor (Andrew Ng) : Chemi. "}, "hash": "8b2274bf1434009c295b7eaa4738a80679607dc493b8570447ceb09915ac289d", "class_name": "RelatedNodeInfo"}}, "hash": "1bad1725ebc0a1b4d941c02da57ae65d2238e0930a92e59135ab5cb8e453c93e", "text": "Student : Chemi.  \n", "start_char_idx": 3561, "end_char_idx": 3580, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d0e25a07-9982-43a7-bd8b-4ea383cfe81c": {"__data__": {"id_": "d0e25a07-9982-43a7-bd8b-4ea383cfe81c", "embedding": null, "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right. ", "original_text": "Instructor (Andrew Ng) : Chemi. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "edb3cb5e-dac4-4bf9-9dc2-155adecfa763", "node_type": "1", "metadata": {"window": "Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro. ", "original_text": "Student : Chemi.  \n"}, "hash": "1bad1725ebc0a1b4d941c02da57ae65d2238e0930a92e59135ab5cb8e453c93e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ec785d2-72ea-41d1-ae3e-868873270333", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool. ", "original_text": "Cool.  \n"}, "hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "class_name": "RelatedNodeInfo"}}, "hash": "8b2274bf1434009c295b7eaa4738a80679607dc493b8570447ceb09915ac289d", "text": "Instructor (Andrew Ng) : Chemi. ", "start_char_idx": 3580, "end_char_idx": 3612, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3ec785d2-72ea-41d1-ae3e-868873270333": {"__data__": {"id_": "3ec785d2-72ea-41d1-ae3e-868873270333", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool. ", "original_text": "Cool.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d0e25a07-9982-43a7-bd8b-4ea383cfe81c", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right. ", "original_text": "Instructor (Andrew Ng) : Chemi. "}, "hash": "8b2274bf1434009c295b7eaa4738a80679607dc493b8570447ceb09915ac289d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8789715-3a48-4d70-a63f-ce61b96ecdfe", "node_type": "1", "metadata": {"window": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}}, "hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "text": "Cool.  \n", "start_char_idx": 3386, "end_char_idx": 3394, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8789715-3a48-4d70-a63f-ce61b96ecdfe": {"__data__": {"id_": "a8789715-3a48-4d70-a63f-ce61b96ecdfe", "embedding": null, "metadata": {"window": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n", "original_text": "Student : [Inaudible].  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3ec785d2-72ea-41d1-ae3e-868873270333", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Civi and what else?  \n Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool. ", "original_text": "Cool.  \n"}, "hash": "ef6d17e9c5171d8911c2db4189f026123a9303b3a566ccd7a22558a835e98de4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "69d5a32f-7274-475e-b79c-f1ff184be0a9", "node_type": "1", "metadata": {"window": "Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n", "original_text": "Instructor (Andrew Ng) : Aero/astro. "}, "hash": "02650eb046ba7a259fbc1bce19271b32aabba7aef914579d935aa8838edcccbe", "class_name": "RelatedNodeInfo"}}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "text": "Student : [Inaudible].  \n", "start_char_idx": 3394, "end_char_idx": 3419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69d5a32f-7274-475e-b79c-f1ff184be0a9": {"__data__": {"id_": "69d5a32f-7274-475e-b79c-f1ff184be0a9", "embedding": null, "metadata": {"window": "Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n", "original_text": "Instructor (Andrew Ng) : Aero/astro. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8789715-3a48-4d70-a63f-ce61b96ecdfe", "node_type": "1", "metadata": {"window": "Student : [Inaudible]  \nInstructor (Andrew Ng) : Synthesis, [inaudible] systems.  Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "abc0e169-74ac-4aab-87c2-7f167b8e054b", "node_type": "1", "metadata": {"window": "Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon? ", "original_text": "Yes, right. "}, "hash": "3775a6a845ef72358b94ad618175e281f6e71aff15460a96ff4fca75c2b9a14f", "class_name": "RelatedNodeInfo"}}, "hash": "02650eb046ba7a259fbc1bce19271b32aabba7aef914579d935aa8838edcccbe", "text": "Instructor (Andrew Ng) : Aero/astro. ", "start_char_idx": 3645, "end_char_idx": 3682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "abc0e169-74ac-4aab-87c2-7f167b8e054b": {"__data__": {"id_": "abc0e169-74ac-4aab-87c2-7f167b8e054b", "embedding": null, "metadata": {"window": "Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon? ", "original_text": "Yes, right. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "69d5a32f-7274-475e-b79c-f1ff184be0a9", "node_type": "1", "metadata": {"window": "Yeah, cool.  \n Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n", "original_text": "Instructor (Andrew Ng) : Aero/astro. "}, "hash": "02650eb046ba7a259fbc1bce19271b32aabba7aef914579d935aa8838edcccbe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c63e20e3-7c3b-453a-9013-864088b107f0", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE. ", "original_text": "Yeah, okay, cool. "}, "hash": "983cab6a97550570e68a2499d81934f4d690189e90704cc28829bfeedd851155", "class_name": "RelatedNodeInfo"}}, "hash": "3775a6a845ef72358b94ad618175e281f6e71aff15460a96ff4fca75c2b9a14f", "text": "Yes, right. ", "start_char_idx": 3682, "end_char_idx": 3694, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c63e20e3-7c3b-453a-9013-864088b107f0": {"__data__": {"id_": "c63e20e3-7c3b-453a-9013-864088b107f0", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE. ", "original_text": "Yeah, okay, cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "abc0e169-74ac-4aab-87c2-7f167b8e054b", "node_type": "1", "metadata": {"window": "Student : Chemi.  \n Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon? ", "original_text": "Yes, right. "}, "hash": "3775a6a845ef72358b94ad618175e281f6e71aff15460a96ff4fca75c2b9a14f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08fc9c23-e41d-4fa0-af6a-28126471dc0f", "node_type": "1", "metadata": {"window": "Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght. ", "original_text": "Anyone else?  \n"}, "hash": "7c797806c4942896b3717953102d61326a085954b8818c0dc2c4635684b066b2", "class_name": "RelatedNodeInfo"}}, "hash": "983cab6a97550570e68a2499d81934f4d690189e90704cc28829bfeedd851155", "text": "Yeah, okay, cool. ", "start_char_idx": 3694, "end_char_idx": 3712, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08fc9c23-e41d-4fa0-af6a-28126471dc0f": {"__data__": {"id_": "08fc9c23-e41d-4fa0-af6a-28126471dc0f", "embedding": null, "metadata": {"window": "Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght. ", "original_text": "Anyone else?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c63e20e3-7c3b-453a-9013-864088b107f0", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Chemi.  Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE. ", "original_text": "Yeah, okay, cool. "}, "hash": "983cab6a97550570e68a2499d81934f4d690189e90704cc28829bfeedd851155", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1bab64b2-0091-4922-83a9-85b37582bdc8", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool. ", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}}, "hash": "7c797806c4942896b3717953102d61326a085954b8818c0dc2c4635684b066b2", "text": "Anyone else?  \n", "start_char_idx": 3712, "end_char_idx": 3727, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1bab64b2-0091-4922-83a9-85b37582bdc8": {"__data__": {"id_": "1bab64b2-0091-4922-83a9-85b37582bdc8", "embedding": null, "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool. ", "original_text": "Student : [Inaudible].  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "08fc9c23-e41d-4fa0-af6a-28126471dc0f", "node_type": "1", "metadata": {"window": "Cool.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght. ", "original_text": "Anyone else?  \n"}, "hash": "7c797806c4942896b3717953102d61326a085954b8818c0dc2c4635684b066b2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1245df91-a0f3-45be-833b-e3870540e8ae", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n", "original_text": "Instructor (Andrew Ng) : Pardon? "}, "hash": "2c9b0516746043c3938a801c3325f911192eadb56eb546b5643d4e979097081e", "class_name": "RelatedNodeInfo"}}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "text": "Student : [Inaudible].  \n", "start_char_idx": 3394, "end_char_idx": 3419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1245df91-a0f3-45be-833b-e3870540e8ae": {"__data__": {"id_": "1245df91-a0f3-45be-833b-e3870540e8ae", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n", "original_text": "Instructor (Andrew Ng) : Pardon? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1bab64b2-0091-4922-83a9-85b37582bdc8", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool. ", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "05784733-673b-4a76-931a-f45479a49ba7", "node_type": "1", "metadata": {"window": "Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n", "original_text": "MSNE. "}, "hash": "630ffcc3ca949495326d36f1a0991d6b10838cd454e5a71f7db5d756b5410258", "class_name": "RelatedNodeInfo"}}, "hash": "2c9b0516746043c3938a801c3325f911192eadb56eb546b5643d4e979097081e", "text": "Instructor (Andrew Ng) : Pardon? ", "start_char_idx": 3752, "end_char_idx": 3785, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "05784733-673b-4a76-931a-f45479a49ba7": {"__data__": {"id_": "05784733-673b-4a76-931a-f45479a49ba7", "embedding": null, "metadata": {"window": "Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n", "original_text": "MSNE. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1245df91-a0f3-45be-833b-e3870540e8ae", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Aero/astro.  Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n", "original_text": "Instructor (Andrew Ng) : Pardon? "}, "hash": "2c9b0516746043c3938a801c3325f911192eadb56eb546b5643d4e979097081e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eeeae031-8f68-4318-bbdf-a0cedf24db28", "node_type": "1", "metadata": {"window": "Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n", "original_text": "All ri ght. "}, "hash": "de523ec9b875e975a9cc978f6e98c5ae9846f0d6d35d0d9d238bf22c627c31b6", "class_name": "RelatedNodeInfo"}}, "hash": "630ffcc3ca949495326d36f1a0991d6b10838cd454e5a71f7db5d756b5410258", "text": "MSNE. ", "start_char_idx": 3785, "end_char_idx": 3791, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eeeae031-8f68-4318-bbdf-a0cedf24db28": {"__data__": {"id_": "eeeae031-8f68-4318-bbdf-a0cedf24db28", "embedding": null, "metadata": {"window": "Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n", "original_text": "All ri ght. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "05784733-673b-4a76-931a-f45479a49ba7", "node_type": "1", "metadata": {"window": "Yes, right.  Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n", "original_text": "MSNE. "}, "hash": "630ffcc3ca949495326d36f1a0991d6b10838cd454e5a71f7db5d756b5410258", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd2b0e5a-5b68-4817-91c2-b83c066837df", "node_type": "1", "metadata": {"window": "Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n", "original_text": "Cool. "}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "class_name": "RelatedNodeInfo"}}, "hash": "de523ec9b875e975a9cc978f6e98c5ae9846f0d6d35d0d9d238bf22c627c31b6", "text": "All ri ght. ", "start_char_idx": 3791, "end_char_idx": 3803, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd2b0e5a-5b68-4817-91c2-b83c066837df": {"__data__": {"id_": "bd2b0e5a-5b68-4817-91c2-b83c066837df", "embedding": null, "metadata": {"window": "Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n", "original_text": "Cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eeeae031-8f68-4318-bbdf-a0cedf24db28", "node_type": "1", "metadata": {"window": "Yeah, okay, cool.  Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n", "original_text": "All ri ght. "}, "hash": "de523ec9b875e975a9cc978f6e98c5ae9846f0d6d35d0d9d238bf22c627c31b6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ecb917f1-9ae9-43dc-a978-5729d54d0fde", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n", "original_text": "Yeah.  \n"}, "hash": "a554f212fee44bdcc4100f5d194a8c0b988d3055e58893cc5a49a291f8c108fc", "class_name": "RelatedNodeInfo"}}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "text": "Cool. ", "start_char_idx": 3386, "end_char_idx": 3392, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ecb917f1-9ae9-43dc-a978-5729d54d0fde": {"__data__": {"id_": "ecb917f1-9ae9-43dc-a978-5729d54d0fde", "embedding": null, "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n", "original_text": "Yeah.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd2b0e5a-5b68-4817-91c2-b83c066837df", "node_type": "1", "metadata": {"window": "Anyone else?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n", "original_text": "Cool. "}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d2a1ab1e-6d3c-47b8-9793-66d5a43413cb", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry. ", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}}, "hash": "a554f212fee44bdcc4100f5d194a8c0b988d3055e58893cc5a49a291f8c108fc", "text": "Yeah.  \n", "start_char_idx": 3809, "end_char_idx": 3817, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d2a1ab1e-6d3c-47b8-9793-66d5a43413cb": {"__data__": {"id_": "d2a1ab1e-6d3c-47b8-9793-66d5a43413cb", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry. ", "original_text": "Student : [Inaudible].  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ecb917f1-9ae9-43dc-a978-5729d54d0fde", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n", "original_text": "Yeah.  \n"}, "hash": "a554f212fee44bdcc4100f5d194a8c0b988d3055e58893cc5a49a291f8c108fc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "852f5349-fc66-4037-a43b-82fb37900f1c", "node_type": "1", "metadata": {"window": "MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay. ", "original_text": "Instructor (Andrew Ng) : Pardon?  \n"}, "hash": "35d91844bac536866f90c23204f831ee099d7cf31d90c2b8cef29a4262f9a09a", "class_name": "RelatedNodeInfo"}}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "text": "Student : [Inaudible].  \n", "start_char_idx": 3394, "end_char_idx": 3419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "852f5349-fc66-4037-a43b-82fb37900f1c": {"__data__": {"id_": "852f5349-fc66-4037-a43b-82fb37900f1c", "embedding": null, "metadata": {"window": "MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay. ", "original_text": "Instructor (Andrew Ng) : Pardon?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d2a1ab1e-6d3c-47b8-9793-66d5a43413cb", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Pardon?  MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry. ", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cfa56a96-82a1-4352-8e7f-653e80cb2bd0", "node_type": "1", "metadata": {"window": "All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool. ", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}}, "hash": "35d91844bac536866f90c23204f831ee099d7cf31d90c2b8cef29a4262f9a09a", "text": "Instructor (Andrew Ng) : Pardon?  \n", "start_char_idx": 3842, "end_char_idx": 3877, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cfa56a96-82a1-4352-8e7f-653e80cb2bd0": {"__data__": {"id_": "cfa56a96-82a1-4352-8e7f-653e80cb2bd0", "embedding": null, "metadata": {"window": "All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool. ", "original_text": "Student : [Inaudible].  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "852f5349-fc66-4037-a43b-82fb37900f1c", "node_type": "1", "metadata": {"window": "MSNE.  All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay. ", "original_text": "Instructor (Andrew Ng) : Pardon?  \n"}, "hash": "35d91844bac536866f90c23204f831ee099d7cf31d90c2b8cef29a4262f9a09a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2b8191f-e78f-424e-aee2-a9205c05d40e", "node_type": "1", "metadata": {"window": "Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great. ", "original_text": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n"}, "hash": "31f6f982c7f3bac1ce485efa6d885edc8b483c9a8d0bacf3543b2319f6e74c29", "class_name": "RelatedNodeInfo"}}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "text": "Student : [Inaudible].  \n", "start_char_idx": 3394, "end_char_idx": 3419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2b8191f-e78f-424e-aee2-a9205c05d40e": {"__data__": {"id_": "a2b8191f-e78f-424e-aee2-a9205c05d40e", "embedding": null, "metadata": {"window": "Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great. ", "original_text": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cfa56a96-82a1-4352-8e7f-653e80cb2bd0", "node_type": "1", "metadata": {"window": "All ri ght.  Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool. ", "original_text": "Student : [Inaudible].  \n"}, "hash": "dc31eb62f28c69d43966031d2ce940f8566648a1cf536297e266f450dbdc0bc8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5423250-608d-4fd0-a28b-dafe99e23a4b", "node_type": "1", "metadata": {"window": "Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n", "original_text": "Instructor (Andrew Ng) : Oh, I see, industry. "}, "hash": "3705ad1d727462bc70cf098a9e22d44a826fe907d8bf2102784bd6c59008dba6", "class_name": "RelatedNodeInfo"}}, "hash": "31f6f982c7f3bac1ce485efa6d885edc8b483c9a8d0bacf3543b2319f6e74c29", "text": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n", "start_char_idx": 3902, "end_char_idx": 3961, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5423250-608d-4fd0-a28b-dafe99e23a4b": {"__data__": {"id_": "b5423250-608d-4fd0-a28b-dafe99e23a4b", "embedding": null, "metadata": {"window": "Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n", "original_text": "Instructor (Andrew Ng) : Oh, I see, industry. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2b8191f-e78f-424e-aee2-a9205c05d40e", "node_type": "1", "metadata": {"window": "Cool.  Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great. ", "original_text": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n"}, "hash": "31f6f982c7f3bac1ce485efa6d885edc8b483c9a8d0bacf3543b2319f6e74c29", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5521157b-1012-470a-bd03-83849e265f18", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "3705ad1d727462bc70cf098a9e22d44a826fe907d8bf2102784bd6c59008dba6", "text": "Instructor (Andrew Ng) : Oh, I see, industry. ", "start_char_idx": 3961, "end_char_idx": 4007, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5521157b-1012-470a-bd03-83849e265f18": {"__data__": {"id_": "5521157b-1012-470a-bd03-83849e265f18", "embedding": null, "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. ", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5423250-608d-4fd0-a28b-dafe99e23a4b", "node_type": "1", "metadata": {"window": "Yeah.  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n", "original_text": "Instructor (Andrew Ng) : Oh, I see, industry. "}, "hash": "3705ad1d727462bc70cf098a9e22d44a826fe907d8bf2102784bd6c59008dba6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "079b3d1e-6872-480f-b4c3-25173d15daf8", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n", "original_text": "Cool. "}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "079b3d1e-6872-480f-b4c3-25173d15daf8": {"__data__": {"id_": "079b3d1e-6872-480f-b4c3-25173d15daf8", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n", "original_text": "Cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5521157b-1012-470a-bd03-83849e265f18", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "29614fb0-02ae-4f51-b53e-dd7291a02e19", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning. ", "original_text": "Great, great. "}, "hash": "45b080814d27b340780db197c311010500338864bdbab7ad5568297ae30e618c", "class_name": "RelatedNodeInfo"}}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "text": "Cool. ", "start_char_idx": 3386, "end_char_idx": 3392, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "29614fb0-02ae-4f51-b53e-dd7291a02e19": {"__data__": {"id_": "29614fb0-02ae-4f51-b53e-dd7291a02e19", "embedding": null, "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning. ", "original_text": "Great, great. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "079b3d1e-6872-480f-b4c3-25173d15daf8", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Pardon?  \n Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n", "original_text": "Cool. "}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be4cb9e8-ac61-4e76-a136-68b99fb9aa59", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. ", "original_text": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n"}, "hash": "780f567470ac616c15302be2f99fbaafa87309706c13c265693f74cbc29054b5", "class_name": "RelatedNodeInfo"}}, "hash": "45b080814d27b340780db197c311010500338864bdbab7ad5568297ae30e618c", "text": "Great, great. ", "start_char_idx": 4019, "end_char_idx": 4033, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "be4cb9e8-ac61-4e76-a136-68b99fb9aa59": {"__data__": {"id_": "be4cb9e8-ac61-4e76-a136-68b99fb9aa59", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. ", "original_text": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "29614fb0-02ae-4f51-b53e-dd7291a02e19", "node_type": "1", "metadata": {"window": "Student : [Inaudible].  \n Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning. ", "original_text": "Great, great. "}, "hash": "45b080814d27b340780db197c311010500338864bdbab7ad5568297ae30e618c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "64d207b4-6214-45a0-bd3d-4ff7f9a949bd", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. ", "original_text": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. "}, "hash": "f49c991c0949d74ddebd63f19a518d31d1b6715adac342b07a9aaa1e0a879aec", "class_name": "RelatedNodeInfo"}}, "hash": "780f567470ac616c15302be2f99fbaafa87309706c13c265693f74cbc29054b5", "text": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n", "start_char_idx": 4033, "end_char_idx": 4237, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "64d207b4-6214-45a0-bd3d-4ff7f9a949bd": {"__data__": {"id_": "64d207b4-6214-45a0-bd3d-4ff7f9a949bd", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. ", "original_text": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be4cb9e8-ac61-4e76-a136-68b99fb9aa59", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Endo \u2014  \nStudent : [Inaudible].  \n Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. ", "original_text": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n"}, "hash": "780f567470ac616c15302be2f99fbaafa87309706c13c265693f74cbc29054b5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc00279f-14a2-4f02-b314-0cadfa05ab92", "node_type": "1", "metadata": {"window": "Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n", "original_text": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n"}, "hash": "37b98f57f7e4dd825302a412a9821346c3e5ae08dd86110f5add1c94eb58b169", "class_name": "RelatedNodeInfo"}}, "hash": "f49c991c0949d74ddebd63f19a518d31d1b6715adac342b07a9aaa1e0a879aec", "text": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. ", "start_char_idx": 4237, "end_char_idx": 4371, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc00279f-14a2-4f02-b314-0cadfa05ab92": {"__data__": {"id_": "bc00279f-14a2-4f02-b314-0cadfa05ab92", "embedding": null, "metadata": {"window": "Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n", "original_text": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "64d207b4-6214-45a0-bd3d-4ff7f9a949bd", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Oh, I see, industry.  Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. ", "original_text": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things. "}, "hash": "f49c991c0949d74ddebd63f19a518d31d1b6715adac342b07a9aaa1e0a879aec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "739917e5-73d7-447d-913b-b8ec8e81f009", "node_type": "1", "metadata": {"window": "Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. ", "original_text": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning. "}, "hash": "be381e4e6386c5bb8077717dd1346571766ee6fffca7997dd28fca9fdc4c43ab", "class_name": "RelatedNodeInfo"}}, "hash": "37b98f57f7e4dd825302a412a9821346c3e5ae08dd86110f5add1c94eb58b169", "text": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n", "start_char_idx": 4371, "end_char_idx": 4725, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "739917e5-73d7-447d-913b-b8ec8e81f009": {"__data__": {"id_": "739917e5-73d7-447d-913b-b8ec8e81f009", "embedding": null, "metadata": {"window": "Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. ", "original_text": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc00279f-14a2-4f02-b314-0cadfa05ab92", "node_type": "1", "metadata": {"window": "Okay.  Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n", "original_text": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n"}, "hash": "37b98f57f7e4dd825302a412a9821346c3e5ae08dd86110f5add1c94eb58b169", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "97a957d6-d9da-45fd-bdba-d4c6155bdc60", "node_type": "1", "metadata": {"window": "Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight. ", "original_text": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. "}, "hash": "9a26111bcd8d1b9f67b7dd6d552f3e095a2bde338c34882fcc17dfe636cffe4a", "class_name": "RelatedNodeInfo"}}, "hash": "be381e4e6386c5bb8077717dd1346571766ee6fffca7997dd28fca9fdc4c43ab", "text": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning. ", "start_char_idx": 4725, "end_char_idx": 4824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97a957d6-d9da-45fd-bdba-d4c6155bdc60": {"__data__": {"id_": "97a957d6-d9da-45fd-bdba-d4c6155bdc60", "embedding": null, "metadata": {"window": "Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight. ", "original_text": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "739917e5-73d7-447d-913b-b8ec8e81f009", "node_type": "1", "metadata": {"window": "Cool.  Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. ", "original_text": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning. "}, "hash": "be381e4e6386c5bb8077717dd1346571766ee6fffca7997dd28fca9fdc4c43ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a12dec1e-86bf-427f-9ee1-f5d811d912d2", "node_type": "1", "metadata": {"window": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n", "original_text": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. "}, "hash": "f4fd6ad79e18f60585d7b4f3d86e4284ecca21e095bb94682e802630bd3d586e", "class_name": "RelatedNodeInfo"}}, "hash": "9a26111bcd8d1b9f67b7dd6d552f3e095a2bde338c34882fcc17dfe636cffe4a", "text": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. ", "start_char_idx": 4824, "end_char_idx": 4924, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a12dec1e-86bf-427f-9ee1-f5d811d912d2": {"__data__": {"id_": "a12dec1e-86bf-427f-9ee1-f5d811d912d2", "embedding": null, "metadata": {"window": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n", "original_text": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "97a957d6-d9da-45fd-bdba-d4c6155bdc60", "node_type": "1", "metadata": {"window": "Great, great.  So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight. ", "original_text": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence. "}, "hash": "9a26111bcd8d1b9f67b7dd6d552f3e095a2bde338c34882fcc17dfe636cffe4a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b3a99b78-b28e-4a45-b364-9ba95ec3e816", "node_type": "1", "metadata": {"window": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n", "original_text": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n"}, "hash": "d3272aa4d4cd9eb1f6843078bcae74e7750f9c88a3e55e36c1f003184880a22c", "class_name": "RelatedNodeInfo"}}, "hash": "f4fd6ad79e18f60585d7b4f3d86e4284ecca21e095bb94682e802630bd3d586e", "text": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. ", "start_char_idx": 4924, "end_char_idx": 5056, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b3a99b78-b28e-4a45-b364-9ba95ec3e816": {"__data__": {"id_": "b3a99b78-b28e-4a45-b364-9ba95ec3e816", "embedding": null, "metadata": {"window": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n", "original_text": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a12dec1e-86bf-427f-9ee1-f5d811d912d2", "node_type": "1", "metadata": {"window": "So as you can \ntell from a cross-section of th is class, I think we're a very diverse audience in this room, \nand that's one of the things that makes this class fun to teach and fun to be in, I think.  \n\n So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n", "original_text": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. "}, "hash": "f4fd6ad79e18f60585d7b4f3d86e4284ecca21e095bb94682e802630bd3d586e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f1ebacbc-defd-4059-8c27-02a46f9ba11c", "node_type": "1", "metadata": {"window": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. ", "original_text": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. "}, "hash": "b7d9f9db28f723c5bc5d6343025ce7db7a77c57e98d5eae3cbd5e287c8ae1d80", "class_name": "RelatedNodeInfo"}}, "hash": "d3272aa4d4cd9eb1f6843078bcae74e7750f9c88a3e55e36c1f003184880a22c", "text": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n", "start_char_idx": 5056, "end_char_idx": 5184, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f1ebacbc-defd-4059-8c27-02a46f9ba11c": {"__data__": {"id_": "f1ebacbc-defd-4059-8c27-02a46f9ba11c", "embedding": null, "metadata": {"window": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. ", "original_text": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3a99b78-b28e-4a45-b364-9ba95ec3e816", "node_type": "1", "metadata": {"window": "So in this class, we've tried to convey to you a broad set of principl es and tools that will \nbe useful for doing many, many things.  And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n", "original_text": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n"}, "hash": "d3272aa4d4cd9eb1f6843078bcae74e7750f9c88a3e55e36c1f003184880a22c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a69f557f-853f-4953-a46a-deb1f7ff7726", "node_type": "1", "metadata": {"window": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n", "original_text": "And other things: One thing that my students and I do is autonomous flight. "}, "hash": "b8a589b1b3fa8733b7fdc5825875f3037e97ce31afe4f9e594be851168943875", "class_name": "RelatedNodeInfo"}}, "hash": "b7d9f9db28f723c5bc5d6343025ce7db7a77c57e98d5eae3cbd5e287c8ae1d80", "text": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. ", "start_char_idx": 5184, "end_char_idx": 5565, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a69f557f-853f-4953-a46a-deb1f7ff7726": {"__data__": {"id_": "a69f557f-853f-4953-a46a-deb1f7ff7726", "embedding": null, "metadata": {"window": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n", "original_text": "And other things: One thing that my students and I do is autonomous flight. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f1ebacbc-defd-4059-8c27-02a46f9ba11c", "node_type": "1", "metadata": {"window": "And ev ery time I teach this class, I can actually \nvery confidently say that af ter December, no matter what yo u're going to do after this \nDecember when you've sort of completed this  class, you'll find the things you learn in \nthis class very useful, and these things will be useful pretty much no matter what you end \nup doing later in your life.  \n So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. ", "original_text": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand. "}, "hash": "b7d9f9db28f723c5bc5d6343025ce7db7a77c57e98d5eae3cbd5e287c8ae1d80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3f7e73a5-69b8-45b6-9239-a576b1bc6acb", "node_type": "1", "metadata": {"window": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. ", "original_text": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n"}, "hash": "6cffd8ea99595be0d571b88525149eeabff1b1ddc98e592ff16e190f44be85f9", "class_name": "RelatedNodeInfo"}}, "hash": "b8a589b1b3fa8733b7fdc5825875f3037e97ce31afe4f9e594be851168943875", "text": "And other things: One thing that my students and I do is autonomous flight. ", "start_char_idx": 5565, "end_char_idx": 5641, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3f7e73a5-69b8-45b6-9239-a576b1bc6acb": {"__data__": {"id_": "3f7e73a5-69b8-45b6-9239-a576b1bc6acb", "embedding": null, "metadata": {"window": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. ", "original_text": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a69f557f-853f-4953-a46a-deb1f7ff7726", "node_type": "1", "metadata": {"window": "So I have more logistics to go over later, but let's say a few more words about machine \nlearning.  I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n", "original_text": "And other things: One thing that my students and I do is autonomous flight. "}, "hash": "b8a589b1b3fa8733b7fdc5825875f3037e97ce31afe4f9e594be851168943875", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c81b6ab2-bc6f-47f7-8da6-487fa4cc1f52", "node_type": "1", "metadata": {"window": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. ", "original_text": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n"}, "hash": "8055f9b7b432ab35893453b8c1fe6cefbe5f77a30e16a706b25f8ef01c340307", "class_name": "RelatedNodeInfo"}}, "hash": "6cffd8ea99595be0d571b88525149eeabff1b1ddc98e592ff16e190f44be85f9", "text": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n", "start_char_idx": 5641, "end_char_idx": 5738, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c81b6ab2-bc6f-47f7-8da6-487fa4cc1f52": {"__data__": {"id_": "c81b6ab2-bc6f-47f7-8da6-487fa4cc1f52", "embedding": null, "metadata": {"window": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. ", "original_text": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f7e73a5-69b8-45b6-9239-a576b1bc6acb", "node_type": "1", "metadata": {"window": "I feel that machine learning grew out of  early work in AI, early work in artificial \nintelligence.  And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. ", "original_text": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n"}, "hash": "6cffd8ea99595be0d571b88525149eeabff1b1ddc98e592ff16e190f44be85f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "806fbdf1-0dc1-438a-bcf6-1613e6d7fe0e", "node_type": "1", "metadata": {"window": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n", "original_text": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. "}, "hash": "35f4c9e6686ae001e9cae48115f4f8f63be807b9d26cac5d1734c64e9d878e3c", "class_name": "RelatedNodeInfo"}}, "hash": "8055f9b7b432ab35893453b8c1fe6cefbe5f77a30e16a706b25f8ef01c340307", "text": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n", "start_char_idx": 5738, "end_char_idx": 6011, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "806fbdf1-0dc1-438a-bcf6-1613e6d7fe0e": {"__data__": {"id_": "806fbdf1-0dc1-438a-bcf6-1613e6d7fe0e", "embedding": null, "metadata": {"window": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n", "original_text": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c81b6ab2-bc6f-47f7-8da6-487fa4cc1f52", "node_type": "1", "metadata": {"window": "And over the last \u2014 I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers.  And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. ", "original_text": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n"}, "hash": "8055f9b7b432ab35893453b8c1fe6cefbe5f77a30e16a706b25f8ef01c340307", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "97ce680d-4b8a-4e46-838a-d857b8f3bbbe", "node_type": "1", "metadata": {"window": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. ", "original_text": "It uses applications that are hard to program by hand.  \n"}, "hash": "6252ab60c1ee7c01c29789def485861dc2e76a96605fc3bd381fa016ff267665", "class_name": "RelatedNodeInfo"}}, "hash": "35f4c9e6686ae001e9cae48115f4f8f63be807b9d26cac5d1734c64e9d878e3c", "text": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. ", "start_char_idx": 6011, "end_char_idx": 6111, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97ce680d-4b8a-4e46-838a-d857b8f3bbbe": {"__data__": {"id_": "97ce680d-4b8a-4e46-838a-d857b8f3bbbe", "embedding": null, "metadata": {"window": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. ", "original_text": "It uses applications that are hard to program by hand.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "806fbdf1-0dc1-438a-bcf6-1613e6d7fe0e", "node_type": "1", "metadata": {"window": "And in particular, it turns out \nthat there are many programs or there are many applications that you can't program by \nhand.  \n For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n", "original_text": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well. "}, "hash": "35f4c9e6686ae001e9cae48115f4f8f63be807b9d26cac5d1734c64e9d878e3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d16acc9f-ef1f-451d-8cf0-e3dfb7bff45a", "node_type": "1", "metadata": {"window": "And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. ", "original_text": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. "}, "hash": "19f49b496dc527d32930be659cb290e06c7c93061acf89306b4be1e32f9a8ce9", "class_name": "RelatedNodeInfo"}}, "hash": "6252ab60c1ee7c01c29789def485861dc2e76a96605fc3bd381fa016ff267665", "text": "It uses applications that are hard to program by hand.  \n", "start_char_idx": 6111, "end_char_idx": 6168, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d16acc9f-ef1f-451d-8cf0-e3dfb7bff45a": {"__data__": {"id_": "d16acc9f-ef1f-451d-8cf0-e3dfb7bff45a", "embedding": null, "metadata": {"window": "And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. ", "original_text": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "97ce680d-4b8a-4e46-838a-d857b8f3bbbe", "node_type": "1", "metadata": {"window": "For example, if you want to get a computer to read handwritten characters, to read sort of \nhandwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \nsoftware to take this input, an image of some thing that I wrote and to  figure out just what \nit is, to translate my cursive handwriting into \u2014 to extract the characters I wrote out in \nlonghand.  And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. ", "original_text": "It uses applications that are hard to program by hand.  \n"}, "hash": "6252ab60c1ee7c01c29789def485861dc2e76a96605fc3bd381fa016ff267665", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28fed53b-6ee5-48ed-9cb4-a978cfbe7434", "node_type": "1", "metadata": {"window": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n", "original_text": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. "}, "hash": "149867184a95a552e3ce0d684fe4641eead75a707083bc5a71bebe73a9a6be30", "class_name": "RelatedNodeInfo"}}, "hash": "19f49b496dc527d32930be659cb290e06c7c93061acf89306b4be1e32f9a8ce9", "text": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. ", "start_char_idx": 6168, "end_char_idx": 6276, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "28fed53b-6ee5-48ed-9cb4-a978cfbe7434": {"__data__": {"id_": "28fed53b-6ee5-48ed-9cb4-a978cfbe7434", "embedding": null, "metadata": {"window": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n", "original_text": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d16acc9f-ef1f-451d-8cf0-e3dfb7bff45a", "node_type": "1", "metadata": {"window": "And other things: One thing that my students and I do is autonomous flight.  It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. ", "original_text": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining. "}, "hash": "19f49b496dc527d32930be659cb290e06c7c93061acf89306b4be1e32f9a8ce9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1fce667c-c143-4167-9886-3eb9b8cafb5d", "node_type": "1", "metadata": {"window": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. ", "original_text": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n"}, "hash": "c660f148e86674141400b92ed8df9a294cafdc5c3a5ca4578d06a640dbf19848", "class_name": "RelatedNodeInfo"}}, "hash": "149867184a95a552e3ce0d684fe4641eead75a707083bc5a71bebe73a9a6be30", "text": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. ", "start_char_idx": 6276, "end_char_idx": 6495, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1fce667c-c143-4167-9886-3eb9b8cafb5d": {"__data__": {"id_": "1fce667c-c143-4167-9886-3eb9b8cafb5d", "embedding": null, "metadata": {"window": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. ", "original_text": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "28fed53b-6ee5-48ed-9cb4-a978cfbe7434", "node_type": "1", "metadata": {"window": "It \nturns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n", "original_text": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was. "}, "hash": "149867184a95a552e3ce0d684fe4641eead75a707083bc5a71bebe73a9a6be30", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b4ed09af-1b81-47df-9d6d-d6640b666d78", "node_type": "1", "metadata": {"window": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n", "original_text": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. "}, "hash": "8992c19fa63308504f0e733894d830a8b08587c725f98c74732dd221c1b6f752", "class_name": "RelatedNodeInfo"}}, "hash": "c660f148e86674141400b92ed8df9a294cafdc5c3a5ca4578d06a640dbf19848", "text": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n", "start_char_idx": 6495, "end_char_idx": 7018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4ed09af-1b81-47df-9d6d-d6640b666d78": {"__data__": {"id_": "b4ed09af-1b81-47df-9d6d-d6640b666d78", "embedding": null, "metadata": {"window": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n", "original_text": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1fce667c-c143-4167-9886-3eb9b8cafb5d", "node_type": "1", "metadata": {"window": "But in contrast, if you want to do things like to get software to fl y a helicopter or have \nsoftware recognize handwritten digits, one very  successful approach is to use a learning \nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. ", "original_text": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n"}, "hash": "c660f148e86674141400b92ed8df9a294cafdc5c3a5ca4578d06a640dbf19848", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "832089fb-ae76-4182-a389-a539669d8a8f", "node_type": "1", "metadata": {"window": "It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n", "original_text": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. "}, "hash": "a55d68af6247dd1b8ca69c59164225d4d40076980662e704a0f5707f48dffa5f", "class_name": "RelatedNodeInfo"}}, "hash": "8992c19fa63308504f0e733894d830a8b08587c725f98c74732dd221c1b6f752", "text": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. ", "start_char_idx": 7018, "end_char_idx": 7199, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "832089fb-ae76-4182-a389-a539669d8a8f": {"__data__": {"id_": "832089fb-ae76-4182-a389-a539669d8a8f", "embedding": null, "metadata": {"window": "It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n", "original_text": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4ed09af-1b81-47df-9d6d-d6640b666d78", "node_type": "1", "metadata": {"window": "And in fact, handwritten digit recognition, this is pretty much the only approach that \nworks well.  It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n", "original_text": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it. "}, "hash": "8992c19fa63308504f0e733894d830a8b08587c725f98c74732dd221c1b6f752", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b0caad91-0adb-486b-8ac0-f6469d776d70", "node_type": "1", "metadata": {"window": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n", "original_text": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n"}, "hash": "373ac7250623cff283358639230c04276e97010e1383a32d434935fbf5475d4b", "class_name": "RelatedNodeInfo"}}, "hash": "a55d68af6247dd1b8ca69c59164225d4d40076980662e704a0f5707f48dffa5f", "text": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. ", "start_char_idx": 7199, "end_char_idx": 7418, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0caad91-0adb-486b-8ac0-f6469d776d70": {"__data__": {"id_": "b0caad91-0adb-486b-8ac0-f6469d776d70", "embedding": null, "metadata": {"window": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n", "original_text": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "832089fb-ae76-4182-a389-a539669d8a8f", "node_type": "1", "metadata": {"window": "It uses applications that are hard to program by hand.  \n Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n", "original_text": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm. "}, "hash": "a55d68af6247dd1b8ca69c59164225d4d40076980662e704a0f5707f48dffa5f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "15f3b207-bdb8-4a58-881a-22f28a8067da", "node_type": "1", "metadata": {"window": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n", "original_text": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. "}, "hash": "e7a8bbcebd4aad54e220e9cd189c8e3a99cde582c46b384dd07d4a1568ebbe06", "class_name": "RelatedNodeInfo"}}, "hash": "373ac7250623cff283358639230c04276e97010e1383a32d434935fbf5475d4b", "text": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n", "start_char_idx": 7418, "end_char_idx": 7531, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "15f3b207-bdb8-4a58-881a-22f28a8067da": {"__data__": {"id_": "15f3b207-bdb8-4a58-881a-22f28a8067da", "embedding": null, "metadata": {"window": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n", "original_text": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b0caad91-0adb-486b-8ac0-f6469d776d70", "node_type": "1", "metadata": {"window": "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \ndatabase mining.  So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n", "original_text": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n"}, "hash": "373ac7250623cff283358639230c04276e97010e1383a32d434935fbf5475d4b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c355ac2-e588-47e1-a35c-c4887640db32", "node_type": "1", "metadata": {"window": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n", "original_text": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n"}, "hash": "e166475c2d1537d30733f2344bbe827a256dfd3ba2c36876c2476d7f9c66a3fe", "class_name": "RelatedNodeInfo"}}, "hash": "e7a8bbcebd4aad54e220e9cd189c8e3a99cde582c46b384dd07d4a1568ebbe06", "text": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. ", "start_char_idx": 7531, "end_char_idx": 7800, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c355ac2-e588-47e1-a35c-c4887640db32": {"__data__": {"id_": "8c355ac2-e588-47e1-a35c-c4887640db32", "embedding": null, "metadata": {"window": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n", "original_text": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "15f3b207-bdb8-4a58-881a-22f28a8067da", "node_type": "1", "metadata": {"window": "So, for example, with the growth of IT and computers, increasingly \nmany hospitals are keeping around medical reco rds of what sort of patients, what \nproblems they had, what their prognoses was,  what the outcome was.  And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n", "original_text": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check. "}, "hash": "e7a8bbcebd4aad54e220e9cd189c8e3a99cde582c46b384dd07d4a1568ebbe06", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d9bf82f-2a03-4ac5-b256-bdc87a16db79", "node_type": "1", "metadata": {"window": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. ", "original_text": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n"}, "hash": "e322d679aeccdf6b29d7a794be69de681b301a37531fe620f8664312e4074fcf", "class_name": "RelatedNodeInfo"}}, "hash": "e166475c2d1537d30733f2344bbe827a256dfd3ba2c36876c2476d7f9c66a3fe", "text": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n", "start_char_idx": 7800, "end_char_idx": 7932, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6d9bf82f-2a03-4ac5-b256-bdc87a16db79": {"__data__": {"id_": "6d9bf82f-2a03-4ac5-b256-bdc87a16db79", "embedding": null, "metadata": {"window": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. ", "original_text": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c355ac2-e588-47e1-a35c-c4887640db32", "node_type": "1", "metadata": {"window": "And taking all of \nthese medical records, which started to be digitized only about maybe 15 years, applying \nlearning algorithms to them can turn raw medi cal records into what I might loosely call \nmedical knowledge in which we start to detect trends in medical practice and even start to \nalter medical practice as a result of me dical knowledge that's derived by applying \nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \nover the last 15, 20 years in an electronic format.  \n Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n", "original_text": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n"}, "hash": "e166475c2d1537d30733f2344bbe827a256dfd3ba2c36876c2476d7f9c66a3fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67e7e0f1-5c4c-4f35-ad12-a0eb46264e49", "node_type": "1", "metadata": {"window": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. ", "original_text": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n"}, "hash": "e124307d98d1f8cb615b9056b96484d321e7b4f1fa1e3a50d70bffb24bebda42", "class_name": "RelatedNodeInfo"}}, "hash": "e322d679aeccdf6b29d7a794be69de681b301a37531fe620f8664312e4074fcf", "text": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n", "start_char_idx": 7932, "end_char_idx": 8281, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67e7e0f1-5c4c-4f35-ad12-a0eb46264e49": {"__data__": {"id_": "67e7e0f1-5c4c-4f35-ad12-a0eb46264e49", "embedding": null, "metadata": {"window": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. ", "original_text": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6d9bf82f-2a03-4ac5-b256-bdc87a16db79", "node_type": "1", "metadata": {"window": "Turns out that most of you probably use learning algorithms \u2014 I don't know \u2014 I think \nhalf a dozen times a day or maybe a dozen  times a day or more, and often without \nknowing it.  So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. ", "original_text": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n"}, "hash": "e322d679aeccdf6b29d7a794be69de681b301a37531fe620f8664312e4074fcf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba529973-7093-4808-87ea-aa839f96716f", "node_type": "1", "metadata": {"window": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n", "original_text": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n"}, "hash": "2632da7484eafccd12db97c204731bfd76fc0050c9155ca0dda48f823dbb25a4", "class_name": "RelatedNodeInfo"}}, "hash": "e124307d98d1f8cb615b9056b96484d321e7b4f1fa1e3a50d70bffb24bebda42", "text": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n", "start_char_idx": 8281, "end_char_idx": 8622, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba529973-7093-4808-87ea-aa839f96716f": {"__data__": {"id_": "ba529973-7093-4808-87ea-aa839f96716f", "embedding": null, "metadata": {"window": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n", "original_text": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67e7e0f1-5c4c-4f35-ad12-a0eb46264e49", "node_type": "1", "metadata": {"window": "So, for example, every time you se nd mail via the US Postal System, turns \nout there's an algorithm that tries to automa tically read the zip code you wrote on your \nenvelope, and that's done by a learning al gorithm.  So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. ", "original_text": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n"}, "hash": "e124307d98d1f8cb615b9056b96484d321e7b4f1fa1e3a50d70bffb24bebda42", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac19a687-8daa-4832-9534-85587ef13d60", "node_type": "1", "metadata": {"window": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals. ", "original_text": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n"}, "hash": "aa38b67014b129f5414485a3aeb6d173bf064b197ca42059afe2a36a42c6d62f", "class_name": "RelatedNodeInfo"}}, "hash": "2632da7484eafccd12db97c204731bfd76fc0050c9155ca0dda48f823dbb25a4", "text": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n", "start_char_idx": 8622, "end_char_idx": 8883, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac19a687-8daa-4832-9534-85587ef13d60": {"__data__": {"id_": "ac19a687-8daa-4832-9534-85587ef13d60", "embedding": null, "metadata": {"window": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals. ", "original_text": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba529973-7093-4808-87ea-aa839f96716f", "node_type": "1", "metadata": {"window": "So every time you send US mail, you \nare using a learning algorithm, perhap s without even being aware of it.  \n\n Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n", "original_text": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n"}, "hash": "2632da7484eafccd12db97c204731bfd76fc0050c9155ca0dda48f823dbb25a4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "905a0c4f-785c-4642-8b4c-26aac4624f1e", "node_type": "1", "metadata": {"window": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n", "original_text": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. "}, "hash": "ed644052d0431fd578736dd16044366769260dea5de2a58640c126a1b9adf1de", "class_name": "RelatedNodeInfo"}}, "hash": "aa38b67014b129f5414485a3aeb6d173bf064b197ca42059afe2a36a42c6d62f", "text": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n", "start_char_idx": 8883, "end_char_idx": 9000, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "905a0c4f-785c-4642-8b4c-26aac4624f1e": {"__data__": {"id_": "905a0c4f-785c-4642-8b4c-26aac4624f1e", "embedding": null, "metadata": {"window": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n", "original_text": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac19a687-8daa-4832-9534-85587ef13d60", "node_type": "1", "metadata": {"window": "Similarly, every time you write a check, I ac tually don't know the number for this, but a \nsignificant fraction of checks that you write are processed by a learning algorithm that's \nlearned to read the digits, so the dolla r amount that you wrote down on your check.  So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals. ", "original_text": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n"}, "hash": "aa38b67014b129f5414485a3aeb6d173bf064b197ca42059afe2a36a42c6d62f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b79cd5dd-16d7-4d58-8e08-285d3d96c41f", "node_type": "1", "metadata": {"window": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. ", "original_text": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. "}, "hash": "fb396cec1c03f8d33bdeee48eeda94a9fd311f974515f3b9c5c251a8e7690a1a", "class_name": "RelatedNodeInfo"}}, "hash": "ed644052d0431fd578736dd16044366769260dea5de2a58640c126a1b9adf1de", "text": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. ", "start_char_idx": 9000, "end_char_idx": 9119, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b79cd5dd-16d7-4d58-8e08-285d3d96c41f": {"__data__": {"id_": "b79cd5dd-16d7-4d58-8e08-285d3d96c41f", "embedding": null, "metadata": {"window": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. ", "original_text": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "905a0c4f-785c-4642-8b4c-26aac4624f1e", "node_type": "1", "metadata": {"window": "So \nevery time you write a check, there's anot her learning algorithm that you're probably \nusing without even being aware of it.  \n If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n", "original_text": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome. "}, "hash": "ed644052d0431fd578736dd16044366769260dea5de2a58640c126a1b9adf1de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6a6f92a5-e827-40c4-a6b1-88a1e4e36cda", "node_type": "1", "metadata": {"window": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n", "original_text": "That's sort of the thing that Tom \nworks on, yes?  \n"}, "hash": "792ba69dbd6f1df7f307167a44188bb8f267a6c4c12da97cc1bdfc3c48c157ff", "class_name": "RelatedNodeInfo"}}, "hash": "fb396cec1c03f8d33bdeee48eeda94a9fd311f974515f3b9c5c251a8e7690a1a", "text": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. ", "start_char_idx": 9119, "end_char_idx": 9229, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6a6f92a5-e827-40c4-a6b1-88a1e4e36cda": {"__data__": {"id_": "6a6f92a5-e827-40c4-a6b1-88a1e4e36cda", "embedding": null, "metadata": {"window": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n", "original_text": "That's sort of the thing that Tom \nworks on, yes?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b79cd5dd-16d7-4d58-8e08-285d3d96c41f", "node_type": "1", "metadata": {"window": "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \ncompanies like eBay as well that do electr onic transactions, there's a good chance that \nthere's a learning algorithm in the backgr ound trying to figure out if, say, your credit \ncard's been stolen or if someone's engaging in a fraudulent transaction.  \n If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. ", "original_text": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that. "}, "hash": "fb396cec1c03f8d33bdeee48eeda94a9fd311f974515f3b9c5c251a8e7690a1a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "50c8e165-a00a-4d10-b21f-8787dcfcf71d", "node_type": "1", "metadata": {"window": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n", "original_text": "So in teaching this class, I sort of have thre e goals. "}, "hash": "478fdbdba95a0648eab979831a1c7f8ec6bfed36756a482f11679ffb4b4024df", "class_name": "RelatedNodeInfo"}}, "hash": "792ba69dbd6f1df7f307167a44188bb8f267a6c4c12da97cc1bdfc3c48c157ff", "text": "That's sort of the thing that Tom \nworks on, yes?  \n", "start_char_idx": 9229, "end_char_idx": 9281, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "50c8e165-a00a-4d10-b21f-8787dcfcf71d": {"__data__": {"id_": "50c8e165-a00a-4d10-b21f-8787dcfcf71d", "embedding": null, "metadata": {"window": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n", "original_text": "So in teaching this class, I sort of have thre e goals. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a6f92a5-e827-40c4-a6b1-88a1e4e36cda", "node_type": "1", "metadata": {"window": "If you use a website like Amazon or Netflix that will often recommend books for you to \nbuy or movies for you to rent or whatever , these are other examples of learning \nalgorithms that have learned what sorts of th ings you like to buy or what sorts of movies \nyou like to watch and can therefore give  customized recommendations to you.  \n Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n", "original_text": "That's sort of the thing that Tom \nworks on, yes?  \n"}, "hash": "792ba69dbd6f1df7f307167a44188bb8f267a6c4c12da97cc1bdfc3c48c157ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e472862-192e-4b42-ac12-fa06aa0f55d0", "node_type": "1", "metadata": {"window": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics. ", "original_text": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n"}, "hash": "b2d0f1cc4805120dfdd11cd33573ef685dd06aa3a98e3e36e2fa4d54c9176d8e", "class_name": "RelatedNodeInfo"}}, "hash": "478fdbdba95a0648eab979831a1c7f8ec6bfed36756a482f11679ffb4b4024df", "text": "So in teaching this class, I sort of have thre e goals. ", "start_char_idx": 9281, "end_char_idx": 9337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7e472862-192e-4b42-ac12-fa06aa0f55d0": {"__data__": {"id_": "7e472862-192e-4b42-ac12-fa06aa0f55d0", "embedding": null, "metadata": {"window": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics. ", "original_text": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "50c8e165-a00a-4d10-b21f-8787dcfcf71d", "node_type": "1", "metadata": {"window": "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \nto explain to me some learning algorithm in th e innards of my car th at's sort of doing its \nbest to optimize my driving performan ce for fuel efficiency or something.  \n So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n", "original_text": "So in teaching this class, I sort of have thre e goals. "}, "hash": "478fdbdba95a0648eab979831a1c7f8ec6bfed36756a482f11679ffb4b4024df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "468274fc-2062-4428-b75e-ea271626ca50", "node_type": "1", "metadata": {"window": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. ", "original_text": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. "}, "hash": "e48a0a686cc5fda81a5884e05c9a0d847b2ba0bd870c462bd253a2d5918cfcd7", "class_name": "RelatedNodeInfo"}}, "hash": "b2d0f1cc4805120dfdd11cd33573ef685dd06aa3a98e3e36e2fa4d54c9176d8e", "text": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n", "start_char_idx": 9337, "end_char_idx": 9435, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "468274fc-2062-4428-b75e-ea271626ca50": {"__data__": {"id_": "468274fc-2062-4428-b75e-ea271626ca50", "embedding": null, "metadata": {"window": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. ", "original_text": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e472862-192e-4b42-ac12-fa06aa0f55d0", "node_type": "1", "metadata": {"window": "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \nwithout even knowing it.  \n And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics. ", "original_text": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n"}, "hash": "b2d0f1cc4805120dfdd11cd33573ef685dd06aa3a98e3e36e2fa4d54c9176d8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c815abe7-aa83-459d-a855-7c6d3146aa52", "node_type": "1", "metadata": {"window": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. ", "original_text": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n"}, "hash": "366b32be06a4b260adccdee7c7fe61a7ae333ab024b2c719c2420e787895f7b6", "class_name": "RelatedNodeInfo"}}, "hash": "e48a0a686cc5fda81a5884e05c9a0d847b2ba0bd870c462bd253a2d5918cfcd7", "text": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. ", "start_char_idx": 9435, "end_char_idx": 9611, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c815abe7-aa83-459d-a855-7c6d3146aa52": {"__data__": {"id_": "c815abe7-aa83-459d-a855-7c6d3146aa52", "embedding": null, "metadata": {"window": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. ", "original_text": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "468274fc-2062-4428-b75e-ea271626ca50", "node_type": "1", "metadata": {"window": "And of course, learning algorithms are also  doing things like giving us a growing \nunderstanding of the human genome.  So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. ", "original_text": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in. "}, "hash": "e48a0a686cc5fda81a5884e05c9a0d847b2ba0bd870c462bd253a2d5918cfcd7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "310c4dc0-fdbe-4439-b842-93bb6b56fe40", "node_type": "1", "metadata": {"window": "That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. ", "original_text": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n"}, "hash": "5d15bacd3b41e6b04aa84536d80c3884cadf5577c8cd16e32e53228805aadb26", "class_name": "RelatedNodeInfo"}}, "hash": "366b32be06a4b260adccdee7c7fe61a7ae333ab024b2c719c2420e787895f7b6", "text": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n", "start_char_idx": 9611, "end_char_idx": 9731, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "310c4dc0-fdbe-4439-b842-93bb6b56fe40": {"__data__": {"id_": "310c4dc0-fdbe-4439-b842-93bb6b56fe40", "embedding": null, "metadata": {"window": "That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. ", "original_text": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c815abe7-aa83-459d-a855-7c6d3146aa52", "node_type": "1", "metadata": {"window": "So if so meday we ever find a cure for cancer, I bet \nlearning algorithms will have had a large role in that.  That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. ", "original_text": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n"}, "hash": "366b32be06a4b260adccdee7c7fe61a7ae333ab024b2c719c2420e787895f7b6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "53612ea8-f03a-4003-b9ec-fefc2f8e6c90", "node_type": "1", "metadata": {"window": "So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n", "original_text": "So let's say a few words about logistics. "}, "hash": "b0719490f57904724f0a9f513a354b979e878a91028cd7c93cdda567be43176f", "class_name": "RelatedNodeInfo"}}, "hash": "5d15bacd3b41e6b04aa84536d80c3884cadf5577c8cd16e32e53228805aadb26", "text": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n", "start_char_idx": 9731, "end_char_idx": 10011, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "53612ea8-f03a-4003-b9ec-fefc2f8e6c90": {"__data__": {"id_": "53612ea8-f03a-4003-b9ec-fefc2f8e6c90", "embedding": null, "metadata": {"window": "So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n", "original_text": "So let's say a few words about logistics. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "310c4dc0-fdbe-4439-b842-93bb6b56fe40", "node_type": "1", "metadata": {"window": "That's sort of the thing that Tom \nworks on, yes?  \n So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. ", "original_text": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n"}, "hash": "5d15bacd3b41e6b04aa84536d80c3884cadf5577c8cd16e32e53228805aadb26", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdaa5ec9-5491-49f1-b6e2-1f3cfc2222b2", "node_type": "1", "metadata": {"window": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics. ", "original_text": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. "}, "hash": "332dd20a59159e1866cd11c287eb463b16c064cbeb626989a65583848417d14f", "class_name": "RelatedNodeInfo"}}, "hash": "b0719490f57904724f0a9f513a354b979e878a91028cd7c93cdda567be43176f", "text": "So let's say a few words about logistics. ", "start_char_idx": 10011, "end_char_idx": 10053, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bdaa5ec9-5491-49f1-b6e2-1f3cfc2222b2": {"__data__": {"id_": "bdaa5ec9-5491-49f1-b6e2-1f3cfc2222b2", "embedding": null, "metadata": {"window": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics. ", "original_text": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "53612ea8-f03a-4003-b9ec-fefc2f8e6c90", "node_type": "1", "metadata": {"window": "So in teaching this class, I sort of have thre e goals.  One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n", "original_text": "So let's say a few words about logistics. "}, "hash": "b0719490f57904724f0a9f513a354b979e878a91028cd7c93cdda567be43176f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f4d57d34-b415-45a2-b3f1-7f1cb877b243", "node_type": "1", "metadata": {"window": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. ", "original_text": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. "}, "hash": "35dbe75be7c9c195fd6e545dca2a33a08a38236f8dbce64eeaf2924e32c71709", "class_name": "RelatedNodeInfo"}}, "hash": "332dd20a59159e1866cd11c287eb463b16c064cbeb626989a65583848417d14f", "text": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. ", "start_char_idx": 10053, "end_char_idx": 10300, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f4d57d34-b415-45a2-b3f1-7f1cb877b243": {"__data__": {"id_": "f4d57d34-b415-45a2-b3f1-7f1cb877b243", "embedding": null, "metadata": {"window": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. ", "original_text": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdaa5ec9-5491-49f1-b6e2-1f3cfc2222b2", "node_type": "1", "metadata": {"window": "One of them is just to I hope convey \nsome of my own excitement a bout machine learning to you.  \n The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics. ", "original_text": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples. "}, "hash": "332dd20a59159e1866cd11c287eb463b16c064cbeb626989a65583848417d14f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "88b5d06b-4c20-4b09-b1c5-e0b555854488", "node_type": "1", "metadata": {"window": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. ", "original_text": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. "}, "hash": "b3f7d56353f838b31a7aaa4f326ae1c25be94f12e12ef062be9f0d67007746fc", "class_name": "RelatedNodeInfo"}}, "hash": "35dbe75be7c9c195fd6e545dca2a33a08a38236f8dbce64eeaf2924e32c71709", "text": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. ", "start_char_idx": 10300, "end_char_idx": 10534, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "88b5d06b-4c20-4b09-b1c5-e0b555854488": {"__data__": {"id_": "88b5d06b-4c20-4b09-b1c5-e0b555854488", "embedding": null, "metadata": {"window": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. ", "original_text": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4d57d34-b415-45a2-b3f1-7f1cb877b243", "node_type": "1", "metadata": {"window": "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\nthe-art machine learning algorithms to whatev er problems you're interested in.  And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. ", "original_text": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program. "}, "hash": "35dbe75be7c9c195fd6e545dca2a33a08a38236f8dbce64eeaf2924e32c71709", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "707e4f64-596f-4f5d-adf2-6c105cd2781c", "node_type": "1", "metadata": {"window": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material. ", "original_text": "I'll say a bit more about that later.  \n"}, "hash": "ef7853d2f8320c37609ef07aeabf19cce7e093ee141521f2b04911e5834183ee", "class_name": "RelatedNodeInfo"}}, "hash": "b3f7d56353f838b31a7aaa4f326ae1c25be94f12e12ef062be9f0d67007746fc", "text": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. ", "start_char_idx": 10534, "end_char_idx": 10693, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "707e4f64-596f-4f5d-adf2-6c105cd2781c": {"__data__": {"id_": "707e4f64-596f-4f5d-adf2-6c105cd2781c", "embedding": null, "metadata": {"window": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material. ", "original_text": "I'll say a bit more about that later.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "88b5d06b-4c20-4b09-b1c5-e0b555854488", "node_type": "1", "metadata": {"window": "And if you \never need to build a system for reading zi p codes, you'll know how to do that by the end \nof this class.  \n And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. ", "original_text": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve. "}, "hash": "b3f7d56353f838b31a7aaa4f326ae1c25be94f12e12ef062be9f0d67007746fc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c8da8742-a327-4c2b-ba3d-cc81b8709673", "node_type": "1", "metadata": {"window": "So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n", "original_text": "I also assume familiarity with basic proba bility and statistics. "}, "hash": "25dc039807c69294322af865fa638fe5260a15aab4b2709f563700e485b57d76", "class_name": "RelatedNodeInfo"}}, "hash": "ef7853d2f8320c37609ef07aeabf19cce7e093ee141521f2b04911e5834183ee", "text": "I'll say a bit more about that later.  \n", "start_char_idx": 10693, "end_char_idx": 10733, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c8da8742-a327-4c2b-ba3d-cc81b8709673": {"__data__": {"id_": "c8da8742-a327-4c2b-ba3d-cc81b8709673", "embedding": null, "metadata": {"window": "So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n", "original_text": "I also assume familiarity with basic proba bility and statistics. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "707e4f64-596f-4f5d-adf2-6c105cd2781c", "node_type": "1", "metadata": {"window": "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \nyou will actually be well qualified to star t doing research in machine learning, okay?  \n So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material. ", "original_text": "I'll say a bit more about that later.  \n"}, "hash": "ef7853d2f8320c37609ef07aeabf19cce7e093ee141521f2b04911e5834183ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71c7e64a-e396-4147-8c62-754832b3ec70", "node_type": "1", "metadata": {"window": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n", "original_text": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. "}, "hash": "38005dac6bcdb1778f061d0555cede3ca9f8ff3798f75e9ee2a58ea8472b4140", "class_name": "RelatedNodeInfo"}}, "hash": "25dc039807c69294322af865fa638fe5260a15aab4b2709f563700e485b57d76", "text": "I also assume familiarity with basic proba bility and statistics. ", "start_char_idx": 10733, "end_char_idx": 10799, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "71c7e64a-e396-4147-8c62-754832b3ec70": {"__data__": {"id_": "71c7e64a-e396-4147-8c62-754832b3ec70", "embedding": null, "metadata": {"window": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n", "original_text": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8da8742-a327-4c2b-ba3d-cc81b8709673", "node_type": "1", "metadata": {"window": "So let's say a few words about logistics.  The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n", "original_text": "I also assume familiarity with basic proba bility and statistics. "}, "hash": "25dc039807c69294322af865fa638fe5260a15aab4b2709f563700e485b57d76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8eea312-60f8-4b10-96ab-b6d2d920bf41", "node_type": "1", "metadata": {"window": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra. ", "original_text": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. "}, "hash": "275d54dd7cba191f7e38821176409ec5123b1e22a87055561a58feb6809252f1", "class_name": "RelatedNodeInfo"}}, "hash": "38005dac6bcdb1778f061d0555cede3ca9f8ff3798f75e9ee2a58ea8472b4140", "text": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. ", "start_char_idx": 10799, "end_char_idx": 10905, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8eea312-60f8-4b10-96ab-b6d2d920bf41": {"__data__": {"id_": "a8eea312-60f8-4b10-96ab-b6d2d920bf41", "embedding": null, "metadata": {"window": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra. ", "original_text": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71c7e64a-e396-4147-8c62-754832b3ec70", "node_type": "1", "metadata": {"window": "The prerequisites of this class are written on one \nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \nof basic knowledge of computer science and kn owledge of the basic computer skills and \nprinciples.  So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n", "original_text": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. "}, "hash": "38005dac6bcdb1778f061d0555cede3ca9f8ff3798f75e9ee2a58ea8472b4140", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "90efa3a3-8eec-4bd5-a57e-10edd2b3fc91", "node_type": "1", "metadata": {"window": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough. ", "original_text": "And in case of some of you, it's been a while \nsince you've seen some of this material. "}, "hash": "2a5132fb9f7922d5e1e5d085ee0de808c40007d1ef0fc730f9be55462a663a52", "class_name": "RelatedNodeInfo"}}, "hash": "275d54dd7cba191f7e38821176409ec5123b1e22a87055561a58feb6809252f1", "text": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. ", "start_char_idx": 10905, "end_char_idx": 11051, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "90efa3a3-8eec-4bd5-a57e-10edd2b3fc91": {"__data__": {"id_": "90efa3a3-8eec-4bd5-a57e-10edd2b3fc91", "embedding": null, "metadata": {"window": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough. ", "original_text": "And in case of some of you, it's been a while \nsince you've seen some of this material. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8eea312-60f8-4b10-96ab-b6d2d920bf41", "node_type": "1", "metadata": {"window": "So I assume all of you know what big?O notation, that all of you know about \nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \nprogramming skills to, like, write a simple co mputer program.  And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra. ", "original_text": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is. "}, "hash": "275d54dd7cba191f7e38821176409ec5123b1e22a87055561a58feb6809252f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a568f1c5-01cf-4c4f-bb59-cbcf68c630ac", "node_type": "1", "metadata": {"window": "I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. ", "original_text": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n"}, "hash": "38716384e6fd21f3332a53b5ca0d8102db8c7d3c1b7f522b2b9b257db5dfc1ce", "class_name": "RelatedNodeInfo"}}, "hash": "2a5132fb9f7922d5e1e5d085ee0de808c40007d1ef0fc730f9be55462a663a52", "text": "And in case of some of you, it's been a while \nsince you've seen some of this material. ", "start_char_idx": 11051, "end_char_idx": 11139, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a568f1c5-01cf-4c4f-bb59-cbcf68c630ac": {"__data__": {"id_": "a568f1c5-01cf-4c4f-bb59-cbcf68c630ac", "embedding": null, "metadata": {"window": "I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. ", "original_text": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "90efa3a3-8eec-4bd5-a57e-10edd2b3fc91", "node_type": "1", "metadata": {"window": "And it turns out that most \n\nof this class will not be very program ming intensive, although we will do some \nprogramming, mostly in either MATLAB or Octa ve.  I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough. ", "original_text": "And in case of some of you, it's been a while \nsince you've seen some of this material. "}, "hash": "2a5132fb9f7922d5e1e5d085ee0de808c40007d1ef0fc730f9be55462a663a52", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "736b0947-88bc-46ec-ac5f-8def163c6cdb", "node_type": "1", "metadata": {"window": "I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. ", "original_text": "I'll say a bit more about that later as well.  \n"}, "hash": "58ecfb8b4d0a2eb02952b50ad3c5f2b42a891e4ce05be54976145e97a89fc9b3", "class_name": "RelatedNodeInfo"}}, "hash": "38716384e6fd21f3332a53b5ca0d8102db8c7d3c1b7f522b2b9b257db5dfc1ce", "text": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n", "start_char_idx": 11139, "end_char_idx": 11284, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "736b0947-88bc-46ec-ac5f-8def163c6cdb": {"__data__": {"id_": "736b0947-88bc-46ec-ac5f-8def163c6cdb", "embedding": null, "metadata": {"window": "I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. ", "original_text": "I'll say a bit more about that later as well.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a568f1c5-01cf-4c4f-bb59-cbcf68c630ac", "node_type": "1", "metadata": {"window": "I'll say a bit more about that later.  \n I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. ", "original_text": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n"}, "hash": "38716384e6fd21f3332a53b5ca0d8102db8c7d3c1b7f522b2b9b257db5dfc1ce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e8059fbe-8c4e-4c28-a42d-b361ff0a0cb1", "node_type": "1", "metadata": {"window": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n", "original_text": "Lastly, I also assume familiarity with basi c linear algebra. "}, "hash": "79d0ed17d93bfd08ad53aec1963f50b930124267c68efe496a97aca5b582dc7b", "class_name": "RelatedNodeInfo"}}, "hash": "58ecfb8b4d0a2eb02952b50ad3c5f2b42a891e4ce05be54976145e97a89fc9b3", "text": "I'll say a bit more about that later as well.  \n", "start_char_idx": 11284, "end_char_idx": 11332, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8059fbe-8c4e-4c28-a42d-b361ff0a0cb1": {"__data__": {"id_": "e8059fbe-8c4e-4c28-a42d-b361ff0a0cb1", "embedding": null, "metadata": {"window": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n", "original_text": "Lastly, I also assume familiarity with basi c linear algebra. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "736b0947-88bc-46ec-ac5f-8def163c6cdb", "node_type": "1", "metadata": {"window": "I also assume familiarity with basic proba bility and statistics.  So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. ", "original_text": "I'll say a bit more about that later as well.  \n"}, "hash": "58ecfb8b4d0a2eb02952b50ad3c5f2b42a891e4ce05be54976145e97a89fc9b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e9356c27-9f45-469b-b3e8-92ccc77e8479", "node_type": "1", "metadata": {"window": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too. ", "original_text": "And again, most undergraduate \nlinear algebra courses are more than enough. "}, "hash": "7c3a9efb8f83590719dfbf3e70e7da5c8be27e50b77794f1f0324213e4a79d9f", "class_name": "RelatedNodeInfo"}}, "hash": "79d0ed17d93bfd08ad53aec1963f50b930124267c68efe496a97aca5b582dc7b", "text": "Lastly, I also assume familiarity with basi c linear algebra. ", "start_char_idx": 11332, "end_char_idx": 11394, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e9356c27-9f45-469b-b3e8-92ccc77e8479": {"__data__": {"id_": "e9356c27-9f45-469b-b3e8-92ccc77e8479", "embedding": null, "metadata": {"window": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too. ", "original_text": "And again, most undergraduate \nlinear algebra courses are more than enough. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e8059fbe-8c4e-4c28-a42d-b361ff0a0cb1", "node_type": "1", "metadata": {"window": "So most undergraduate \nstatistics class, like Stat 116 taught here at Stanford, will be more than enough.  I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n", "original_text": "Lastly, I also assume familiarity with basi c linear algebra. "}, "hash": "79d0ed17d93bfd08ad53aec1963f50b930124267c68efe496a97aca5b582dc7b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0de43831-200d-4c50-b3b2-92a15040f35c", "node_type": "1", "metadata": {"window": "And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n", "original_text": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. "}, "hash": "252d00679af40a9428e76683d8184cacf74dd4044aae49bdf59422c1145f4878", "class_name": "RelatedNodeInfo"}}, "hash": "7c3a9efb8f83590719dfbf3e70e7da5c8be27e50b77794f1f0324213e4a79d9f", "text": "And again, most undergraduate \nlinear algebra courses are more than enough. ", "start_char_idx": 11394, "end_char_idx": 11470, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0de43831-200d-4c50-b3b2-92a15040f35c": {"__data__": {"id_": "0de43831-200d-4c50-b3b2-92a15040f35c", "embedding": null, "metadata": {"window": "And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n", "original_text": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e9356c27-9f45-469b-b3e8-92ccc77e8479", "node_type": "1", "metadata": {"window": "I'm gonna \nassume all of you know what ra ndom variables are, that all of you know what expectation \nis, what a variance or a random variable is.  And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too. ", "original_text": "And again, most undergraduate \nlinear algebra courses are more than enough. "}, "hash": "7c3a9efb8f83590719dfbf3e70e7da5c8be27e50b77794f1f0324213e4a79d9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "329470c1-b402-4402-a19d-2180fa89a01b", "node_type": "1", "metadata": {"window": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class. ", "original_text": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. "}, "hash": "8c2c138944f1d2bc503c1d5c2ae851c6f2be9a06c96c61d47a8152fc2c58c37d", "class_name": "RelatedNodeInfo"}}, "hash": "252d00679af40a9428e76683d8184cacf74dd4044aae49bdf59422c1145f4878", "text": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. ", "start_char_idx": 11470, "end_char_idx": 11580, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "329470c1-b402-4402-a19d-2180fa89a01b": {"__data__": {"id_": "329470c1-b402-4402-a19d-2180fa89a01b", "embedding": null, "metadata": {"window": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class. ", "original_text": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0de43831-200d-4c50-b3b2-92a15040f35c", "node_type": "1", "metadata": {"window": "And in case of some of you, it's been a while \nsince you've seen some of this material.  At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n", "original_text": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough. "}, "hash": "252d00679af40a9428e76683d8184cacf74dd4044aae49bdf59422c1145f4878", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a5c15082-c1db-4f6d-95b1-9e53b9ccd2f2", "node_type": "1", "metadata": {"window": "I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss. ", "original_text": "If you know what an eigenvect or of a matrix is, that'd be even better. \n"}, "hash": "325ed0caecdb468ce59082534aef58ddb29eb442df07a55e65fcea4357c7ab77", "class_name": "RelatedNodeInfo"}}, "hash": "8c2c138944f1d2bc503c1d5c2ae851c6f2be9a06c96c61d47a8152fc2c58c37d", "text": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. ", "start_char_idx": 11580, "end_char_idx": 11788, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a5c15082-c1db-4f6d-95b1-9e53b9ccd2f2": {"__data__": {"id_": "a5c15082-c1db-4f6d-95b1-9e53b9ccd2f2", "embedding": null, "metadata": {"window": "I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss. ", "original_text": "If you know what an eigenvect or of a matrix is, that'd be even better. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "329470c1-b402-4402-a19d-2180fa89a01b", "node_type": "1", "metadata": {"window": "At some of the discussion sections, we'll actually \ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class. ", "original_text": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. "}, "hash": "8c2c138944f1d2bc503c1d5c2ae851c6f2be9a06c96c61d47a8152fc2c58c37d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9bccb95-1fa9-4a3a-9f4d-ea090ceb281a", "node_type": "1", "metadata": {"window": "Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n", "original_text": "But if you don't quite know or if you're not qu ite sure, that's fine, too. "}, "hash": "c0b47bf5a1379db32fc52b3ac93be17368eb25731fc0acc7ea74cf55fba9cdf1", "class_name": "RelatedNodeInfo"}}, "hash": "325ed0caecdb468ce59082534aef58ddb29eb442df07a55e65fcea4357c7ab77", "text": "If you know what an eigenvect or of a matrix is, that'd be even better. \n", "start_char_idx": 11788, "end_char_idx": 11861, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d9bccb95-1fa9-4a3a-9f4d-ea090ceb281a": {"__data__": {"id_": "d9bccb95-1fa9-4a3a-9f4d-ea090ceb281a", "embedding": null, "metadata": {"window": "Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n", "original_text": "But if you don't quite know or if you're not qu ite sure, that's fine, too. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a5c15082-c1db-4f6d-95b1-9e53b9ccd2f2", "node_type": "1", "metadata": {"window": "I'll say a bit more about that later as well.  \n Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss. ", "original_text": "If you know what an eigenvect or of a matrix is, that'd be even better. \n"}, "hash": "325ed0caecdb468ce59082534aef58ddb29eb442df07a55e65fcea4357c7ab77", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b25156a-87c4-45cc-8da4-5f78ba11596f", "node_type": "1", "metadata": {"window": "And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. ", "original_text": "We'll go over it in \nthe review sections.  \n"}, "hash": "8da2a6131a75e31c4f8605b2e0332d0f0a2cabf3674328ae987b5661d1952e75", "class_name": "RelatedNodeInfo"}}, "hash": "c0b47bf5a1379db32fc52b3ac93be17368eb25731fc0acc7ea74cf55fba9cdf1", "text": "But if you don't quite know or if you're not qu ite sure, that's fine, too. ", "start_char_idx": 11861, "end_char_idx": 11937, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b25156a-87c4-45cc-8da4-5f78ba11596f": {"__data__": {"id_": "5b25156a-87c4-45cc-8da4-5f78ba11596f", "embedding": null, "metadata": {"window": "And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. ", "original_text": "We'll go over it in \nthe review sections.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9bccb95-1fa9-4a3a-9f4d-ea090ceb281a", "node_type": "1", "metadata": {"window": "Lastly, I also assume familiarity with basi c linear algebra.  And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n", "original_text": "But if you don't quite know or if you're not qu ite sure, that's fine, too. "}, "hash": "c0b47bf5a1379db32fc52b3ac93be17368eb25731fc0acc7ea74cf55fba9cdf1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a4ed568-3f83-4d91-b199-5fb596bafd79", "node_type": "1", "metadata": {"window": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. ", "original_text": "So there are a couple more logisti cal things I should deal with in  this class. "}, "hash": "41119db85e11c66ef2dd168250f427d858c17e362b6b2904a288939394b6c68f", "class_name": "RelatedNodeInfo"}}, "hash": "8da2a6131a75e31c4f8605b2e0332d0f0a2cabf3674328ae987b5661d1952e75", "text": "We'll go over it in \nthe review sections.  \n", "start_char_idx": 11937, "end_char_idx": 11981, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a4ed568-3f83-4d91-b199-5fb596bafd79": {"__data__": {"id_": "3a4ed568-3f83-4d91-b199-5fb596bafd79", "embedding": null, "metadata": {"window": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. ", "original_text": "So there are a couple more logisti cal things I should deal with in  this class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b25156a-87c4-45cc-8da4-5f78ba11596f", "node_type": "1", "metadata": {"window": "And again, most undergraduate \nlinear algebra courses are more than enough.  So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. ", "original_text": "We'll go over it in \nthe review sections.  \n"}, "hash": "8da2a6131a75e31c4f8605b2e0332d0f0a2cabf3674328ae987b5661d1952e75", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "093c4841-0ea8-45e3-b0ca-fdffd036809e", "node_type": "1", "metadata": {"window": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n", "original_text": "One is that, as \nmost of you know, CS229 is a televised cla ss. "}, "hash": "babf30762a3910234322bd5d22d87cba778e206d794218babe78d18408073ad2", "class_name": "RelatedNodeInfo"}}, "hash": "41119db85e11c66ef2dd168250f427d858c17e362b6b2904a288939394b6c68f", "text": "So there are a couple more logisti cal things I should deal with in  this class. ", "start_char_idx": 11981, "end_char_idx": 12062, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "093c4841-0ea8-45e3-b0ca-fdffd036809e": {"__data__": {"id_": "093c4841-0ea8-45e3-b0ca-fdffd036809e", "embedding": null, "metadata": {"window": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n", "original_text": "One is that, as \nmost of you know, CS229 is a televised cla ss. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a4ed568-3f83-4d91-b199-5fb596bafd79", "node_type": "1", "metadata": {"window": "So if you've taken courses like Math 51, \n103, Math 113 or CS205 at Stanford, that would be more than enough.  Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. ", "original_text": "So there are a couple more logisti cal things I should deal with in  this class. "}, "hash": "41119db85e11c66ef2dd168250f427d858c17e362b6b2904a288939394b6c68f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28a8b6a9-9b90-4ec5-9edb-a7d39175c033", "node_type": "1", "metadata": {"window": "If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. ", "original_text": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n"}, "hash": "e1c8db573561ffa6e8360211747cd371e7163184acc06b58cef3a0a91e5571b4", "class_name": "RelatedNodeInfo"}}, "hash": "babf30762a3910234322bd5d22d87cba778e206d794218babe78d18408073ad2", "text": "One is that, as \nmost of you know, CS229 is a televised cla ss. ", "start_char_idx": 12062, "end_char_idx": 12126, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "28a8b6a9-9b90-4ec5-9edb-a7d39175c033": {"__data__": {"id_": "28a8b6a9-9b90-4ec5-9edb-a7d39175c033", "embedding": null, "metadata": {"window": "If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. ", "original_text": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "093c4841-0ea8-45e3-b0ca-fdffd036809e", "node_type": "1", "metadata": {"window": "Basically, I'm \ngonna assume that all of you know what matrix es and vectors are, that you know how to \nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is.  If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n", "original_text": "One is that, as \nmost of you know, CS229 is a televised cla ss. "}, "hash": "babf30762a3910234322bd5d22d87cba778e206d794218babe78d18408073ad2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4be2f053-ba7d-401b-84f6-54efa75a7b78", "node_type": "1", "metadata": {"window": "But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n", "original_text": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. "}, "hash": "0f65f96eda9be06dad9c20d24d51e39406f35d705301bb3b938121adb4fc9a86", "class_name": "RelatedNodeInfo"}}, "hash": "e1c8db573561ffa6e8360211747cd371e7163184acc06b58cef3a0a91e5571b4", "text": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n", "start_char_idx": 12126, "end_char_idx": 12246, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4be2f053-ba7d-401b-84f6-54efa75a7b78": {"__data__": {"id_": "4be2f053-ba7d-401b-84f6-54efa75a7b78", "embedding": null, "metadata": {"window": "But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n", "original_text": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "28a8b6a9-9b90-4ec5-9edb-a7d39175c033", "node_type": "1", "metadata": {"window": "If you know what an eigenvect or of a matrix is, that'd be even better. \n But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. ", "original_text": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n"}, "hash": "e1c8db573561ffa6e8360211747cd371e7163184acc06b58cef3a0a91e5571b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10664c78-cdd1-4c89-8fd7-39e4d9aab81f", "node_type": "1", "metadata": {"window": "We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see. ", "original_text": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. "}, "hash": "0d4f80f91ce5af6b210ec9aa67b8213d216640b06d60f5f46311fe2e3b669184", "class_name": "RelatedNodeInfo"}}, "hash": "0f65f96eda9be06dad9c20d24d51e39406f35d705301bb3b938121adb4fc9a86", "text": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. ", "start_char_idx": 12246, "end_char_idx": 12432, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10664c78-cdd1-4c89-8fd7-39e4d9aab81f": {"__data__": {"id_": "10664c78-cdd1-4c89-8fd7-39e4d9aab81f", "embedding": null, "metadata": {"window": "We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see. ", "original_text": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4be2f053-ba7d-401b-84f6-54efa75a7b78", "node_type": "1", "metadata": {"window": "But if you don't quite know or if you're not qu ite sure, that's fine, too.  We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n", "original_text": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb. "}, "hash": "0f65f96eda9be06dad9c20d24d51e39406f35d705301bb3b938121adb4fc9a86", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6a722f7-69a9-4fec-a6ef-e3cef9737c8f", "node_type": "1", "metadata": {"window": "So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. ", "original_text": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n"}, "hash": "e37ad0782fe67afa62670a813d456b2b4f67fa3320f22a1ec77ec374ffd4d0dc", "class_name": "RelatedNodeInfo"}}, "hash": "0d4f80f91ce5af6b210ec9aa67b8213d216640b06d60f5f46311fe2e3b669184", "text": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. ", "start_char_idx": 12432, "end_char_idx": 12644, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f6a722f7-69a9-4fec-a6ef-e3cef9737c8f": {"__data__": {"id_": "f6a722f7-69a9-4fec-a6ef-e3cef9737c8f", "embedding": null, "metadata": {"window": "So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. ", "original_text": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10664c78-cdd1-4c89-8fd7-39e4d9aab81f", "node_type": "1", "metadata": {"window": "We'll go over it in \nthe review sections.  \n So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see. ", "original_text": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone. "}, "hash": "0d4f80f91ce5af6b210ec9aa67b8213d216640b06d60f5f46311fe2e3b669184", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c8b557b-a681-4607-86c3-a7e16ea70f61", "node_type": "1", "metadata": {"window": "One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these. ", "original_text": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. "}, "hash": "af78ebe5e609e60c0759a00bbd3e62ab168c60f2f9fe000bdacad5513fe9e0c4", "class_name": "RelatedNodeInfo"}}, "hash": "e37ad0782fe67afa62670a813d456b2b4f67fa3320f22a1ec77ec374ffd4d0dc", "text": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n", "start_char_idx": 12644, "end_char_idx": 12742, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c8b557b-a681-4607-86c3-a7e16ea70f61": {"__data__": {"id_": "2c8b557b-a681-4607-86c3-a7e16ea70f61", "embedding": null, "metadata": {"window": "One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these. ", "original_text": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6a722f7-69a9-4fec-a6ef-e3cef9737c8f", "node_type": "1", "metadata": {"window": "So there are a couple more logisti cal things I should deal with in  this class.  One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. ", "original_text": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n"}, "hash": "e37ad0782fe67afa62670a813d456b2b4f67fa3320f22a1ec77ec374ffd4d0dc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c79b0f3-6f6e-4afa-91ac-deef120efe4c", "node_type": "1", "metadata": {"window": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n", "original_text": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n"}, "hash": "512b9452c4e2b2db9252959e66dae351b2ac53266ba2d873f24f47bd96c53f6c", "class_name": "RelatedNodeInfo"}}, "hash": "af78ebe5e609e60c0759a00bbd3e62ab168c60f2f9fe000bdacad5513fe9e0c4", "text": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. ", "start_char_idx": 12742, "end_char_idx": 12977, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7c79b0f3-6f6e-4afa-91ac-deef120efe4c": {"__data__": {"id_": "7c79b0f3-6f6e-4afa-91ac-deef120efe4c", "embedding": null, "metadata": {"window": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n", "original_text": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c8b557b-a681-4607-86c3-a7e16ea70f61", "node_type": "1", "metadata": {"window": "One is that, as \nmost of you know, CS229 is a televised cla ss.  And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these. ", "original_text": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day. "}, "hash": "af78ebe5e609e60c0759a00bbd3e62ab168c60f2f9fe000bdacad5513fe9e0c4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20bd9b90-8e3b-496e-9379-ff6600fdc27b", "node_type": "1", "metadata": {"window": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay. ", "original_text": "Let's see. "}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "class_name": "RelatedNodeInfo"}}, "hash": "512b9452c4e2b2db9252959e66dae351b2ac53266ba2d873f24f47bd96c53f6c", "text": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n", "start_char_idx": 12977, "end_char_idx": 13312, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20bd9b90-8e3b-496e-9379-ff6600fdc27b": {"__data__": {"id_": "20bd9b90-8e3b-496e-9379-ff6600fdc27b", "embedding": null, "metadata": {"window": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay. ", "original_text": "Let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c79b0f3-6f6e-4afa-91ac-deef120efe4c", "node_type": "1", "metadata": {"window": "And in fact, I guess many of you are \nprobably watching this at home on TV, so I' m gonna say hi to our home viewers.  \n So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n", "original_text": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n"}, "hash": "512b9452c4e2b2db9252959e66dae351b2ac53266ba2d873f24f47bd96c53f6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f2095ed-0e7a-45a2-be37-2ae7e95f602e", "node_type": "1", "metadata": {"window": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder? ", "original_text": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. "}, "hash": "5f624f5da3476c4174129fd9db4ae7a0b21a7394fbde61fe4f15daf6e6e8281d", "class_name": "RelatedNodeInfo"}}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "text": "Let's see. ", "start_char_idx": 13312, "end_char_idx": 13323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f2095ed-0e7a-45a2-be37-2ae7e95f602e": {"__data__": {"id_": "5f2095ed-0e7a-45a2-be37-2ae7e95f602e", "embedding": null, "metadata": {"window": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder? ", "original_text": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20bd9b90-8e3b-496e-9379-ff6600fdc27b", "node_type": "1", "metadata": {"window": "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to \nmake a small number of Stanford classes publ icly available or posting the videos on the \nweb.  And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay. ", "original_text": "Let's see. "}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "695b6bd6-23e5-4675-b640-3a3988140948", "node_type": "1", "metadata": {"window": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume? ", "original_text": "So let me just sa y a few words about parts of these. "}, "hash": "d29fe48b2827af88ef5fbc95ee9d51507bd35d19e9895bb565d45d5eed003cad", "class_name": "RelatedNodeInfo"}}, "hash": "5f624f5da3476c4174129fd9db4ae7a0b21a7394fbde61fe4f15daf6e6e8281d", "text": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. ", "start_char_idx": 13323, "end_char_idx": 13427, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "695b6bd6-23e5-4675-b640-3a3988140948": {"__data__": {"id_": "695b6bd6-23e5-4675-b640-3a3988140948", "embedding": null, "metadata": {"window": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume? ", "original_text": "So let me just sa y a few words about parts of these. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f2095ed-0e7a-45a2-be37-2ae7e95f602e", "node_type": "1", "metadata": {"window": "And so this year, Stanford is actually starting a small pilot program in which we'll \npost videos of a small number of classes onlin e, so on the Internet in a way that makes it \npublicly accessible to everyone.  I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder? ", "original_text": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout. "}, "hash": "5f624f5da3476c4174129fd9db4ae7a0b21a7394fbde61fe4f15daf6e6e8281d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "193ec0eb-b51c-408a-8f27-ba22a38aa190", "node_type": "1", "metadata": {"window": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing. ", "original_text": "On the \nthird page, there's a section that says Online Resources.  \n"}, "hash": "6a81bd19e4a2fdfb6b8eb5a300b3a164867dd163bc1a8c293b1ad9a407c3d45e", "class_name": "RelatedNodeInfo"}}, "hash": "d29fe48b2827af88ef5fbc95ee9d51507bd35d19e9895bb565d45d5eed003cad", "text": "So let me just sa y a few words about parts of these. ", "start_char_idx": 13427, "end_char_idx": 13481, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "193ec0eb-b51c-408a-8f27-ba22a38aa190": {"__data__": {"id_": "193ec0eb-b51c-408a-8f27-ba22a38aa190", "embedding": null, "metadata": {"window": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing. ", "original_text": "On the \nthird page, there's a section that says Online Resources.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "695b6bd6-23e5-4675-b640-3a3988140948", "node_type": "1", "metadata": {"window": "I'm very exc ited about that because machine learning in \nschool, let's get the word out there.  \n One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume? ", "original_text": "So let me just sa y a few words about parts of these. "}, "hash": "d29fe48b2827af88ef5fbc95ee9d51507bd35d19e9895bb565d45d5eed003cad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f38b633b-21d5-432c-a636-71faa7f152c3", "node_type": "1", "metadata": {"window": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n", "original_text": "Oh, okay. "}, "hash": "77187f450437342a6d1173cdc2d69aab041b98a673ac62943af515d751a83cd2", "class_name": "RelatedNodeInfo"}}, "hash": "6a81bd19e4a2fdfb6b8eb5a300b3a164867dd163bc1a8c293b1ad9a407c3d45e", "text": "On the \nthird page, there's a section that says Online Resources.  \n", "start_char_idx": 13481, "end_char_idx": 13549, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f38b633b-21d5-432c-a636-71faa7f152c3": {"__data__": {"id_": "f38b633b-21d5-432c-a636-71faa7f152c3", "embedding": null, "metadata": {"window": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n", "original_text": "Oh, okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "193ec0eb-b51c-408a-8f27-ba22a38aa190", "node_type": "1", "metadata": {"window": "One of the consequences of this is that \u2014 let's see \u2014 so videos  or pictures of the students \nin this classroom will not be posted online, so your images \u2014 so don't worry about being \nby seeing your own face appear on YouTube one day.  But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing. ", "original_text": "On the \nthird page, there's a section that says Online Resources.  \n"}, "hash": "6a81bd19e4a2fdfb6b8eb5a300b3a164867dd163bc1a8c293b1ad9a407c3d45e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b312024a-d71e-4a14-9d51-5a79e83e8883", "node_type": "1", "metadata": {"window": "Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing. ", "original_text": "Louder? "}, "hash": "4ded5921b11e4cd7699e173c870cf090ff7766dbc2de9a2020b3af1914a4f974", "class_name": "RelatedNodeInfo"}}, "hash": "77187f450437342a6d1173cdc2d69aab041b98a673ac62943af515d751a83cd2", "text": "Oh, okay. ", "start_char_idx": 13549, "end_char_idx": 13559, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b312024a-d71e-4a14-9d51-5a79e83e8883": {"__data__": {"id_": "b312024a-d71e-4a14-9d51-5a79e83e8883", "embedding": null, "metadata": {"window": "Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing. ", "original_text": "Louder? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f38b633b-21d5-432c-a636-71faa7f152c3", "node_type": "1", "metadata": {"window": "But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \nmiddle of class, but because there won't be video you can safely sit there and make faces \nat me, and that won't show, okay?  \n Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n", "original_text": "Oh, okay. "}, "hash": "77187f450437342a6d1173cdc2d69aab041b98a673ac62943af515d751a83cd2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "99d38753-bf42-4bfa-be49-bc069b1bf3c0", "node_type": "1", "metadata": {"window": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool. ", "original_text": "Actually, could you turn up the volume? "}, "hash": "d0fb0d3d853162c8d47b8444815bfd895b9d3a03d53b7939c1bb86e928d99606", "class_name": "RelatedNodeInfo"}}, "hash": "4ded5921b11e4cd7699e173c870cf090ff7766dbc2de9a2020b3af1914a4f974", "text": "Louder? ", "start_char_idx": 13559, "end_char_idx": 13567, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "99d38753-bf42-4bfa-be49-bc069b1bf3c0": {"__data__": {"id_": "99d38753-bf42-4bfa-be49-bc069b1bf3c0", "embedding": null, "metadata": {"window": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool. ", "original_text": "Actually, could you turn up the volume? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b312024a-d71e-4a14-9d51-5a79e83e8883", "node_type": "1", "metadata": {"window": "Let's see.  I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing. ", "original_text": "Louder? "}, "hash": "4ded5921b11e4cd7699e173c870cf090ff7766dbc2de9a2020b3af1914a4f974", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9825dce6-857f-4691-9d0b-eda34ec5a59c", "node_type": "1", "metadata": {"window": "So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n", "original_text": "Testing. "}, "hash": "b7bf448a62bb45f2c5e98b9a134613aa9d638f6fc90d8a226026a187b43e62a3", "class_name": "RelatedNodeInfo"}}, "hash": "d0fb0d3d853162c8d47b8444815bfd895b9d3a03d53b7939c1bb86e928d99606", "text": "Actually, could you turn up the volume? ", "start_char_idx": 13567, "end_char_idx": 13607, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9825dce6-857f-4691-9d0b-eda34ec5a59c": {"__data__": {"id_": "9825dce6-857f-4691-9d0b-eda34ec5a59c", "embedding": null, "metadata": {"window": "So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n", "original_text": "Testing. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "99d38753-bf42-4bfa-be49-bc069b1bf3c0", "node_type": "1", "metadata": {"window": "I also handed out this \u2014 ther e were two handouts I hope most of you have, \ncourse information handout.  So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool. ", "original_text": "Actually, could you turn up the volume? "}, "hash": "d0fb0d3d853162c8d47b8444815bfd895b9d3a03d53b7939c1bb86e928d99606", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "32c0b547-6fc7-4d93-acdd-e27cb4e6713f", "node_type": "1", "metadata": {"window": "On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources. ", "original_text": "Is this better? \n"}, "hash": "81cd72c0cadcbe040ba9dce23a386d547b1d359c9992a2de754483a5410f2f31", "class_name": "RelatedNodeInfo"}}, "hash": "b7bf448a62bb45f2c5e98b9a134613aa9d638f6fc90d8a226026a187b43e62a3", "text": "Testing. ", "start_char_idx": 13607, "end_char_idx": 13616, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "32c0b547-6fc7-4d93-acdd-e27cb4e6713f": {"__data__": {"id_": "32c0b547-6fc7-4d93-acdd-e27cb4e6713f", "embedding": null, "metadata": {"window": "On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources. ", "original_text": "Is this better? \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9825dce6-857f-4691-9d0b-eda34ec5a59c", "node_type": "1", "metadata": {"window": "So let me just sa y a few words about parts of these.  On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n", "original_text": "Testing. "}, "hash": "b7bf448a62bb45f2c5e98b9a134613aa9d638f6fc90d8a226026a187b43e62a3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d9e08a0-c0c2-431d-8150-63dea9fced95", "node_type": "1", "metadata": {"window": "Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts. ", "original_text": "Testing, testing. "}, "hash": "ccdd17dc9bab2ddbfb833a9680b9d2bfec80af485c9fe6d0a364257c0d991386", "class_name": "RelatedNodeInfo"}}, "hash": "81cd72c0cadcbe040ba9dce23a386d547b1d359c9992a2de754483a5410f2f31", "text": "Is this better? \n", "start_char_idx": 13616, "end_char_idx": 13633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9d9e08a0-c0c2-431d-8150-63dea9fced95": {"__data__": {"id_": "9d9e08a0-c0c2-431d-8150-63dea9fced95", "embedding": null, "metadata": {"window": "Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts. ", "original_text": "Testing, testing. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32c0b547-6fc7-4d93-acdd-e27cb4e6713f", "node_type": "1", "metadata": {"window": "On the \nthird page, there's a section that says Online Resources.  \n Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources. ", "original_text": "Is this better? \n"}, "hash": "81cd72c0cadcbe040ba9dce23a386d547b1d359c9992a2de754483a5410f2f31", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "75476202-adfe-4271-8c29-841dc4eb40e2", "node_type": "1", "metadata": {"window": "Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. ", "original_text": "Okay, cool. "}, "hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "class_name": "RelatedNodeInfo"}}, "hash": "ccdd17dc9bab2ddbfb833a9680b9d2bfec80af485c9fe6d0a364257c0d991386", "text": "Testing, testing. ", "start_char_idx": 13633, "end_char_idx": 13651, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "75476202-adfe-4271-8c29-841dc4eb40e2": {"__data__": {"id_": "75476202-adfe-4271-8c29-841dc4eb40e2", "embedding": null, "metadata": {"window": "Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. ", "original_text": "Okay, cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d9e08a0-c0c2-431d-8150-63dea9fced95", "node_type": "1", "metadata": {"window": "Oh, okay.  Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts. ", "original_text": "Testing, testing. "}, "hash": "ccdd17dc9bab2ddbfb833a9680b9d2bfec80af485c9fe6d0a364257c0d991386", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a7e43216-402a-4e5f-8bc3-c8afd91a486e", "node_type": "1", "metadata": {"window": "Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. ", "original_text": "Thanks.  \n\n"}, "hash": "978ceaa043b4c877105058188db373d2d82cfffad5e1f684b52a4051f33959cf", "class_name": "RelatedNodeInfo"}}, "hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "text": "Okay, cool. ", "start_char_idx": 13651, "end_char_idx": 13663, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a7e43216-402a-4e5f-8bc3-c8afd91a486e": {"__data__": {"id_": "a7e43216-402a-4e5f-8bc3-c8afd91a486e", "embedding": null, "metadata": {"window": "Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. ", "original_text": "Thanks.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "75476202-adfe-4271-8c29-841dc4eb40e2", "node_type": "1", "metadata": {"window": "Louder?  Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. ", "original_text": "Okay, cool. "}, "hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "40b7204c-42fd-445e-a7d4-eb9c37349df3", "node_type": "1", "metadata": {"window": "Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n", "original_text": "So all right, online resources. "}, "hash": "6204e0f648c2f8d26069e13a2d7be3daa1505446bdda2ce1f0fb6a540856fafc", "class_name": "RelatedNodeInfo"}}, "hash": "978ceaa043b4c877105058188db373d2d82cfffad5e1f684b52a4051f33959cf", "text": "Thanks.  \n\n", "start_char_idx": 13663, "end_char_idx": 13674, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40b7204c-42fd-445e-a7d4-eb9c37349df3": {"__data__": {"id_": "40b7204c-42fd-445e-a7d4-eb9c37349df3", "embedding": null, "metadata": {"window": "Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n", "original_text": "So all right, online resources. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a7e43216-402a-4e5f-8bc3-c8afd91a486e", "node_type": "1", "metadata": {"window": "Actually, could you turn up the volume?  Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. ", "original_text": "Thanks.  \n\n"}, "hash": "978ceaa043b4c877105058188db373d2d82cfffad5e1f684b52a4051f33959cf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "069a68a9-8c48-412c-a905-47fa844abe5c", "node_type": "1", "metadata": {"window": "Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. ", "original_text": "The class has a home page, so it's in on the handouts. "}, "hash": "14201af3029eeffca6b3d1d6b82983748cef02e0814fd19333abe3dd2d827d92", "class_name": "RelatedNodeInfo"}}, "hash": "6204e0f648c2f8d26069e13a2d7be3daa1505446bdda2ce1f0fb6a540856fafc", "text": "So all right, online resources. ", "start_char_idx": 13674, "end_char_idx": 13706, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "069a68a9-8c48-412c-a905-47fa844abe5c": {"__data__": {"id_": "069a68a9-8c48-412c-a905-47fa844abe5c", "embedding": null, "metadata": {"window": "Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. ", "original_text": "The class has a home page, so it's in on the handouts. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "40b7204c-42fd-445e-a7d4-eb9c37349df3", "node_type": "1", "metadata": {"window": "Testing.  Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n", "original_text": "So all right, online resources. "}, "hash": "6204e0f648c2f8d26069e13a2d7be3daa1505446bdda2ce1f0fb6a540856fafc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a94b49b2-0fa5-4553-8722-7eb606a5e0b3", "node_type": "1", "metadata": {"window": "Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n", "original_text": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. "}, "hash": "5f90d581d18aa0ff7d4b1bf13cf46b1f10b51b81dfaeb74b12757dcb9b37b3f4", "class_name": "RelatedNodeInfo"}}, "hash": "14201af3029eeffca6b3d1d6b82983748cef02e0814fd19333abe3dd2d827d92", "text": "The class has a home page, so it's in on the handouts. ", "start_char_idx": 13706, "end_char_idx": 13761, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a94b49b2-0fa5-4553-8722-7eb606a5e0b3": {"__data__": {"id_": "a94b49b2-0fa5-4553-8722-7eb606a5e0b3", "embedding": null, "metadata": {"window": "Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n", "original_text": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "069a68a9-8c48-412c-a905-47fa844abe5c", "node_type": "1", "metadata": {"window": "Is this better? \n Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. ", "original_text": "The class has a home page, so it's in on the handouts. "}, "hash": "14201af3029eeffca6b3d1d6b82983748cef02e0814fd19333abe3dd2d827d92", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "704467fd-d748-4ef7-8349-273e6ca7bd31", "node_type": "1", "metadata": {"window": "Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout. ", "original_text": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. "}, "hash": "c797adaaff7e967fea55e2ed7e0cb3930b1f5df94efaa18a1bd3e8fd2674705d", "class_name": "RelatedNodeInfo"}}, "hash": "5f90d581d18aa0ff7d4b1bf13cf46b1f10b51b81dfaeb74b12757dcb9b37b3f4", "text": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. ", "start_char_idx": 13761, "end_char_idx": 13824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "704467fd-d748-4ef7-8349-273e6ca7bd31": {"__data__": {"id_": "704467fd-d748-4ef7-8349-273e6ca7bd31", "embedding": null, "metadata": {"window": "Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout. ", "original_text": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a94b49b2-0fa5-4553-8722-7eb606a5e0b3", "node_type": "1", "metadata": {"window": "Testing, testing.  Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n", "original_text": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu. "}, "hash": "5f90d581d18aa0ff7d4b1bf13cf46b1f10b51b81dfaeb74b12757dcb9b37b3f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "caa31d19-4204-4f77-b059-0b6ece766507", "node_type": "1", "metadata": {"window": "Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. ", "original_text": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n"}, "hash": "c75e610a0b59f3d2d7e3f69b951772444862dd410f0775b975d525c3e6e86e93", "class_name": "RelatedNodeInfo"}}, "hash": "c797adaaff7e967fea55e2ed7e0cb3930b1f5df94efaa18a1bd3e8fd2674705d", "text": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. ", "start_char_idx": 13824, "end_char_idx": 14003, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "caa31d19-4204-4f77-b059-0b6ece766507": {"__data__": {"id_": "caa31d19-4204-4f77-b059-0b6ece766507", "embedding": null, "metadata": {"window": "Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. ", "original_text": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "704467fd-d748-4ef7-8349-273e6ca7bd31", "node_type": "1", "metadata": {"window": "Okay, cool.  Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout. ", "original_text": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class. "}, "hash": "c797adaaff7e967fea55e2ed7e0cb3930b1f5df94efaa18a1bd3e8fd2674705d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1de041b1-402d-4ff8-947b-55adf606e27a", "node_type": "1", "metadata": {"window": "So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me. ", "original_text": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. "}, "hash": "c03f535ff069f20f8ea7e0f2bf0b2adfc27b79ee6a963fe35678845514a94939", "class_name": "RelatedNodeInfo"}}, "hash": "c75e610a0b59f3d2d7e3f69b951772444862dd410f0775b975d525c3e6e86e93", "text": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n", "start_char_idx": 14003, "end_char_idx": 14097, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1de041b1-402d-4ff8-947b-55adf606e27a": {"__data__": {"id_": "1de041b1-402d-4ff8-947b-55adf606e27a", "embedding": null, "metadata": {"window": "So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me. ", "original_text": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "caa31d19-4204-4f77-b059-0b6ece766507", "node_type": "1", "metadata": {"window": "Thanks.  \n\n So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. ", "original_text": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n"}, "hash": "c75e610a0b59f3d2d7e3f69b951772444862dd410f0775b975d525c3e6e86e93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac89c9b1-1603-4ab5-b97d-efb8cdc0c81c", "node_type": "1", "metadata": {"window": "The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. ", "original_text": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n"}, "hash": "e6944e029e9219cbae2461b23f2fc48314874965977af026f7c1ea220169ca34", "class_name": "RelatedNodeInfo"}}, "hash": "c03f535ff069f20f8ea7e0f2bf0b2adfc27b79ee6a963fe35678845514a94939", "text": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. ", "start_char_idx": 14097, "end_char_idx": 14270, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac89c9b1-1603-4ab5-b97d-efb8cdc0c81c": {"__data__": {"id_": "ac89c9b1-1603-4ab5-b97d-efb8cdc0c81c", "embedding": null, "metadata": {"window": "The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. ", "original_text": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1de041b1-402d-4ff8-947b-55adf606e27a", "node_type": "1", "metadata": {"window": "So all right, online resources.  The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me. ", "original_text": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class. "}, "hash": "c03f535ff069f20f8ea7e0f2bf0b2adfc27b79ee6a963fe35678845514a94939", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7751d0e-2b82-40bf-a8a3-10a1b85712cc", "node_type": "1", "metadata": {"window": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n", "original_text": "There's also a newsgroup, su.class.cs229, also written on the handout. "}, "hash": "a176b485c02927bb422af8d1a059a84b0c1631d5bb47559d3de124aeaa742081", "class_name": "RelatedNodeInfo"}}, "hash": "e6944e029e9219cbae2461b23f2fc48314874965977af026f7c1ea220169ca34", "text": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n", "start_char_idx": 14270, "end_char_idx": 14449, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d7751d0e-2b82-40bf-a8a3-10a1b85712cc": {"__data__": {"id_": "d7751d0e-2b82-40bf-a8a3-10a1b85712cc", "embedding": null, "metadata": {"window": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n", "original_text": "There's also a newsgroup, su.class.cs229, also written on the handout. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac89c9b1-1603-4ab5-b97d-efb8cdc0c81c", "node_type": "1", "metadata": {"window": "The class has a home page, so it's in on the handouts.  I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. ", "original_text": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n"}, "hash": "e6944e029e9219cbae2461b23f2fc48314874965977af026f7c1ea220169ca34", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "403d83c8-ac17-4031-8791-21ea76fdbd3e", "node_type": "1", "metadata": {"window": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. ", "original_text": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. "}, "hash": "2e2f608cebd2ab973d186feb5f8ad84b76c7b6bae5d07477612b4540a7bab4e2", "class_name": "RelatedNodeInfo"}}, "hash": "a176b485c02927bb422af8d1a059a84b0c1631d5bb47559d3de124aeaa742081", "text": "There's also a newsgroup, su.class.cs229, also written on the handout. ", "start_char_idx": 14449, "end_char_idx": 14520, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "403d83c8-ac17-4031-8791-21ea76fdbd3e": {"__data__": {"id_": "403d83c8-ac17-4031-8791-21ea76fdbd3e", "embedding": null, "metadata": {"window": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. ", "original_text": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7751d0e-2b82-40bf-a8a3-10a1b85712cc", "node_type": "1", "metadata": {"window": "I \nwon't write on the chalkboard \u2014 http:// cs229.stanford.edu.  And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n", "original_text": "There's also a newsgroup, su.class.cs229, also written on the handout. "}, "hash": "a176b485c02927bb422af8d1a059a84b0c1631d5bb47559d3de124aeaa742081", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb57749f-2246-406f-88c1-d804bbd5eacd", "node_type": "1", "metadata": {"window": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me. ", "original_text": "So the class newsgroup \nwill not be monitored by the TAs and me. "}, "hash": "19239c50803ca0c879bcab875cea2163c87a2c0a88a96a0da7459d562b88f190", "class_name": "RelatedNodeInfo"}}, "hash": "2e2f608cebd2ab973d186feb5f8ad84b76c7b6bae5d07477612b4540a7bab4e2", "text": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. ", "start_char_idx": 14520, "end_char_idx": 14685, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bb57749f-2246-406f-88c1-d804bbd5eacd": {"__data__": {"id_": "bb57749f-2246-406f-88c1-d804bbd5eacd", "embedding": null, "metadata": {"window": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me. ", "original_text": "So the class newsgroup \nwill not be monitored by the TAs and me. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "403d83c8-ac17-4031-8791-21ea76fdbd3e", "node_type": "1", "metadata": {"window": "And so when there are \nhomework assignments or things like that, we  usually won't sort of \u2014 in the mission of \nsaving trees, we will usually not give out many handouts in class.  So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. ", "original_text": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves. "}, "hash": "2e2f608cebd2ab973d186feb5f8ad84b76c7b6bae5d07477612b4540a7bab4e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "236594cb-ed86-4d43-beea-006c536fc76a", "node_type": "1", "metadata": {"window": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n", "original_text": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. "}, "hash": "24d337f3f0bb636e9d023db2ce6e81bd83dfae27a8f13128e74eedffb0e2af90", "class_name": "RelatedNodeInfo"}}, "hash": "19239c50803ca0c879bcab875cea2163c87a2c0a88a96a0da7459d562b88f190", "text": "So the class newsgroup \nwill not be monitored by the TAs and me. ", "start_char_idx": 14685, "end_char_idx": 14750, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "236594cb-ed86-4d43-beea-006c536fc76a": {"__data__": {"id_": "236594cb-ed86-4d43-beea-006c536fc76a", "embedding": null, "metadata": {"window": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n", "original_text": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb57749f-2246-406f-88c1-d804bbd5eacd", "node_type": "1", "metadata": {"window": "So homework \nassignments, homework solutions will be posted online at the course home page.  \n As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me. ", "original_text": "So the class newsgroup \nwill not be monitored by the TAs and me. "}, "hash": "19239c50803ca0c879bcab875cea2163c87a2c0a88a96a0da7459d562b88f190", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "de431448-acb7-46f9-bd12-233cb1addd63", "node_type": "1", "metadata": {"window": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n", "original_text": "So feel free to ta lk trash about this class there.  \n"}, "hash": "f6247fd518ca9e85507041c8f668fbb489c1b0b99ab4a42c48362e98e19b4673", "class_name": "RelatedNodeInfo"}}, "hash": "24d337f3f0bb636e9d023db2ce6e81bd83dfae27a8f13128e74eedffb0e2af90", "text": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. ", "start_char_idx": 14750, "end_char_idx": 14908, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de431448-acb7-46f9-bd12-233cb1addd63": {"__data__": {"id_": "de431448-acb7-46f9-bd12-233cb1addd63", "embedding": null, "metadata": {"window": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n", "original_text": "So feel free to ta lk trash about this class there.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "236594cb-ed86-4d43-beea-006c536fc76a", "node_type": "1", "metadata": {"window": "As far as this class, I've also written, a nd I guess I've also revised every year a set of \nfairly detailed lecture notes that cover the te chnical content of this  class.  And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n", "original_text": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me. "}, "hash": "24d337f3f0bb636e9d023db2ce6e81bd83dfae27a8f13128e74eedffb0e2af90", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "87c0ab7d-357b-45d0-ab10-78eec8f77c7a", "node_type": "1", "metadata": {"window": "There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see. ", "original_text": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. "}, "hash": "2e33b43df6f10b5460a247dec0a5a8739d501f882aef4071674d49367003e93d", "class_name": "RelatedNodeInfo"}}, "hash": "f6247fd518ca9e85507041c8f668fbb489c1b0b99ab4a42c48362e98e19b4673", "text": "So feel free to ta lk trash about this class there.  \n", "start_char_idx": 14908, "end_char_idx": 14962, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "87c0ab7d-357b-45d0-ab10-78eec8f77c7a": {"__data__": {"id_": "87c0ab7d-357b-45d0-ab10-78eec8f77c7a", "embedding": null, "metadata": {"window": "There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see. ", "original_text": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "de431448-acb7-46f9-bd12-233cb1addd63", "node_type": "1", "metadata": {"window": "And so if you \nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \nall the math and equations and so on  that I'll be doing in class.  \n There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n", "original_text": "So feel free to ta lk trash about this class there.  \n"}, "hash": "f6247fd518ca9e85507041c8f668fbb489c1b0b99ab4a42c48362e98e19b4673", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b473ec0-2c18-4de1-bec0-a980859fbec0", "node_type": "1", "metadata": {"window": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. ", "original_text": "This goes to an acc ount that's read by all the TAs and me. "}, "hash": "8c09b056adc96e6e98c87be1ef1e205d80353994134cd796e923a1f14ee7fd5d", "class_name": "RelatedNodeInfo"}}, "hash": "2e33b43df6f10b5460a247dec0a5a8739d501f882aef4071674d49367003e93d", "text": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. ", "start_char_idx": 14962, "end_char_idx": 15081, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b473ec0-2c18-4de1-bec0-a980859fbec0": {"__data__": {"id_": "1b473ec0-2c18-4de1-bec0-a980859fbec0", "embedding": null, "metadata": {"window": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. ", "original_text": "This goes to an acc ount that's read by all the TAs and me. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "87c0ab7d-357b-45d0-ab10-78eec8f77c7a", "node_type": "1", "metadata": {"window": "There's also a newsgroup, su.class.cs229, also written on the handout.  This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see. ", "original_text": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu. "}, "hash": "2e33b43df6f10b5460a247dec0a5a8739d501f882aef4071674d49367003e93d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1ac08c1-0a3b-4efb-8221-78e598994e4e", "node_type": "1", "metadata": {"window": "So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code. ", "original_text": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n"}, "hash": "e91d5878a625634a76f8d684a51ed79c5adb9dc434624a5d2a52444e4468feab", "class_name": "RelatedNodeInfo"}}, "hash": "8c09b056adc96e6e98c87be1ef1e205d80353994134cd796e923a1f14ee7fd5d", "text": "This goes to an acc ount that's read by all the TAs and me. ", "start_char_idx": 15081, "end_char_idx": 15141, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a1ac08c1-0a3b-4efb-8221-78e598994e4e": {"__data__": {"id_": "a1ac08c1-0a3b-4efb-8221-78e598994e4e", "embedding": null, "metadata": {"window": "So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code. ", "original_text": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b473ec0-2c18-4de1-bec0-a980859fbec0", "node_type": "1", "metadata": {"window": "This is a \nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \nhave whatever discussions you want to ha ve amongst yourselves.  So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. ", "original_text": "This goes to an acc ount that's read by all the TAs and me. "}, "hash": "8c09b056adc96e6e98c87be1ef1e205d80353994134cd796e923a1f14ee7fd5d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80320470-9e88-4c01-aef4-f675b2ca397b", "node_type": "1", "metadata": {"window": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n", "original_text": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n"}, "hash": "0470656dfefcf59e49f7eb6db9c0e58edd330230b4d44ab8357a6df19b2e81d8", "class_name": "RelatedNodeInfo"}}, "hash": "e91d5878a625634a76f8d684a51ed79c5adb9dc434624a5d2a52444e4468feab", "text": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n", "start_char_idx": 15141, "end_char_idx": 15316, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "80320470-9e88-4c01-aef4-f675b2ca397b": {"__data__": {"id_": "80320470-9e88-4c01-aef4-f675b2ca397b", "embedding": null, "metadata": {"window": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n", "original_text": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1ac08c1-0a3b-4efb-8221-78e598994e4e", "node_type": "1", "metadata": {"window": "So the class newsgroup \nwill not be monitored by the TAs and me.  But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code. ", "original_text": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n"}, "hash": "e91d5878a625634a76f8d684a51ed79c5adb9dc434624a5d2a52444e4468feab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b4fd04c-6bd3-4564-b51a-110e8edb324d", "node_type": "1", "metadata": {"window": "So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. ", "original_text": "Let's see. "}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "class_name": "RelatedNodeInfo"}}, "hash": "0470656dfefcf59e49f7eb6db9c0e58edd330230b4d44ab8357a6df19b2e81d8", "text": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n", "start_char_idx": 15316, "end_char_idx": 15602, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9b4fd04c-6bd3-4564-b51a-110e8edb324d": {"__data__": {"id_": "9b4fd04c-6bd3-4564-b51a-110e8edb324d", "embedding": null, "metadata": {"window": "So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. ", "original_text": "Let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80320470-9e88-4c01-aef4-f675b2ca397b", "node_type": "1", "metadata": {"window": "But this is a place for you to form study groups \nor find project partners or discuss homework problems and so on, and it's not monitored \nby the TAs and me.  So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n", "original_text": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n"}, "hash": "0470656dfefcf59e49f7eb6db9c0e58edd330230b4d44ab8357a6df19b2e81d8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a73d5032-2f9a-431a-9ae8-66b0963683cd", "node_type": "1", "metadata": {"window": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. ", "original_text": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. "}, "hash": "a9d3cf8c80ae11f6f27efa3e2c004b30fe00022b3854d674ea5dc14fb24d1507", "class_name": "RelatedNodeInfo"}}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "text": "Let's see. ", "start_char_idx": 13312, "end_char_idx": 13323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a73d5032-2f9a-431a-9ae8-66b0963683cd": {"__data__": {"id_": "a73d5032-2f9a-431a-9ae8-66b0963683cd", "embedding": null, "metadata": {"window": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. ", "original_text": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b4fd04c-6bd3-4564-b51a-110e8edb324d", "node_type": "1", "metadata": {"window": "So feel free to ta lk trash about this class there.  \n If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. ", "original_text": "Let's see. "}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a887d294-892f-44ca-9566-71b947afd593", "node_type": "1", "metadata": {"window": "This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n", "original_text": "Notice on the honor code. "}, "hash": "629768138a239b88cba8f9e492ac354cfbc3328626afde09d922fa94185f9030", "class_name": "RelatedNodeInfo"}}, "hash": "a9d3cf8c80ae11f6f27efa3e2c004b30fe00022b3854d674ea5dc14fb24d1507", "text": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. ", "start_char_idx": 15613, "end_char_idx": 15697, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a887d294-892f-44ca-9566-71b947afd593": {"__data__": {"id_": "a887d294-892f-44ca-9566-71b947afd593", "embedding": null, "metadata": {"window": "This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n", "original_text": "Notice on the honor code. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a73d5032-2f9a-431a-9ae8-66b0963683cd", "node_type": "1", "metadata": {"window": "If you want to contact the teaching staff, pl ease use the email address written down here, \ncs229-qa@cs.stanford.edu.  This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. ", "original_text": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject. "}, "hash": "a9d3cf8c80ae11f6f27efa3e2c004b30fe00022b3854d674ea5dc14fb24d1507", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cfd90cfe-88da-440b-a9b2-4199146e60d0", "node_type": "1", "metadata": {"window": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.  ", "original_text": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n"}, "hash": "70b15765324a2d6e589b30fabc394b81438635ffca95ab15e7f5c147141ea5b3", "class_name": "RelatedNodeInfo"}}, "hash": "629768138a239b88cba8f9e492ac354cfbc3328626afde09d922fa94185f9030", "text": "Notice on the honor code. ", "start_char_idx": 15697, "end_char_idx": 15723, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cfd90cfe-88da-440b-a9b2-4199146e60d0": {"__data__": {"id_": "cfd90cfe-88da-440b-a9b2-4199146e60d0", "embedding": null, "metadata": {"window": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.  ", "original_text": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a887d294-892f-44ca-9566-71b947afd593", "node_type": "1", "metadata": {"window": "This goes to an acc ount that's read by all the TAs and me.  So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n", "original_text": "Notice on the honor code. "}, "hash": "629768138a239b88cba8f9e492ac354cfbc3328626afde09d922fa94185f9030", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89b67a36-f4c2-4dcf-b2f9-ccfb2a290ee0", "node_type": "1", "metadata": {"window": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult. ", "original_text": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. "}, "hash": "eae9883a8d381e24ce6be6fdbf06110aeb2d8d48c564ce48346a24296ffb7060", "class_name": "RelatedNodeInfo"}}, "hash": "70b15765324a2d6e589b30fabc394b81438635ffca95ab15e7f5c147141ea5b3", "text": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n", "start_char_idx": 15723, "end_char_idx": 15879, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89b67a36-f4c2-4dcf-b2f9-ccfb2a290ee0": {"__data__": {"id_": "89b67a36-f4c2-4dcf-b2f9-ccfb2a290ee0", "embedding": null, "metadata": {"window": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult. ", "original_text": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cfd90cfe-88da-440b-a9b2-4199146e60d0", "node_type": "1", "metadata": {"window": "So \nrather than sending us email individually, if you send email to this account, it will \nactually let us get back to you maximally quickly with answers to your questions.  \n If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.  ", "original_text": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n"}, "hash": "70b15765324a2d6e589b30fabc394b81438635ffca95ab15e7f5c147141ea5b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49ad0228-e032-4666-8850-38a1f56bb08e", "node_type": "1", "metadata": {"window": "Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. ", "original_text": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. "}, "hash": "030c027fded7123828c393b2efecbe382430ba87e89e907e13ba1ba134e27a49", "class_name": "RelatedNodeInfo"}}, "hash": "eae9883a8d381e24ce6be6fdbf06110aeb2d8d48c564ce48346a24296ffb7060", "text": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. ", "start_char_idx": 15879, "end_char_idx": 16013, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49ad0228-e032-4666-8850-38a1f56bb08e": {"__data__": {"id_": "49ad0228-e032-4666-8850-38a1f56bb08e", "embedding": null, "metadata": {"window": "Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. ", "original_text": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89b67a36-f4c2-4dcf-b2f9-ccfb2a290ee0", "node_type": "1", "metadata": {"window": "If you're asking questions about homework probl ems, please say in the subject line which \nassignment and which question the email refers to, since that will also help us to route \nyour question to the appropriate TA or to me  appropriately and get the response back to \nyou quickly.  \n Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult. ", "original_text": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates. "}, "hash": "eae9883a8d381e24ce6be6fdbf06110aeb2d8d48c564ce48346a24296ffb7060", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f3718338-8d51-4ed1-afbf-1c4d4288b0d7", "node_type": "1", "metadata": {"window": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n", "original_text": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n"}, "hash": "b90d0748c37581b35613b030d9ec8debd35d21eb6b3e8bab37f19cc4d3269833", "class_name": "RelatedNodeInfo"}}, "hash": "030c027fded7123828c393b2efecbe382430ba87e89e907e13ba1ba134e27a49", "text": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. ", "start_char_idx": 16013, "end_char_idx": 16185, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3718338-8d51-4ed1-afbf-1c4d4288b0d7": {"__data__": {"id_": "f3718338-8d51-4ed1-afbf-1c4d4288b0d7", "embedding": null, "metadata": {"window": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n", "original_text": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49ad0228-e032-4666-8850-38a1f56bb08e", "node_type": "1", "metadata": {"window": "Let's see.  Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. ", "original_text": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with. "}, "hash": "030c027fded7123828c393b2efecbe382430ba87e89e907e13ba1ba134e27a49", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0cfd113-5c1b-4a88-88a4-0cfe35e267ef", "node_type": "1", "metadata": {"window": "Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. ", "original_text": "But some of the problems sets in this cla ss are reasonably difficult.  "}, "hash": "d89000a860ad34d2eb86eb0ab67d4d48e71f2b01a3c9b7ca9e94b3dd0815a6e2", "class_name": "RelatedNodeInfo"}}, "hash": "b90d0748c37581b35613b030d9ec8debd35d21eb6b3e8bab37f19cc4d3269833", "text": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n", "start_char_idx": 16185, "end_char_idx": 16285, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0cfd113-5c1b-4a88-88a4-0cfe35e267ef": {"__data__": {"id_": "a0cfd113-5c1b-4a88-88a4-0cfe35e267ef", "embedding": null, "metadata": {"window": "Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. ", "original_text": "But some of the problems sets in this cla ss are reasonably difficult.  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3718338-8d51-4ed1-afbf-1c4d4288b0d7", "node_type": "1", "metadata": {"window": "Skipping ahead \u2014 let's see \u2014 for homework, one midterm, one open and term \nproject.  Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n", "original_text": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n"}, "hash": "b90d0748c37581b35613b030d9ec8debd35d21eb6b3e8bab37f19cc4d3269833", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7809fb49-ecd4-4151-8796-56948da8da35", "node_type": "1", "metadata": {"window": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n", "original_text": "People that have \ntaken the class before may tell you they were very difficult. "}, "hash": "ea38683ae172d2eca57bba280955106c2e5c2e5e353a32d05459ac90f7d88a5a", "class_name": "RelatedNodeInfo"}}, "hash": "d89000a860ad34d2eb86eb0ab67d4d48e71f2b01a3c9b7ca9e94b3dd0815a6e2", "text": "But some of the problems sets in this cla ss are reasonably difficult.  ", "start_char_idx": 16285, "end_char_idx": 16357, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7809fb49-ecd4-4151-8796-56948da8da35": {"__data__": {"id_": "7809fb49-ecd4-4151-8796-56948da8da35", "embedding": null, "metadata": {"window": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n", "original_text": "People that have \ntaken the class before may tell you they were very difficult. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a0cfd113-5c1b-4a88-88a4-0cfe35e267ef", "node_type": "1", "metadata": {"window": "Notice on the honor code.  So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. ", "original_text": "But some of the problems sets in this cla ss are reasonably difficult.  "}, "hash": "d89000a860ad34d2eb86eb0ab67d4d48e71f2b01a3c9b7ca9e94b3dd0815a6e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "634eaebd-c564-4fb2-86e4-3fd2ee3c9797", "node_type": "1", "metadata": {"window": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? ", "original_text": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. "}, "hash": "8060c588e1c957742da115c03f5e7441043263f9d16fc7527e0555c0e63ab34b", "class_name": "RelatedNodeInfo"}}, "hash": "ea38683ae172d2eca57bba280955106c2e5c2e5e353a32d05459ac90f7d88a5a", "text": "People that have \ntaken the class before may tell you they were very difficult. ", "start_char_idx": 16357, "end_char_idx": 16437, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "634eaebd-c564-4fb2-86e4-3fd2ee3c9797": {"__data__": {"id_": "634eaebd-c564-4fb2-86e4-3fd2ee3c9797", "embedding": null, "metadata": {"window": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? ", "original_text": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7809fb49-ecd4-4151-8796-56948da8da35", "node_type": "1", "metadata": {"window": "So one thi ng that I think will help you to succeed and \ndo well in this class and even help you to enjoy this cla ss more is if you form a study \ngroup.  \n So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n", "original_text": "People that have \ntaken the class before may tell you they were very difficult. "}, "hash": "ea38683ae172d2eca57bba280955106c2e5c2e5e353a32d05459ac90f7d88a5a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a057f2ec-fd3d-4232-9a4c-6e9cc1efbf74", "node_type": "1", "metadata": {"window": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n", "original_text": "So I definitely encourage you to do that.  \n"}, "hash": "bc27b1c0fbf3141edcf5a68c5594850c59a4b144c43466bec4791be7df2927b8", "class_name": "RelatedNodeInfo"}}, "hash": "8060c588e1c957742da115c03f5e7441043263f9d16fc7527e0555c0e63ab34b", "text": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. ", "start_char_idx": 16437, "end_char_idx": 16588, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a057f2ec-fd3d-4232-9a4c-6e9cc1efbf74": {"__data__": {"id_": "a057f2ec-fd3d-4232-9a4c-6e9cc1efbf74", "embedding": null, "metadata": {"window": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n", "original_text": "So I definitely encourage you to do that.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "634eaebd-c564-4fb2-86e4-3fd2ee3c9797", "node_type": "1", "metadata": {"window": "So start looking around where you' re sitting now or at the end of class today, mingle a \nlittle bit and get to know your classmates.  I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? ", "original_text": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with. "}, "hash": "8060c588e1c957742da115c03f5e7441043263f9d16fc7527e0555c0e63ab34b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ce0d9d7-2762-4e1a-8392-c3f83c8ec350", "node_type": "1", "metadata": {"window": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. ", "original_text": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. "}, "hash": "f882f9825617e9a71f61ef7f7c73297484e0cd9bc04d92ad25f5245f0fc38a42", "class_name": "RelatedNodeInfo"}}, "hash": "bc27b1c0fbf3141edcf5a68c5594850c59a4b144c43466bec4791be7df2927b8", "text": "So I definitely encourage you to do that.  \n", "start_char_idx": 16588, "end_char_idx": 16632, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3ce0d9d7-2762-4e1a-8392-c3f83c8ec350": {"__data__": {"id_": "3ce0d9d7-2762-4e1a-8392-c3f83c8ec350", "embedding": null, "metadata": {"window": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. ", "original_text": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a057f2ec-fd3d-4232-9a4c-6e9cc1efbf74", "node_type": "1", "metadata": {"window": "I strongly encourage you to form study groups \nand sort of have a group of people to study with and have a group of your fellow students \nto talk over these concepts with.  You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n", "original_text": "So I definitely encourage you to do that.  \n"}, "hash": "bc27b1c0fbf3141edcf5a68c5594850c59a4b144c43466bec4791be7df2927b8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "32440711-f759-4f1b-bb0c-ab6fe7feb73f", "node_type": "1", "metadata": {"window": "But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n", "original_text": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n"}, "hash": "54315a4e5c55a9a073cb12273b12fc9dfdb5b882019eda68163723db6f1524f8", "class_name": "RelatedNodeInfo"}}, "hash": "f882f9825617e9a71f61ef7f7c73297484e0cd9bc04d92ad25f5245f0fc38a42", "text": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. ", "start_char_idx": 16632, "end_char_idx": 16791, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "32440711-f759-4f1b-bb0c-ab6fe7feb73f": {"__data__": {"id_": "32440711-f759-4f1b-bb0c-ab6fe7feb73f", "embedding": null, "metadata": {"window": "But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n", "original_text": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3ce0d9d7-2762-4e1a-8392-c3f83c8ec350", "node_type": "1", "metadata": {"window": "You can also  post on the class news group if you want to \nuse that to try to form a study group.  \n But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. ", "original_text": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together. "}, "hash": "f882f9825617e9a71f61ef7f7c73297484e0cd9bc04d92ad25f5245f0fc38a42", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "525fde1b-aa29-4b7e-83ea-f4d320d339d9", "node_type": "1", "metadata": {"window": "People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. ", "original_text": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? "}, "hash": "5afb5eb56d6c7adf3a176a34f9ae5457f49013e551d578b8bd1c4f3f6d8bcfc0", "class_name": "RelatedNodeInfo"}}, "hash": "54315a4e5c55a9a073cb12273b12fc9dfdb5b882019eda68163723db6f1524f8", "text": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n", "start_char_idx": 16791, "end_char_idx": 17023, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "525fde1b-aa29-4b7e-83ea-f4d320d339d9": {"__data__": {"id_": "525fde1b-aa29-4b7e-83ea-f4d320d339d9", "embedding": null, "metadata": {"window": "People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. ", "original_text": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32440711-f759-4f1b-bb0c-ab6fe7feb73f", "node_type": "1", "metadata": {"window": "But some of the problems sets in this cla ss are reasonably difficult.   People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n", "original_text": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n"}, "hash": "54315a4e5c55a9a073cb12273b12fc9dfdb5b882019eda68163723db6f1524f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "beef7256-e300-4986-b448-cf9d1ca31dd2", "node_type": "1", "metadata": {"window": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. ", "original_text": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n"}, "hash": "9bd7685852af2d1d61c7cf7d2b14c05fb226e68568ab34cc740ba7cc5c4a1380", "class_name": "RelatedNodeInfo"}}, "hash": "5afb5eb56d6c7adf3a176a34f9ae5457f49013e551d578b8bd1c4f3f6d8bcfc0", "text": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? ", "start_char_idx": 17023, "end_char_idx": 17268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "beef7256-e300-4986-b448-cf9d1ca31dd2": {"__data__": {"id_": "beef7256-e300-4986-b448-cf9d1ca31dd2", "embedding": null, "metadata": {"window": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. ", "original_text": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "525fde1b-aa29-4b7e-83ea-f4d320d339d9", "node_type": "1", "metadata": {"window": "People that have \ntaken the class before may tell you they were very difficult.  And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. ", "original_text": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay? "}, "hash": "5afb5eb56d6c7adf3a176a34f9ae5457f49013e551d578b8bd1c4f3f6d8bcfc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e8b85381-adb6-46e7-b05b-90179f5acd35", "node_type": "1", "metadata": {"window": "So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. ", "original_text": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. "}, "hash": "17a77857a8056b25ecb578d34ce1670c077aadd85341ee587f136e998de1f5be", "class_name": "RelatedNodeInfo"}}, "hash": "9bd7685852af2d1d61c7cf7d2b14c05fb226e68568ab34cc740ba7cc5c4a1380", "text": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n", "start_char_idx": 17268, "end_char_idx": 17371, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8b85381-adb6-46e7-b05b-90179f5acd35": {"__data__": {"id_": "e8b85381-adb6-46e7-b05b-90179f5acd35", "embedding": null, "metadata": {"window": "So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. ", "original_text": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "beef7256-e300-4986-b448-cf9d1ca31dd2", "node_type": "1", "metadata": {"window": "And just I bet it would be \nmore fun for you, and you'd probably have a be tter learning experience if you form a \nstudy group of people to work with.  So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. ", "original_text": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n"}, "hash": "9bd7685852af2d1d61c7cf7d2b14c05fb226e68568ab34cc740ba7cc5c4a1380", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66e45215-e79e-4a67-bc8b-2242b3236779", "node_type": "1", "metadata": {"window": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n", "original_text": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n"}, "hash": "d0ad1a54ec2ba946977625803d7983a629edebbedd5510dc54f33efc01010479", "class_name": "RelatedNodeInfo"}}, "hash": "17a77857a8056b25ecb578d34ce1670c077aadd85341ee587f136e998de1f5be", "text": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. ", "start_char_idx": 17371, "end_char_idx": 17511, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66e45215-e79e-4a67-bc8b-2242b3236779": {"__data__": {"id_": "66e45215-e79e-4a67-bc8b-2242b3236779", "embedding": null, "metadata": {"window": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n", "original_text": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e8b85381-adb6-46e7-b05b-90179f5acd35", "node_type": "1", "metadata": {"window": "So I definitely encourage you to do that.  \n And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. ", "original_text": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly. "}, "hash": "17a77857a8056b25ecb578d34ce1670c077aadd85341ee587f136e998de1f5be", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "04dcedee-6a25-4d37-bac9-18ac5b0e27c3", "node_type": "1", "metadata": {"window": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n", "original_text": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. "}, "hash": "071581ea9b962996a5088749aac76a0d39ea4b8af62bdcf8550f6f7614d1249f", "class_name": "RelatedNodeInfo"}}, "hash": "d0ad1a54ec2ba946977625803d7983a629edebbedd5510dc54f33efc01010479", "text": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n", "start_char_idx": 17511, "end_char_idx": 17836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "04dcedee-6a25-4d37-bac9-18ac5b0e27c3": {"__data__": {"id_": "04dcedee-6a25-4d37-bac9-18ac5b0e27c3", "embedding": null, "metadata": {"window": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n", "original_text": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66e45215-e79e-4a67-bc8b-2242b3236779", "node_type": "1", "metadata": {"window": "And just to say a word on the honor code, whic h is I definitely en courage you to form a \nstudy group and work together, discuss homew ork problems together.  But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n", "original_text": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n"}, "hash": "d0ad1a54ec2ba946977625803d7983a629edebbedd5510dc54f33efc01010479", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f3b3a4d4-f2a8-44b6-a6d4-93af015ee702", "node_type": "1", "metadata": {"window": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n", "original_text": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. "}, "hash": "a17fbe51836ec773cd3b063bd006d9cddf18135c9b48d2afa1693300ac7f1cd3", "class_name": "RelatedNodeInfo"}}, "hash": "071581ea9b962996a5088749aac76a0d39ea4b8af62bdcf8550f6f7614d1249f", "text": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. ", "start_char_idx": 17836, "end_char_idx": 17971, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3b3a4d4-f2a8-44b6-a6d4-93af015ee702": {"__data__": {"id_": "f3b3a4d4-f2a8-44b6-a6d4-93af015ee702", "embedding": null, "metadata": {"window": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n", "original_text": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "04dcedee-6a25-4d37-bac9-18ac5b0e27c3", "node_type": "1", "metadata": {"window": "But if you discuss \n\nhomework problems with other students, then  I'll ask you to sort of go home and write \ndown your own solutions independe ntly without referring to note s that were taken in any \nof your joint study sessions.  \n So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n", "original_text": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class. "}, "hash": "071581ea9b962996a5088749aac76a0d39ea4b8af62bdcf8550f6f7614d1249f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d1f7385-c314-4b80-84ee-e3267c675f91", "node_type": "1", "metadata": {"window": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see. ", "original_text": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. "}, "hash": "4561dea3a69a92e7fa1f942bf18a4b9cc1fae1d8bda25058ac26688a853b5577", "class_name": "RelatedNodeInfo"}}, "hash": "a17fbe51836ec773cd3b063bd006d9cddf18135c9b48d2afa1693300ac7f1cd3", "text": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. ", "start_char_idx": 17971, "end_char_idx": 18083, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0d1f7385-c314-4b80-84ee-e3267c675f91": {"__data__": {"id_": "0d1f7385-c314-4b80-84ee-e3267c675f91", "embedding": null, "metadata": {"window": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see. ", "original_text": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3b3a4d4-f2a8-44b6-a6d4-93af015ee702", "node_type": "1", "metadata": {"window": "So in other words, when you turn in a hom ework problem, what you turn in should be \nsomething that was reconstructed independe ntly by yourself and w ithout referring to \nnotes that you took during your  study sessions with other people, okay?  And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n", "original_text": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number. "}, "hash": "a17fbe51836ec773cd3b063bd006d9cddf18135c9b48d2afa1693300ac7f1cd3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "155a5b0e-d579-4055-9517-58dbfc56a5bb", "node_type": "1", "metadata": {"window": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject. ", "original_text": "I'd love for that \nto happen.  \n"}, "hash": "11bba99265e089eebd13b2e69f7b5254779a0ec96ecea544f0fb441807032aaf", "class_name": "RelatedNodeInfo"}}, "hash": "4561dea3a69a92e7fa1f942bf18a4b9cc1fae1d8bda25058ac26688a853b5577", "text": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. ", "start_char_idx": 18083, "end_char_idx": 18191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "155a5b0e-d579-4055-9517-58dbfc56a5bb": {"__data__": {"id_": "155a5b0e-d579-4055-9517-58dbfc56a5bb", "embedding": null, "metadata": {"window": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject. ", "original_text": "I'd love for that \nto happen.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d1f7385-c314-4b80-84ee-e3267c675f91", "node_type": "1", "metadata": {"window": "And obviously, \nshowing your solutions to othe rs or copying other solutions  directly is right out.  \n We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see. ", "original_text": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year. "}, "hash": "4561dea3a69a92e7fa1f942bf18a4b9cc1fae1d8bda25058ac26688a853b5577", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ded4819e-4ef9-4736-bd64-7fa62b5b253f", "node_type": "1", "metadata": {"window": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. ", "original_text": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n"}, "hash": "d37b30b3867b3a2958462a4d18eaa74b5f3487c582ee0a5f0cd4fda576ccf661", "class_name": "RelatedNodeInfo"}}, "hash": "11bba99265e089eebd13b2e69f7b5254779a0ec96ecea544f0fb441807032aaf", "text": "I'd love for that \nto happen.  \n", "start_char_idx": 18191, "end_char_idx": 18223, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ded4819e-4ef9-4736-bd64-7fa62b5b253f": {"__data__": {"id_": "ded4819e-4ef9-4736-bd64-7fa62b5b253f", "embedding": null, "metadata": {"window": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. ", "original_text": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "155a5b0e-d579-4055-9517-58dbfc56a5bb", "node_type": "1", "metadata": {"window": "We occasionally also reuse problem set questions from previous years so that the \nproblems are a bit more debugged and work more  smoothly.  And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject. ", "original_text": "I'd love for that \nto happen.  \n"}, "hash": "11bba99265e089eebd13b2e69f7b5254779a0ec96ecea544f0fb441807032aaf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3cb9d746-a900-4bd0-a68c-8385ef6f8865", "node_type": "1", "metadata": {"window": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n", "original_text": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n"}, "hash": "d4994dda97148fe055429c73a13afce2accb20ca0f81d57a457184f2d89a4a5f", "class_name": "RelatedNodeInfo"}}, "hash": "d37b30b3867b3a2958462a4d18eaa74b5f3487c582ee0a5f0cd4fda576ccf661", "text": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n", "start_char_idx": 18223, "end_char_idx": 18356, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3cb9d746-a900-4bd0-a68c-8385ef6f8865": {"__data__": {"id_": "3cb9d746-a900-4bd0-a68c-8385ef6f8865", "embedding": null, "metadata": {"window": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n", "original_text": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ded4819e-4ef9-4736-bd64-7fa62b5b253f", "node_type": "1", "metadata": {"window": "And as a result of that, I also \nask you not to look at solutions from previous ye ars, and this includes both sort of official \nsolutions that we've given out to previous gene rations of this class and previous solutions \nthat people that have taken this class in previous years may have written out by \nthemselves, okay?  \n Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. ", "original_text": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n"}, "hash": "d37b30b3867b3a2958462a4d18eaa74b5f3487c582ee0a5f0cd4fda576ccf661", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "11763e29-7b0c-4871-8f24-4fe5d0eefe2e", "node_type": "1", "metadata": {"window": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. ", "original_text": "And let's see. "}, "hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "class_name": "RelatedNodeInfo"}}, "hash": "d4994dda97148fe055429c73a13afce2accb20ca0f81d57a457184f2d89a4a5f", "text": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n", "start_char_idx": 18356, "end_char_idx": 18480, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "11763e29-7b0c-4871-8f24-4fe5d0eefe2e": {"__data__": {"id_": "11763e29-7b0c-4871-8f24-4fe5d0eefe2e", "embedding": null, "metadata": {"window": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. ", "original_text": "And let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3cb9d746-a900-4bd0-a68c-8385ef6f8865", "node_type": "1", "metadata": {"window": "Sadly, in this class, there are usually \u2014 sadly, in previous y ears, there have often been a \nfew honor code violations in this class.  And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n", "original_text": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n"}, "hash": "d4994dda97148fe055429c73a13afce2accb20ca0f81d57a457184f2d89a4a5f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "30eb16bd-ea86-4751-bfc0-982fd4368e67", "node_type": "1", "metadata": {"window": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n", "original_text": "And one more administrative thing I wanted to sa y is about the class \nproject. "}, "hash": "7b109cc70bdf95925a20df6e2f5845a3255d2308048de4f820c3d4e035e75c1c", "class_name": "RelatedNodeInfo"}}, "hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "text": "And let's see. ", "start_char_idx": 18480, "end_char_idx": 18495, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "30eb16bd-ea86-4751-bfc0-982fd4368e67": {"__data__": {"id_": "30eb16bd-ea86-4751-bfc0-982fd4368e67", "embedding": null, "metadata": {"window": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n", "original_text": "And one more administrative thing I wanted to sa y is about the class \nproject. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "11763e29-7b0c-4871-8f24-4fe5d0eefe2e", "node_type": "1", "metadata": {"window": "And last year, I think I pr osecuted five honor code \nviolations, which I think is a ridiculously large number.  And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. ", "original_text": "And let's see. "}, "hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d70e34f2-f0d3-4b55-bc33-6936021a7071", "node_type": "1", "metadata": {"window": "I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. ", "original_text": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. "}, "hash": "8d5cd39a4aac4d992046427b13c0a6bbd2887f8201d4fd583a367d49d213ce76", "class_name": "RelatedNodeInfo"}}, "hash": "7b109cc70bdf95925a20df6e2f5845a3255d2308048de4f820c3d4e035e75c1c", "text": "And one more administrative thing I wanted to sa y is about the class \nproject. ", "start_char_idx": 18495, "end_char_idx": 18575, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d70e34f2-f0d3-4b55-bc33-6936021a7071": {"__data__": {"id_": "d70e34f2-f0d3-4b55-bc33-6936021a7071", "embedding": null, "metadata": {"window": "I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. ", "original_text": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "30eb16bd-ea86-4751-bfc0-982fd4368e67", "node_type": "1", "metadata": {"window": "And so just don't work without \nsolutions, and hopefully there'll be zero honor code  violations this year.  I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n", "original_text": "And one more administrative thing I wanted to sa y is about the class \nproject. "}, "hash": "7b109cc70bdf95925a20df6e2f5845a3255d2308048de4f820c3d4e035e75c1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e07d5df5-5bb3-4e61-92de-071acc10e170", "node_type": "1", "metadata": {"window": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n", "original_text": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n"}, "hash": "7f41cfa428d8b8c09eba7f07afad2dea814dcc37a871b2d47cdeab44d321f981", "class_name": "RelatedNodeInfo"}}, "hash": "8d5cd39a4aac4d992046427b13c0a6bbd2887f8201d4fd583a367d49d213ce76", "text": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. ", "start_char_idx": 18575, "end_char_idx": 18732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e07d5df5-5bb3-4e61-92de-071acc10e170": {"__data__": {"id_": "e07d5df5-5bb3-4e61-92de-071acc10e170", "embedding": null, "metadata": {"window": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n", "original_text": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d70e34f2-f0d3-4b55-bc33-6936021a7071", "node_type": "1", "metadata": {"window": "I'd love for that \nto happen.  \n The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. ", "original_text": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning. "}, "hash": "8d5cd39a4aac4d992046427b13c0a6bbd2887f8201d4fd583a367d49d213ce76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3e059260-9d9a-41ec-95c8-c4031c2b24e4", "node_type": "1", "metadata": {"window": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see. ", "original_text": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. "}, "hash": "2b4d6b5a05ec0ad15c6b789f55d4e5e2c449da6080ed3f7bbd209507b2e2abaa", "class_name": "RelatedNodeInfo"}}, "hash": "7f41cfa428d8b8c09eba7f07afad2dea814dcc37a871b2d47cdeab44d321f981", "text": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n", "start_char_idx": 18732, "end_char_idx": 18848, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3e059260-9d9a-41ec-95c8-c4031c2b24e4": {"__data__": {"id_": "3e059260-9d9a-41ec-95c8-c4031c2b24e4", "embedding": null, "metadata": {"window": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see. ", "original_text": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e07d5df5-5bb3-4e61-92de-071acc10e170", "node_type": "1", "metadata": {"window": "The section here on the late homework polic y if you ever want to hand in a homework \nlate, I'll leave you to r ead that yourself.  \n We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n", "original_text": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n"}, "hash": "7f41cfa428d8b8c09eba7f07afad2dea814dcc37a871b2d47cdeab44d321f981", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc0fe5c8-ba3c-4185-b984-bb6373576732", "node_type": "1", "metadata": {"window": "And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n", "original_text": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n"}, "hash": "72fb581640563d25931c9d38954a5568031b921a3d267165b23cd6d1c45b00dd", "class_name": "RelatedNodeInfo"}}, "hash": "2b4d6b5a05ec0ad15c6b789f55d4e5e2c449da6080ed3f7bbd209507b2e2abaa", "text": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. ", "start_char_idx": 18848, "end_char_idx": 19006, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cc0fe5c8-ba3c-4185-b984-bb6373576732": {"__data__": {"id_": "cc0fe5c8-ba3c-4185-b984-bb6373576732", "embedding": null, "metadata": {"window": "And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n", "original_text": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e059260-9d9a-41ec-95c8-c4031c2b24e4", "node_type": "1", "metadata": {"window": "We also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \nso please keep that evening free.  \n And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see. ", "original_text": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning. "}, "hash": "2b4d6b5a05ec0ad15c6b789f55d4e5e2c449da6080ed3f7bbd209507b2e2abaa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1de0d645-1f8e-469b-811b-1c9afc3dbb69", "node_type": "1", "metadata": {"window": "And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. ", "original_text": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. "}, "hash": "43d73780e92166418280b844d50691d522be8a0a39dbfc4a07f4107dc6bf8241", "class_name": "RelatedNodeInfo"}}, "hash": "72fb581640563d25931c9d38954a5568031b921a3d267165b23cd6d1c45b00dd", "text": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n", "start_char_idx": 19006, "end_char_idx": 19478, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1de0d645-1f8e-469b-811b-1c9afc3dbb69": {"__data__": {"id_": "1de0d645-1f8e-469b-811b-1c9afc3dbb69", "embedding": null, "metadata": {"window": "And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. ", "original_text": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc0fe5c8-ba3c-4185-b984-bb6373576732", "node_type": "1", "metadata": {"window": "And let's see.  And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n", "original_text": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n"}, "hash": "72fb581640563d25931c9d38954a5568031b921a3d267165b23cd6d1c45b00dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "61f4d134-c4d8-45ce-b8d2-638bae48b9ce", "node_type": "1", "metadata": {"window": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand. ", "original_text": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n"}, "hash": "b580f7d587eabbf1d36df27b413abdf415b98fae786051a5af6dfe4cae0aaccc", "class_name": "RelatedNodeInfo"}}, "hash": "43d73780e92166418280b844d50691d522be8a0a39dbfc4a07f4107dc6bf8241", "text": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. ", "start_char_idx": 19478, "end_char_idx": 19651, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61f4d134-c4d8-45ce-b8d2-638bae48b9ce": {"__data__": {"id_": "61f4d134-c4d8-45ce-b8d2-638bae48b9ce", "embedding": null, "metadata": {"window": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand. ", "original_text": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1de0d645-1f8e-469b-811b-1c9afc3dbb69", "node_type": "1", "metadata": {"window": "And one more administrative thing I wanted to sa y is about the class \nproject.  So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. ", "original_text": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about. "}, "hash": "43d73780e92166418280b844d50691d522be8a0a39dbfc4a07f4107dc6bf8241", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "828ff51a-7f12-4d8e-ac15-5e8c74b4ff19", "node_type": "1", "metadata": {"window": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n", "original_text": "And let's see. "}, "hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "class_name": "RelatedNodeInfo"}}, "hash": "b580f7d587eabbf1d36df27b413abdf415b98fae786051a5af6dfe4cae0aaccc", "text": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n", "start_char_idx": 19651, "end_char_idx": 19784, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "828ff51a-7f12-4d8e-ac15-5e8c74b4ff19": {"__data__": {"id_": "828ff51a-7f12-4d8e-ac15-5e8c74b4ff19", "embedding": null, "metadata": {"window": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n", "original_text": "And let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61f4d134-c4d8-45ce-b8d2-638bae48b9ce", "node_type": "1", "metadata": {"window": "So part of the goal of this cla ss is to leave you well eq uipped to apply machine \nlearning algorithms to a problem or to do rese arch in machine learning.  And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand. ", "original_text": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n"}, "hash": "b580f7d587eabbf1d36df27b413abdf415b98fae786051a5af6dfe4cae0aaccc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d70b1cb-1f72-47c5-a8cc-f016938078dc", "node_type": "1", "metadata": {"window": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. ", "original_text": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n"}, "hash": "5eafc3dc0803d95fb2b56283f6289c23143baa30451e276bf8b098b59d2c0069", "class_name": "RelatedNodeInfo"}}, "hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "text": "And let's see. ", "start_char_idx": 18480, "end_char_idx": 18495, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6d70b1cb-1f72-47c5-a8cc-f016938078dc": {"__data__": {"id_": "6d70b1cb-1f72-47c5-a8cc-f016938078dc", "embedding": null, "metadata": {"window": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. ", "original_text": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "828ff51a-7f12-4d8e-ac15-5e8c74b4ff19", "node_type": "1", "metadata": {"window": "And so as part of \nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \n And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n", "original_text": "And let's see. "}, "hash": "5ba94ed54554715c15fd23702b297dfbea53b638e3e8a06cdfcfdca238b755ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8706beab-0055-44c0-9a77-08910e8adc56", "node_type": "1", "metadata": {"window": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms. ", "original_text": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. "}, "hash": "de7eee609be433fcc8d8691cf3098d805b116ddb762946e991a62e20c1c89c76", "class_name": "RelatedNodeInfo"}}, "hash": "5eafc3dc0803d95fb2b56283f6289c23143baa30451e276bf8b098b59d2c0069", "text": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n", "start_char_idx": 19799, "end_char_idx": 19925, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8706beab-0055-44c0-9a77-08910e8adc56": {"__data__": {"id_": "8706beab-0055-44c0-9a77-08910e8adc56", "embedding": null, "metadata": {"window": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms. ", "original_text": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6d70b1cb-1f72-47c5-a8cc-f016938078dc", "node_type": "1", "metadata": {"window": "And what most students do for this is either  apply machine learning to a problem that you \nfind interesting or investigate some aspect of  machine learning.  So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. ", "original_text": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n"}, "hash": "5eafc3dc0803d95fb2b56283f6289c23143baa30451e276bf8b098b59d2c0069", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "35ccc861-0059-4acf-a7a8-ef0a6c9c92e9", "node_type": "1", "metadata": {"window": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft. ", "original_text": "And so I'm holding the li st in my hand. "}, "hash": "46aa22f53a1da0b29ae4d47500750a7022a3221ee9b560d89ffd41f383b7e1d8", "class_name": "RelatedNodeInfo"}}, "hash": "de7eee609be433fcc8d8691cf3098d805b116ddb762946e991a62e20c1c89c76", "text": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. ", "start_char_idx": 19925, "end_char_idx": 20042, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "35ccc861-0059-4acf-a7a8-ef0a6c9c92e9": {"__data__": {"id_": "35ccc861-0059-4acf-a7a8-ef0a6c9c92e9", "embedding": null, "metadata": {"window": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft. ", "original_text": "And so I'm holding the li st in my hand. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8706beab-0055-44c0-9a77-08910e8adc56", "node_type": "1", "metadata": {"window": "So to those of you that \nare either already doing research or to those of you who are in industry, you're taking this \nfrom a company, one fantastic sort of way to do a class project would be if you apply \nmachine learning algorithms to a problem that  you're interested in, to a problem that \nyou're already working on, whether it be a scien ce research problem or sort of a problem \nin industry where you're trying to get a syst em to work using a learning algorithm.  \n To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms. ", "original_text": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year. "}, "hash": "de7eee609be433fcc8d8691cf3098d805b116ddb762946e991a62e20c1c89c76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "910cac67-793c-4b24-a81e-9aa96c3bb663", "node_type": "1", "metadata": {"window": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n", "original_text": "You can  go home later and \ntake a look at it online.  \n"}, "hash": "db5c63fedd37421f8f9c3f19a9e159f62f938ddbf0cf86759ab4688ecf87186d", "class_name": "RelatedNodeInfo"}}, "hash": "46aa22f53a1da0b29ae4d47500750a7022a3221ee9b560d89ffd41f383b7e1d8", "text": "And so I'm holding the li st in my hand. ", "start_char_idx": 20042, "end_char_idx": 20083, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "910cac67-793c-4b24-a81e-9aa96c3bb663": {"__data__": {"id_": "910cac67-793c-4b24-a81e-9aa96c3bb663", "embedding": null, "metadata": {"window": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n", "original_text": "You can  go home later and \ntake a look at it online.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35ccc861-0059-4acf-a7a8-ef0a6c9c92e9", "node_type": "1", "metadata": {"window": "To those of you that are not currently doing re search, one great way to do a project would \nbe if you apply learning algorithms to just pick a problem that you care about.  Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft. ", "original_text": "And so I'm holding the li st in my hand. "}, "hash": "46aa22f53a1da0b29ae4d47500750a7022a3221ee9b560d89ffd41f383b7e1d8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2fc42a5e-71e2-48e7-bb56-15d2cd04600e", "node_type": "1", "metadata": {"window": "And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. ", "original_text": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. "}, "hash": "1701488d18e522e3782448f9f358711448f4568f3ddfab031a366156492b770e", "class_name": "RelatedNodeInfo"}}, "hash": "db5c63fedd37421f8f9c3f19a9e159f62f938ddbf0cf86759ab4688ecf87186d", "text": "You can  go home later and \ntake a look at it online.  \n", "start_char_idx": 20083, "end_char_idx": 20139, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2fc42a5e-71e2-48e7-bb56-15d2cd04600e": {"__data__": {"id_": "2fc42a5e-71e2-48e7-bb56-15d2cd04600e", "embedding": null, "metadata": {"window": "And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. ", "original_text": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "910cac67-793c-4b24-a81e-9aa96c3bb663", "node_type": "1", "metadata": {"window": "Pick a \nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \nideas and see what happens.  \n\n And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n", "original_text": "You can  go home later and \ntake a look at it online.  \n"}, "hash": "db5c63fedd37421f8f9c3f19a9e159f62f938ddbf0cf86759ab4688ecf87186d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ea32b5e4-cbd7-4a1c-9e71-1acdd79c02c5", "node_type": "1", "metadata": {"window": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. ", "original_text": "Ther e was a few projects on improving learning \nalgorithms. "}, "hash": "bd4edab755109ac5704c7dde6fc7e8313293f0fdf7208fc9065082b64fb44f9f", "class_name": "RelatedNodeInfo"}}, "hash": "1701488d18e522e3782448f9f358711448f4568f3ddfab031a366156492b770e", "text": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. ", "start_char_idx": 20139, "end_char_idx": 20271, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ea32b5e4-cbd7-4a1c-9e71-1acdd79c02c5": {"__data__": {"id_": "ea32b5e4-cbd7-4a1c-9e71-1acdd79c02c5", "embedding": null, "metadata": {"window": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. ", "original_text": "Ther e was a few projects on improving learning \nalgorithms. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2fc42a5e-71e2-48e7-bb56-15d2cd04600e", "node_type": "1", "metadata": {"window": "And let's see.  Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. ", "original_text": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot. "}, "hash": "1701488d18e522e3782448f9f358711448f4568f3ddfab031a366156492b770e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a532e9b5-8c59-4fa3-9f09-bf0011d24a1d", "node_type": "1", "metadata": {"window": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n", "original_text": "There's a project on flying autonomous  aircraft. "}, "hash": "b1142436834078bbc70a0370a1172ded041f117002579d116bb16da512b0dfc9", "class_name": "RelatedNodeInfo"}}, "hash": "bd4edab755109ac5704c7dde6fc7e8313293f0fdf7208fc9065082b64fb44f9f", "text": "Ther e was a few projects on improving learning \nalgorithms. ", "start_char_idx": 20271, "end_char_idx": 20332, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a532e9b5-8c59-4fa3-9f09-bf0011d24a1d": {"__data__": {"id_": "a532e9b5-8c59-4fa3-9f09-bf0011d24a1d", "embedding": null, "metadata": {"window": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n", "original_text": "There's a project on flying autonomous  aircraft. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ea32b5e4-cbd7-4a1c-9e71-1acdd79c02c5", "node_type": "1", "metadata": {"window": "Oh, and the goal of the projec t should really be for you to do a publishable \npiece of research in machine learning, okay?  \n And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. ", "original_text": "Ther e was a few projects on improving learning \nalgorithms. "}, "hash": "bd4edab755109ac5704c7dde6fc7e8313293f0fdf7208fc9065082b64fb44f9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ddbe670-4043-47da-aa02-6349f53851fb", "node_type": "1", "metadata": {"window": "And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects. ", "original_text": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n"}, "hash": "4b01f92f6588ffe0f9c45d120f24ff455a5d9e4e291c63c278739960021f59b7", "class_name": "RelatedNodeInfo"}}, "hash": "b1142436834078bbc70a0370a1172ded041f117002579d116bb16da512b0dfc9", "text": "There's a project on flying autonomous  aircraft. ", "start_char_idx": 20332, "end_char_idx": 20382, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9ddbe670-4043-47da-aa02-6349f53851fb": {"__data__": {"id_": "9ddbe670-4043-47da-aa02-6349f53851fb", "embedding": null, "metadata": {"window": "And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects. ", "original_text": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a532e9b5-8c59-4fa3-9f09-bf0011d24a1d", "node_type": "1", "metadata": {"window": "And if you go to the course website, you'll actuall y find a list of the projects that students \nhad done last year.  And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n", "original_text": "There's a project on flying autonomous  aircraft. "}, "hash": "b1142436834078bbc70a0370a1172ded041f117002579d116bb16da512b0dfc9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c70c51f2-bbf0-42a4-a9cd-acc9025d1474", "node_type": "1", "metadata": {"window": "You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas. ", "original_text": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. "}, "hash": "7a2cf4d5c6c6ece996c9bc6e55f4b427d7c9e9603fc06cf28ab5c16c0b7f058b", "class_name": "RelatedNodeInfo"}}, "hash": "4b01f92f6588ffe0f9c45d120f24ff455a5d9e4e291c63c278739960021f59b7", "text": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n", "start_char_idx": 20382, "end_char_idx": 20500, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c70c51f2-bbf0-42a4-a9cd-acc9025d1474": {"__data__": {"id_": "c70c51f2-bbf0-42a4-a9cd-acc9025d1474", "embedding": null, "metadata": {"window": "You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas. ", "original_text": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ddbe670-4043-47da-aa02-6349f53851fb", "node_type": "1", "metadata": {"window": "And so I'm holding the li st in my hand.  You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects. ", "original_text": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n"}, "hash": "4b01f92f6588ffe0f9c45d120f24ff455a5d9e4e291c63c278739960021f59b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3623d2b6-9c56-455e-aefb-593f55f26e30", "node_type": "1", "metadata": {"window": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. ", "original_text": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. "}, "hash": "0d09dd3dcc5824afeccae93f062a77b921eceb795f266661578cc7e1ed563ce5", "class_name": "RelatedNodeInfo"}}, "hash": "7a2cf4d5c6c6ece996c9bc6e55f4b427d7c9e9603fc06cf28ab5c16c0b7f058b", "text": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. ", "start_char_idx": 20500, "end_char_idx": 21017, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3623d2b6-9c56-455e-aefb-593f55f26e30": {"__data__": {"id_": "3623d2b6-9c56-455e-aefb-593f55f26e30", "embedding": null, "metadata": {"window": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. ", "original_text": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c70c51f2-bbf0-42a4-a9cd-acc9025d1474", "node_type": "1", "metadata": {"window": "You can  go home later and \ntake a look at it online.  \n But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas. ", "original_text": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading. "}, "hash": "7a2cf4d5c6c6ece996c9bc6e55f4b427d7c9e9603fc06cf28ab5c16c0b7f058b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77199c7c-349f-46ff-be92-58092e2ef7a3", "node_type": "1", "metadata": {"window": "Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n", "original_text": "There's a learning algorithm on op tical illusions, and \nso on.  \n"}, "hash": "296ab43358e4d9b9641b86ac6af3ce618bb072c1501ead69274a8c446cfad9f4", "class_name": "RelatedNodeInfo"}}, "hash": "0d09dd3dcc5824afeccae93f062a77b921eceb795f266661578cc7e1ed563ce5", "text": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. ", "start_char_idx": 21017, "end_char_idx": 21160, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77199c7c-349f-46ff-be92-58092e2ef7a3": {"__data__": {"id_": "77199c7c-349f-46ff-be92-58092e2ef7a3", "embedding": null, "metadata": {"window": "Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n", "original_text": "There's a learning algorithm on op tical illusions, and \nso on.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3623d2b6-9c56-455e-aefb-593f55f26e30", "node_type": "1", "metadata": {"window": "But reading down this list, I see that last year, there were st udents that ap plied learning \nalgorithms to control a snake robot.  Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. ", "original_text": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive. "}, "hash": "0d09dd3dcc5824afeccae93f062a77b921eceb795f266661578cc7e1ed563ce5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a9da18de-b3b4-43f6-b49e-12399dbf5493", "node_type": "1", "metadata": {"window": "There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n", "original_text": "And it goes on, so lots of fun projects. "}, "hash": "77ddac329c9609ded850255372794880307198b728cc2f1c2eb015fcd6c702ba", "class_name": "RelatedNodeInfo"}}, "hash": "296ab43358e4d9b9641b86ac6af3ce618bb072c1501ead69274a8c446cfad9f4", "text": "There's a learning algorithm on op tical illusions, and \nso on.  \n", "start_char_idx": 21160, "end_char_idx": 21226, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a9da18de-b3b4-43f6-b49e-12399dbf5493": {"__data__": {"id_": "a9da18de-b3b4-43f6-b49e-12399dbf5493", "embedding": null, "metadata": {"window": "There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n", "original_text": "And it goes on, so lots of fun projects. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77199c7c-349f-46ff-be92-58092e2ef7a3", "node_type": "1", "metadata": {"window": "Ther e was a few projects on improving learning \nalgorithms.  There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n", "original_text": "There's a learning algorithm on op tical illusions, and \nso on.  \n"}, "hash": "296ab43358e4d9b9641b86ac6af3ce618bb072c1501ead69274a8c446cfad9f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d972bf5a-6e28-46f9-9c83-bc47753f1ab5", "node_type": "1", "metadata": {"window": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n", "original_text": "A nd take a look, then come up with your own \nideas. "}, "hash": "d055d58bff889ce829c8a39757ea18c6214bcf1f3312322f7416df7b80feadec", "class_name": "RelatedNodeInfo"}}, "hash": "77ddac329c9609ded850255372794880307198b728cc2f1c2eb015fcd6c702ba", "text": "And it goes on, so lots of fun projects. ", "start_char_idx": 21226, "end_char_idx": 21267, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d972bf5a-6e28-46f9-9c83-bc47753f1ab5": {"__data__": {"id_": "d972bf5a-6e28-46f9-9c83-bc47753f1ab5", "embedding": null, "metadata": {"window": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n", "original_text": "A nd take a look, then come up with your own \nideas. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a9da18de-b3b4-43f6-b49e-12399dbf5493", "node_type": "1", "metadata": {"window": "There's a project on flying autonomous  aircraft.  There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n", "original_text": "And it goes on, so lots of fun projects. "}, "hash": "77ddac329c9609ded850255372794880307198b728cc2f1c2eb015fcd6c702ba", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "979503fd-7488-4d64-8817-13fbb161895a", "node_type": "1", "metadata": {"window": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n", "original_text": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. "}, "hash": "2af5f8022ce6634a59c6b9c281a3b7c9979a7416e6a786f39d1f71e7bfbe2a7d", "class_name": "RelatedNodeInfo"}}, "hash": "d055d58bff889ce829c8a39757ea18c6214bcf1f3312322f7416df7b80feadec", "text": "A nd take a look, then come up with your own \nideas. ", "start_char_idx": 21267, "end_char_idx": 21320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "979503fd-7488-4d64-8817-13fbb161895a": {"__data__": {"id_": "979503fd-7488-4d64-8817-13fbb161895a", "embedding": null, "metadata": {"window": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n", "original_text": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d972bf5a-6e28-46f9-9c83-bc47753f1ab5", "node_type": "1", "metadata": {"window": "There was a project actually \ndone by our TA Paul on improvi ng computer vision algorithms  using machine learning.  \n There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n", "original_text": "A nd take a look, then come up with your own \nideas. "}, "hash": "d055d58bff889ce829c8a39757ea18c6214bcf1f3312322f7416df7b80feadec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fdbf51a6-b01c-4d36-a5ac-e9b3761a9ed4", "node_type": "1", "metadata": {"window": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right. ", "original_text": "Yeah, question?  \n"}, "hash": "0984ee79ac23493d9bcf4d411fdb58da7207ca498b6afb00893e52fe5cd5067b", "class_name": "RelatedNodeInfo"}}, "hash": "2af5f8022ce6634a59c6b9c281a3b7c9979a7416e6a786f39d1f71e7bfbe2a7d", "text": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. ", "start_char_idx": 21320, "end_char_idx": 21434, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fdbf51a6-b01c-4d36-a5ac-e9b3761a9ed4": {"__data__": {"id_": "fdbf51a6-b01c-4d36-a5ac-e9b3761a9ed4", "embedding": null, "metadata": {"window": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right. ", "original_text": "Yeah, question?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "979503fd-7488-4d64-8817-13fbb161895a", "node_type": "1", "metadata": {"window": "There are a couple of project s on Netflix rankings using learning algorithms; a few \nmedical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using \nlearning algorithms; one on musical instrume nt detection; anot her on irony sequence \nalignment; and a few algorithms on understandin g the brain neuroscience, actually quite a \nfew projects on neuroscience; a couple of projects on unde scending fMRI data on brain \nscans, and so on; another project on market makings, the financial trading.  There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n", "original_text": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it. "}, "hash": "2af5f8022ce6634a59c6b9c281a3b7c9979a7416e6a786f39d1f71e7bfbe2a7d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4262fe4b-d936-4814-bf4d-de9fcf732949", "node_type": "1", "metadata": {"window": "There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n", "original_text": "Student : Are these gro up projects?  \n"}, "hash": "b9f2af44f5a7a761a34561e2b944f5f8ef5b44641d82f78a88fb27f3572071c1", "class_name": "RelatedNodeInfo"}}, "hash": "0984ee79ac23493d9bcf4d411fdb58da7207ca498b6afb00893e52fe5cd5067b", "text": "Yeah, question?  \n", "start_char_idx": 21434, "end_char_idx": 21452, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4262fe4b-d936-4814-bf4d-de9fcf732949": {"__data__": {"id_": "4262fe4b-d936-4814-bf4d-de9fcf732949", "embedding": null, "metadata": {"window": "There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n", "original_text": "Student : Are these gro up projects?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fdbf51a6-b01c-4d36-a5ac-e9b3761a9ed4", "node_type": "1", "metadata": {"window": "There was an \ninteresting project on trying to use learning algorithms to decide what is it that makes a \nperson's face physically attractive.  There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right. ", "original_text": "Yeah, question?  \n"}, "hash": "0984ee79ac23493d9bcf4d411fdb58da7207ca498b6afb00893e52fe5cd5067b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6279660c-0d22-4b21-bcc3-983340ac5d23", "node_type": "1", "metadata": {"window": "And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? ", "original_text": "Instructor (Andrew Ng): Oh, yes, thank you.  \n"}, "hash": "03c93675d2d81414ee214e639d15cecc17138e746b5cd4ec13792fceb3ff0e4a", "class_name": "RelatedNodeInfo"}}, "hash": "b9f2af44f5a7a761a34561e2b944f5f8ef5b44641d82f78a88fb27f3572071c1", "text": "Student : Are these gro up projects?  \n", "start_char_idx": 21452, "end_char_idx": 21491, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6279660c-0d22-4b21-bcc3-983340ac5d23": {"__data__": {"id_": "6279660c-0d22-4b21-bcc3-983340ac5d23", "embedding": null, "metadata": {"window": "And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? ", "original_text": "Instructor (Andrew Ng): Oh, yes, thank you.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4262fe4b-d936-4814-bf4d-de9fcf732949", "node_type": "1", "metadata": {"window": "There's a learning algorithm on op tical illusions, and \nso on.  \n And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n", "original_text": "Student : Are these gro up projects?  \n"}, "hash": "b9f2af44f5a7a761a34561e2b944f5f8ef5b44641d82f78a88fb27f3572071c1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fdb40385-4472-4484-ad57-29858ef66959", "node_type": "1", "metadata": {"window": "A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves. ", "original_text": "Student : So how many people can be in a group?  \n"}, "hash": "a074fad27c9d17cb4fe24593afe8fe96ce4c5484143ab03320f4c3198a767a3d", "class_name": "RelatedNodeInfo"}}, "hash": "03c93675d2d81414ee214e639d15cecc17138e746b5cd4ec13792fceb3ff0e4a", "text": "Instructor (Andrew Ng): Oh, yes, thank you.  \n", "start_char_idx": 21491, "end_char_idx": 21537, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fdb40385-4472-4484-ad57-29858ef66959": {"__data__": {"id_": "fdb40385-4472-4484-ad57-29858ef66959", "embedding": null, "metadata": {"window": "A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves. ", "original_text": "Student : So how many people can be in a group?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6279660c-0d22-4b21-bcc3-983340ac5d23", "node_type": "1", "metadata": {"window": "And it goes on, so lots of fun projects.  A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? ", "original_text": "Instructor (Andrew Ng): Oh, yes, thank you.  \n"}, "hash": "03c93675d2d81414ee214e639d15cecc17138e746b5cd4ec13792fceb3ff0e4a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3243e697-6745-4191-bd0c-444df7098494", "node_type": "1", "metadata": {"window": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n", "original_text": "Instructor (Andrew Ng): Right. "}, "hash": "c57149b3d8bc33fadc553594a269834f40b2d98644b3bd7ff95f1570b6b455da", "class_name": "RelatedNodeInfo"}}, "hash": "a074fad27c9d17cb4fe24593afe8fe96ce4c5484143ab03320f4c3198a767a3d", "text": "Student : So how many people can be in a group?  \n", "start_char_idx": 21537, "end_char_idx": 21587, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3243e697-6745-4191-bd0c-444df7098494": {"__data__": {"id_": "3243e697-6745-4191-bd0c-444df7098494", "embedding": null, "metadata": {"window": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n", "original_text": "Instructor (Andrew Ng): Right. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fdb40385-4472-4484-ad57-29858ef66959", "node_type": "1", "metadata": {"window": "A nd take a look, then come up with your own \nideas.  But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves. ", "original_text": "Student : So how many people can be in a group?  \n"}, "hash": "a074fad27c9d17cb4fe24593afe8fe96ce4c5484143ab03320f4c3198a767a3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8ab6cc4-216e-4ab6-a84b-e5e78533ad97", "node_type": "1", "metadata": {"window": "Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay. ", "original_text": "So projects can be done in  groups of up to three people. \n"}, "hash": "34475234759f60492d75a3c21232132dce2ab375875985ea80ff123d6ba15c1a", "class_name": "RelatedNodeInfo"}}, "hash": "c57149b3d8bc33fadc553594a269834f40b2d98644b3bd7ff95f1570b6b455da", "text": "Instructor (Andrew Ng): Right. ", "start_char_idx": 21587, "end_char_idx": 21618, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8ab6cc4-216e-4ab6-a84b-e5e78533ad97": {"__data__": {"id_": "a8ab6cc4-216e-4ab6-a84b-e5e78533ad97", "embedding": null, "metadata": {"window": "Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay. ", "original_text": "So projects can be done in  groups of up to three people. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3243e697-6745-4191-bd0c-444df7098494", "node_type": "1", "metadata": {"window": "But whatever you find cool and interest ing, I hope you'll be able to make machine \nlearning a project out of it.  Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n", "original_text": "Instructor (Andrew Ng): Right. "}, "hash": "c57149b3d8bc33fadc553594a269834f40b2d98644b3bd7ff95f1570b6b455da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "96f06b1f-cff6-4862-befb-cd100a32f5a6", "node_type": "1", "metadata": {"window": "Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion. ", "original_text": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? "}, "hash": "96735df2449852c511edab5ed0302df111185cecdf0c057182e87ca50fb4d464", "class_name": "RelatedNodeInfo"}}, "hash": "34475234759f60492d75a3c21232132dce2ab375875985ea80ff123d6ba15c1a", "text": "So projects can be done in  groups of up to three people. \n", "start_char_idx": 21618, "end_char_idx": 21677, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96f06b1f-cff6-4862-befb-cd100a32f5a6": {"__data__": {"id_": "96f06b1f-cff6-4862-befb-cd100a32f5a6", "embedding": null, "metadata": {"window": "Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion. ", "original_text": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8ab6cc4-216e-4ab6-a84b-e5e78533ad97", "node_type": "1", "metadata": {"window": "Yeah, question?  \n Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay. ", "original_text": "So projects can be done in  groups of up to three people. \n"}, "hash": "34475234759f60492d75a3c21232132dce2ab375875985ea80ff123d6ba15c1a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b2962b0b-ff6f-43ed-a321-8287babaf40c", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB? ", "original_text": "And just start brainstorming ideas for now amongst \nyourselves. "}, "hash": "42d221281d172c8bf2c7b4229bf8c554cebfbffa449a024ec2f1a36d8fe274bc", "class_name": "RelatedNodeInfo"}}, "hash": "96735df2449852c511edab5ed0302df111185cecdf0c057182e87ca50fb4d464", "text": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? ", "start_char_idx": 21677, "end_char_idx": 21885, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b2962b0b-ff6f-43ed-a321-8287babaf40c": {"__data__": {"id_": "b2962b0b-ff6f-43ed-a321-8287babaf40c", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB? ", "original_text": "And just start brainstorming ideas for now amongst \nyourselves. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "96f06b1f-cff6-4862-befb-cd100a32f5a6", "node_type": "1", "metadata": {"window": "Student : Are these gro up projects?  \n Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion. ", "original_text": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay? "}, "hash": "96735df2449852c511edab5ed0302df111185cecdf0c057182e87ca50fb4d464", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "97fa3c9c-f905-4039-bd16-bd3068d3c6ab", "node_type": "1", "metadata": {"window": "Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot. ", "original_text": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n"}, "hash": "3381d2b28c815f2b77dafbea91181a42771c28de2876e125ffb263d6055e9870", "class_name": "RelatedNodeInfo"}}, "hash": "42d221281d172c8bf2c7b4229bf8c554cebfbffa449a024ec2f1a36d8fe274bc", "text": "And just start brainstorming ideas for now amongst \nyourselves. ", "start_char_idx": 21885, "end_char_idx": 21949, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97fa3c9c-f905-4039-bd16-bd3068d3c6ab": {"__data__": {"id_": "97fa3c9c-f905-4039-bd16-bd3068d3c6ab", "embedding": null, "metadata": {"window": "Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot. ", "original_text": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b2962b0b-ff6f-43ed-a321-8287babaf40c", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): Oh, yes, thank you.  \n Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB? ", "original_text": "And just start brainstorming ideas for now amongst \nyourselves. "}, "hash": "42d221281d172c8bf2c7b4229bf8c554cebfbffa449a024ec2f1a36d8fe274bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5e94c4f-fd73-4863-8977-1bf4fe6f4eae", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "3381d2b28c815f2b77dafbea91181a42771c28de2876e125ffb263d6055e9870", "text": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n", "start_char_idx": 21949, "end_char_idx": 22037, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5e94c4f-fd73-4863-8977-1bf4fe6f4eae": {"__data__": {"id_": "b5e94c4f-fd73-4863-8977-1bf4fe6f4eae", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay. ", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "97fa3c9c-f905-4039-bd16-bd3068d3c6ab", "node_type": "1", "metadata": {"window": "Student : So how many people can be in a group?  \n Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot. ", "original_text": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n"}, "hash": "3381d2b28c815f2b77dafbea91181a42771c28de2876e125ffb263d6055e9870", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "613b5561-62fb-41a7-96bc-502ff81d1468", "node_type": "1", "metadata": {"window": "So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? ", "original_text": "So one more organizational ques tion. "}, "hash": "b883747af9c937e6c2a3d658de1370ff5f4d3b43c6c5cf9bda2617ae47be095d", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "613b5561-62fb-41a7-96bc-502ff81d1468": {"__data__": {"id_": "613b5561-62fb-41a7-96bc-502ff81d1468", "embedding": null, "metadata": {"window": "So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? ", "original_text": "So one more organizational ques tion. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5e94c4f-fd73-4863-8977-1bf4fe6f4eae", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): Right.  So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71b1670f-aa9a-421f-978c-3c43fa532100", "node_type": "1", "metadata": {"window": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n", "original_text": "I'm curious, how many of you know \nMATLAB? "}, "hash": "059923215a1d23cab80e4b645183b507630209ca7339046ec2f8fbb4d8985147", "class_name": "RelatedNodeInfo"}}, "hash": "b883747af9c937e6c2a3d658de1370ff5f4d3b43c6c5cf9bda2617ae47be095d", "text": "So one more organizational ques tion. ", "start_char_idx": 22043, "end_char_idx": 22081, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "71b1670f-aa9a-421f-978c-3c43fa532100": {"__data__": {"id_": "71b1670f-aa9a-421f-978c-3c43fa532100", "embedding": null, "metadata": {"window": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n", "original_text": "I'm curious, how many of you know \nMATLAB? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "613b5561-62fb-41a7-96bc-502ff81d1468", "node_type": "1", "metadata": {"window": "So projects can be done in  groups of up to three people. \n So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? ", "original_text": "So one more organizational ques tion. "}, "hash": "b883747af9c937e6c2a3d658de1370ff5f4d3b43c6c5cf9bda2617ae47be095d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "43307305-5e91-4c91-9af0-9df87e1a9fdd", "node_type": "1", "metadata": {"window": "And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. ", "original_text": "Wow, cool, quite a lot. "}, "hash": "904740b4f74faf3c90eb6e4ad80ff2fa7c27f5fa3b137cfee149b2976fcc50f5", "class_name": "RelatedNodeInfo"}}, "hash": "059923215a1d23cab80e4b645183b507630209ca7339046ec2f8fbb4d8985147", "text": "I'm curious, how many of you know \nMATLAB? ", "start_char_idx": 22081, "end_char_idx": 22124, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "43307305-5e91-4c91-9af0-9df87e1a9fdd": {"__data__": {"id_": "43307305-5e91-4c91-9af0-9df87e1a9fdd", "embedding": null, "metadata": {"window": "And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. ", "original_text": "Wow, cool, quite a lot. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71b1670f-aa9a-421f-978c-3c43fa532100", "node_type": "1", "metadata": {"window": "So as part of forming study groups, later t oday as you get to know your classmates, I \ndefinitely also encourage you to grab two ot her people and form a group of up to three \npeople for your project, okay?  And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n", "original_text": "I'm curious, how many of you know \nMATLAB? "}, "hash": "059923215a1d23cab80e4b645183b507630209ca7339046ec2f8fbb4d8985147", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "63b16e47-29ae-4093-8259-179f73b7c312", "node_type": "1", "metadata": {"window": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "904740b4f74faf3c90eb6e4ad80ff2fa7c27f5fa3b137cfee149b2976fcc50f5", "text": "Wow, cool, quite a lot. ", "start_char_idx": 22124, "end_char_idx": 22148, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63b16e47-29ae-4093-8259-179f73b7c312": {"__data__": {"id_": "63b16e47-29ae-4093-8259-179f73b7c312", "embedding": null, "metadata": {"window": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "43307305-5e91-4c91-9af0-9df87e1a9fdd", "node_type": "1", "metadata": {"window": "And just start brainstorming ideas for now amongst \nyourselves.  You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. ", "original_text": "Wow, cool, quite a lot. "}, "hash": "904740b4f74faf3c90eb6e4ad80ff2fa7c27f5fa3b137cfee149b2976fcc50f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cebdbc01-d8da-481d-b17d-aee7e42b4d9b", "node_type": "1", "metadata": {"window": "Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. ", "original_text": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? "}, "hash": "248f956f28d8406b9d76c5fe740dbc7868300d91e2eb6a274d6c1afda08332e5", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cebdbc01-d8da-481d-b17d-aee7e42b4d9b": {"__data__": {"id_": "cebdbc01-d8da-481d-b17d-aee7e42b4d9b", "embedding": null, "metadata": {"window": "Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. ", "original_text": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "63b16e47-29ae-4093-8259-179f73b7c312", "node_type": "1", "metadata": {"window": "You can also come and talk to me or the TAs if you want to brainstorm ideas \nwith us.  \n Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c2895b8-7e55-42d2-97c3-699682340e52", "node_type": "1", "metadata": {"window": "So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n", "original_text": "Oh, okay, much smaller number.  \n"}, "hash": "44f6d27801e8bec02188184a2284946c3b31f1883ec3ca26b5a72799541cc7c2", "class_name": "RelatedNodeInfo"}}, "hash": "248f956f28d8406b9d76c5fe740dbc7868300d91e2eb6a274d6c1afda08332e5", "text": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? ", "start_char_idx": 22154, "end_char_idx": 22235, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c2895b8-7e55-42d2-97c3-699682340e52": {"__data__": {"id_": "2c2895b8-7e55-42d2-97c3-699682340e52", "embedding": null, "metadata": {"window": "So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n", "original_text": "Oh, okay, much smaller number.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cebdbc01-d8da-481d-b17d-aee7e42b4d9b", "node_type": "1", "metadata": {"window": "Okay.  So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. ", "original_text": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ? "}, "hash": "248f956f28d8406b9d76c5fe740dbc7868300d91e2eb6a274d6c1afda08332e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4cb5359e-f761-4f67-a993-e880a9f9d331", "node_type": "1", "metadata": {"window": "I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. ", "original_text": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. "}, "hash": "f9a084d3801d7e635e7c01357918602ef59b8bea14d307e635d7f31a0a2bbc75", "class_name": "RelatedNodeInfo"}}, "hash": "44f6d27801e8bec02188184a2284946c3b31f1883ec3ca26b5a72799541cc7c2", "text": "Oh, okay, much smaller number.  \n", "start_char_idx": 22235, "end_char_idx": 22268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4cb5359e-f761-4f67-a993-e880a9f9d331": {"__data__": {"id_": "4cb5359e-f761-4f67-a993-e880a9f9d331", "embedding": null, "metadata": {"window": "I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. ", "original_text": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c2895b8-7e55-42d2-97c3-699682340e52", "node_type": "1", "metadata": {"window": "So one more organizational ques tion.  I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n", "original_text": "Oh, okay, much smaller number.  \n"}, "hash": "44f6d27801e8bec02188184a2284946c3b31f1883ec3ca26b5a72799541cc7c2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7a5d215-beb8-43ea-adfa-d972d70c6698", "node_type": "1", "metadata": {"window": "Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n", "original_text": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n"}, "hash": "f561c5a9e4b2e206fdae9bfff49ef15590a969fdf55972ff0fe7e011f4239619", "class_name": "RelatedNodeInfo"}}, "hash": "f9a084d3801d7e635e7c01357918602ef59b8bea14d307e635d7f31a0a2bbc75", "text": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. ", "start_char_idx": 22268, "end_char_idx": 22428, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7a5d215-beb8-43ea-adfa-d972d70c6698": {"__data__": {"id_": "b7a5d215-beb8-43ea-adfa-d972d70c6698", "embedding": null, "metadata": {"window": "Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n", "original_text": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cb5359e-f761-4f67-a993-e880a9f9d331", "node_type": "1", "metadata": {"window": "I'm curious, how many of you know \nMATLAB?  Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. ", "original_text": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks. "}, "hash": "f9a084d3801d7e635e7c01357918602ef59b8bea14d307e635d7f31a0a2bbc75", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba7b1151-d6f3-45d1-9864-79967049b725", "node_type": "1", "metadata": {"window": "Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. ", "original_text": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. "}, "hash": "b6d63ce131383956b53a9afdc853a87728b0aae4bc2615f595f345fbf1792b1c", "class_name": "RelatedNodeInfo"}}, "hash": "f561c5a9e4b2e206fdae9bfff49ef15590a969fdf55972ff0fe7e011f4239619", "text": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n", "start_char_idx": 22428, "end_char_idx": 22616, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba7b1151-d6f3-45d1-9864-79967049b725": {"__data__": {"id_": "ba7b1151-d6f3-45d1-9864-79967049b725", "embedding": null, "metadata": {"window": "Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. ", "original_text": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7a5d215-beb8-43ea-adfa-d972d70c6698", "node_type": "1", "metadata": {"window": "Wow, cool, quite a lot.  Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n", "original_text": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n"}, "hash": "f561c5a9e4b2e206fdae9bfff49ef15590a969fdf55972ff0fe7e011f4239619", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e678b697-79c9-4918-a2bf-1bc308aa74c6", "node_type": "1", "metadata": {"window": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n", "original_text": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n"}, "hash": "5db6b2e2bd44f3dc130833d17b79c475308d3b2c6a431c3891a0e3aa9e91a214", "class_name": "RelatedNodeInfo"}}, "hash": "b6d63ce131383956b53a9afdc853a87728b0aae4bc2615f595f345fbf1792b1c", "text": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. ", "start_char_idx": 22616, "end_char_idx": 22888, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e678b697-79c9-4918-a2bf-1bc308aa74c6": {"__data__": {"id_": "e678b697-79c9-4918-a2bf-1bc308aa74c6", "embedding": null, "metadata": {"window": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n", "original_text": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba7b1151-d6f3-45d1-9864-79967049b725", "node_type": "1", "metadata": {"window": "Okay.  So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. ", "original_text": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data. "}, "hash": "b6d63ce131383956b53a9afdc853a87728b0aae4bc2615f595f345fbf1792b1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67fbcdf1-9470-4fff-83d4-bd83801a4c7e", "node_type": "1", "metadata": {"window": "Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. ", "original_text": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. "}, "hash": "5da26343627e167a0457dfb1dee1715172a31805f2e49adaf6ca9f5bdad5abf0", "class_name": "RelatedNodeInfo"}}, "hash": "5db6b2e2bd44f3dc130833d17b79c475308d3b2c6a431c3891a0e3aa9e91a214", "text": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n", "start_char_idx": 22888, "end_char_idx": 22995, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67fbcdf1-9470-4fff-83d4-bd83801a4c7e": {"__data__": {"id_": "67fbcdf1-9470-4fff-83d4-bd83801a4c7e", "embedding": null, "metadata": {"window": "Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. ", "original_text": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e678b697-79c9-4918-a2bf-1bc308aa74c6", "node_type": "1", "metadata": {"window": "So as part of the \u2014 act ually how many of you \nknow Octave or have used Octave ?  Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n", "original_text": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n"}, "hash": "5db6b2e2bd44f3dc130833d17b79c475308d3b2c6a431c3891a0e3aa9e91a214", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "21b579f3-bbec-4d6e-a56c-de1e735d3964", "node_type": "1", "metadata": {"window": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it. ", "original_text": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n"}, "hash": "b3d4a56b32c57a42ba07f13837ff7a7dd8f7909fc2e45d90b179d985c05c5998", "class_name": "RelatedNodeInfo"}}, "hash": "5da26343627e167a0457dfb1dee1715172a31805f2e49adaf6ca9f5bdad5abf0", "text": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. ", "start_char_idx": 22995, "end_char_idx": 23304, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "21b579f3-bbec-4d6e-a56c-de1e735d3964": {"__data__": {"id_": "21b579f3-bbec-4d6e-a56c-de1e735d3964", "embedding": null, "metadata": {"window": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it. ", "original_text": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67fbcdf1-9470-4fff-83d4-bd83801a4c7e", "node_type": "1", "metadata": {"window": "Oh, okay, much smaller number.  \n So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. ", "original_text": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet. "}, "hash": "5da26343627e167a0457dfb1dee1715172a31805f2e49adaf6ca9f5bdad5abf0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c6ee044-318a-4e1c-8596-a40d8df09394", "node_type": "1", "metadata": {"window": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day. ", "original_text": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. "}, "hash": "94ce4e98817ec39220f912c71980cb7937db01ecfde1c724e07e2a3ff9aa4f48", "class_name": "RelatedNodeInfo"}}, "hash": "b3d4a56b32c57a42ba07f13837ff7a7dd8f7909fc2e45d90b179d985c05c5998", "text": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n", "start_char_idx": 23304, "end_char_idx": 23447, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c6ee044-318a-4e1c-8596-a40d8df09394": {"__data__": {"id_": "9c6ee044-318a-4e1c-8596-a40d8df09394", "embedding": null, "metadata": {"window": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day. ", "original_text": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "21b579f3-bbec-4d6e-a56c-de1e735d3964", "node_type": "1", "metadata": {"window": "So as part of this class, especially in the homeworks, we'll ask you to implement a few \nprograms, a few machine learning algorithms as  part of the homeworks.  And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it. ", "original_text": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n"}, "hash": "b3d4a56b32c57a42ba07f13837ff7a7dd8f7909fc2e45d90b179d985c05c5998", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "04f31385-beeb-49ce-b950-f154c3af6749", "node_type": "1", "metadata": {"window": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n", "original_text": "He's taught it for many years. \n"}, "hash": "3aa3bc91826c72679d58b2f37516208cff42f6493b338d66a541c5f115bb8ee2", "class_name": "RelatedNodeInfo"}}, "hash": "94ce4e98817ec39220f912c71980cb7937db01ecfde1c724e07e2a3ff9aa4f48", "text": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. ", "start_char_idx": 23447, "end_char_idx": 23677, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "04f31385-beeb-49ce-b950-f154c3af6749": {"__data__": {"id_": "04f31385-beeb-49ce-b950-f154c3af6749", "embedding": null, "metadata": {"window": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n", "original_text": "He's taught it for many years. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c6ee044-318a-4e1c-8596-a40d8df09394", "node_type": "1", "metadata": {"window": "And most of \n\nthose homeworks will be done in either MATLA B or in Octave, which is sort of \u2014 I \nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day. ", "original_text": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course. "}, "hash": "94ce4e98817ec39220f912c71980cb7937db01ecfde1c724e07e2a3ff9aa4f48", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cbec7fb8-bbca-4e24-826e-4227f23e6410", "node_type": "1", "metadata": {"window": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited. ", "original_text": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. "}, "hash": "1a7f3532d48a957438fbf9d321b7af3d012a7972d62e424700fa4bcadf3806e5", "class_name": "RelatedNodeInfo"}}, "hash": "3aa3bc91826c72679d58b2f37516208cff42f6493b338d66a541c5f115bb8ee2", "text": "He's taught it for many years. \n", "start_char_idx": 23677, "end_char_idx": 23709, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cbec7fb8-bbca-4e24-826e-4227f23e6410": {"__data__": {"id_": "cbec7fb8-bbca-4e24-826e-4227f23e6410", "embedding": null, "metadata": {"window": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited. ", "original_text": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "04f31385-beeb-49ce-b950-f154c3af6749", "node_type": "1", "metadata": {"window": "So I guess for those of you that haven't s een MATLAB before, and I know most of you \nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \nplot data.  And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n", "original_text": "He's taught it for many years. \n"}, "hash": "3aa3bc91826c72679d58b2f37516208cff42f6493b338d66a541c5f115bb8ee2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27fae339-fe59-43dd-a1bd-1f35d3caeaa1", "node_type": "1", "metadata": {"window": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow. ", "original_text": "I learned so much from it. "}, "hash": "c856df51ebc1110c77e98d0f5325edd858d1bf67ae220eb1e251d2a841a9ef35", "class_name": "RelatedNodeInfo"}}, "hash": "1a7f3532d48a957438fbf9d321b7af3d012a7972d62e424700fa4bcadf3806e5", "text": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. ", "start_char_idx": 23709, "end_char_idx": 23911, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "27fae339-fe59-43dd-a1bd-1f35d3caeaa1": {"__data__": {"id_": "27fae339-fe59-43dd-a1bd-1f35d3caeaa1", "embedding": null, "metadata": {"window": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow. ", "original_text": "I learned so much from it. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbec7fb8-bbca-4e24-826e-4227f23e6410", "node_type": "1", "metadata": {"window": "And it's sort of an extremely easy to  learn tool to use for implementing a lot of \nlearning algorithms.  \n And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited. ", "original_text": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. "}, "hash": "1a7f3532d48a957438fbf9d321b7af3d012a7972d62e424700fa4bcadf3806e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42a19f85-8cb4-48c2-8e5c-f448143db5cd", "node_type": "1", "metadata": {"window": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great. ", "original_text": "There's this stuff that I learned in your \nclass, and I now use every day. "}, "hash": "d750815cb858630c89d5b6c27a64abc6662b5ce8255b65e4e71568f62df3ed99", "class_name": "RelatedNodeInfo"}}, "hash": "c856df51ebc1110c77e98d0f5325edd858d1bf67ae220eb1e251d2a841a9ef35", "text": "I learned so much from it. ", "start_char_idx": 23911, "end_char_idx": 23938, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "42a19f85-8cb4-48c2-8e5c-f448143db5cd": {"__data__": {"id_": "42a19f85-8cb4-48c2-8e5c-f448143db5cd", "embedding": null, "metadata": {"window": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great. ", "original_text": "There's this stuff that I learned in your \nclass, and I now use every day. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "27fae339-fe59-43dd-a1bd-1f35d3caeaa1", "node_type": "1", "metadata": {"window": "And in case some of you want to work on your  own home computer or something if you \ndon't have a MATLAB license, for the purposes of  this class, there's also \u2014 [inaudible] \nwrite that down [inaudible] MATLAB \u2014 there' s also a software package called Octave \nthat you can download for free off the Internet.  And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow. ", "original_text": "I learned so much from it. "}, "hash": "c856df51ebc1110c77e98d0f5325edd858d1bf67ae220eb1e251d2a841a9ef35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dcf46624-2589-4f4f-a2ac-fdded3287b34", "node_type": "1", "metadata": {"window": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful. ", "original_text": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n"}, "hash": "265619cf5f24b64996b48f4789ea88fdb32be24f8b25c33e4c5798baa10ddfe4", "class_name": "RelatedNodeInfo"}}, "hash": "d750815cb858630c89d5b6c27a64abc6662b5ce8255b65e4e71568f62df3ed99", "text": "There's this stuff that I learned in your \nclass, and I now use every day. ", "start_char_idx": 23938, "end_char_idx": 24013, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dcf46624-2589-4f4f-a2ac-fdded3287b34": {"__data__": {"id_": "dcf46624-2589-4f4f-a2ac-fdded3287b34", "embedding": null, "metadata": {"window": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful. ", "original_text": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42a19f85-8cb4-48c2-8e5c-f448143db5cd", "node_type": "1", "metadata": {"window": "And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \neverything.  \n So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great. ", "original_text": "There's this stuff that I learned in your \nclass, and I now use every day. "}, "hash": "d750815cb858630c89d5b6c27a64abc6662b5ce8255b65e4e71568f62df3ed99", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51394643-2cad-41d5-8560-7ffe119b9a01", "node_type": "1", "metadata": {"window": "He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned? ", "original_text": "So my friend was very excited. "}, "hash": "cfea2e8adc061d7af0e584bc6e3fea4274a4cb457aea0dd7402a9c3cf2bc2839", "class_name": "RelatedNodeInfo"}}, "hash": "265619cf5f24b64996b48f4789ea88fdb32be24f8b25c33e4c5798baa10ddfe4", "text": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n", "start_char_idx": 24013, "end_char_idx": 24095, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "51394643-2cad-41d5-8560-7ffe119b9a01": {"__data__": {"id_": "51394643-2cad-41d5-8560-7ffe119b9a01", "embedding": null, "metadata": {"window": "He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned? ", "original_text": "So my friend was very excited. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dcf46624-2589-4f4f-a2ac-fdded3287b34", "node_type": "1", "metadata": {"window": "So actually I, well, so yeah, just a side comment for those of you that haven't seen \nMATLAB before I guess, once a colleague of mine at a different university, not at \nStanford, actually teaches another machine l earning course.  He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful. ", "original_text": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n"}, "hash": "265619cf5f24b64996b48f4789ea88fdb32be24f8b25c33e4c5798baa10ddfe4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c60f60a6-2f47-4b2f-9869-4f78404377b8", "node_type": "1", "metadata": {"window": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression? ", "original_text": "He said, \"W ow. "}, "hash": "7425195511886f19b92452880f70234153263281836177ff1f17a0f2bc98c297", "class_name": "RelatedNodeInfo"}}, "hash": "cfea2e8adc061d7af0e584bc6e3fea4274a4cb457aea0dd7402a9c3cf2bc2839", "text": "So my friend was very excited. ", "start_char_idx": 24095, "end_char_idx": 24126, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c60f60a6-2f47-4b2f-9869-4f78404377b8": {"__data__": {"id_": "c60f60a6-2f47-4b2f-9869-4f78404377b8", "embedding": null, "metadata": {"window": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression? ", "original_text": "He said, \"W ow. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51394643-2cad-41d5-8560-7ffe119b9a01", "node_type": "1", "metadata": {"window": "He's taught it for many years. \n So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned? ", "original_text": "So my friend was very excited. "}, "hash": "cfea2e8adc061d7af0e584bc6e3fea4274a4cb457aea0dd7402a9c3cf2bc2839", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e113a4a4-3c9f-49a9-8a9b-7d9514ce3758", "node_type": "1", "metadata": {"window": "I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA? ", "original_text": "That's great. "}, "hash": "57643ff4578c50f4a04d36a493aa235b518590b3e31070fa5e6a6008118cb02d", "class_name": "RelatedNodeInfo"}}, "hash": "7425195511886f19b92452880f70234153263281836177ff1f17a0f2bc98c297", "text": "He said, \"W ow. ", "start_char_idx": 24126, "end_char_idx": 24142, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e113a4a4-3c9f-49a9-8a9b-7d9514ce3758": {"__data__": {"id_": "e113a4a4-3c9f-49a9-8a9b-7d9514ce3758", "embedding": null, "metadata": {"window": "I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA? ", "original_text": "That's great. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c60f60a6-2f47-4b2f-9869-4f78404377b8", "node_type": "1", "metadata": {"window": "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class.  I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression? ", "original_text": "He said, \"W ow. "}, "hash": "7425195511886f19b92452880f70234153263281836177ff1f17a0f2bc98c297", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "44f6b920-46d0-48b7-8926-fa1e3c5370d4", "node_type": "1", "metadata": {"window": "There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks? ", "original_text": "I'm glad to hear this \nmachine learning stuff was actually useful. "}, "hash": "91f3207227a0d1ff56c56040e3ed7c7afa6ce3b4578b6482fac9768955daf244", "class_name": "RelatedNodeInfo"}}, "hash": "57643ff4578c50f4a04d36a493aa235b518590b3e31070fa5e6a6008118cb02d", "text": "That's great. ", "start_char_idx": 24142, "end_char_idx": 24156, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "44f6b920-46d0-48b7-8926-fa1e3c5370d4": {"__data__": {"id_": "44f6b920-46d0-48b7-8926-fa1e3c5370d4", "embedding": null, "metadata": {"window": "There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks? ", "original_text": "I'm glad to hear this \nmachine learning stuff was actually useful. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e113a4a4-3c9f-49a9-8a9b-7d9514ce3758", "node_type": "1", "metadata": {"window": "I learned so much from it.  There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA? ", "original_text": "That's great. "}, "hash": "57643ff4578c50f4a04d36a493aa235b518590b3e31070fa5e6a6008118cb02d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "35d38511-4694-410a-9bbd-fdb7e92f766b", "node_type": "1", "metadata": {"window": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\" ", "original_text": "So what was it that you learned? "}, "hash": "37a840efc198461a9680f4e1956a90347a015eaf7eda25f7d41d3ed0ad839965", "class_name": "RelatedNodeInfo"}}, "hash": "91f3207227a0d1ff56c56040e3ed7c7afa6ce3b4578b6482fac9768955daf244", "text": "I'm glad to hear this \nmachine learning stuff was actually useful. ", "start_char_idx": 24156, "end_char_idx": 24223, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "35d38511-4694-410a-9bbd-fdb7e92f766b": {"__data__": {"id_": "35d38511-4694-410a-9bbd-fdb7e92f766b", "embedding": null, "metadata": {"window": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\" ", "original_text": "So what was it that you learned? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "44f6b920-46d0-48b7-8926-fa1e3c5370d4", "node_type": "1", "metadata": {"window": "There's this stuff that I learned in your \nclass, and I now use every day.  And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks? ", "original_text": "I'm glad to hear this \nmachine learning stuff was actually useful. "}, "hash": "91f3207227a0d1ff56c56040e3ed7c7afa6ce3b4578b6482fac9768955daf244", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8363622d-49a1-4e80-8e76-901b73846325", "node_type": "1", "metadata": {"window": "So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n", "original_text": "Was it \nlogistic regression? "}, "hash": "4a37f5cb444f9b3685f9c25f538d00ea49c9ba2dcb59149ec666987d2086a726", "class_name": "RelatedNodeInfo"}}, "hash": "37a840efc198461a9680f4e1956a90347a015eaf7eda25f7d41d3ed0ad839965", "text": "So what was it that you learned? ", "start_char_idx": 24223, "end_char_idx": 24256, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8363622d-49a1-4e80-8e76-901b73846325": {"__data__": {"id_": "8363622d-49a1-4e80-8e76-901b73846325", "embedding": null, "metadata": {"window": "So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n", "original_text": "Was it \nlogistic regression? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35d38511-4694-410a-9bbd-fdb7e92f766b", "node_type": "1", "metadata": {"window": "And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \n So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\" ", "original_text": "So what was it that you learned? "}, "hash": "37a840efc198461a9680f4e1956a90347a015eaf7eda25f7d41d3ed0ad839965", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4068a141-349c-49c0-ae7a-4e7c91970b5e", "node_type": "1", "metadata": {"window": "He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it. ", "original_text": "Was it the PCA? "}, "hash": "84a86e297e3e7102d1fa45426d759bd9befdb2f1335873b264b98ce99c39ff6a", "class_name": "RelatedNodeInfo"}}, "hash": "4a37f5cb444f9b3685f9c25f538d00ea49c9ba2dcb59149ec666987d2086a726", "text": "Was it \nlogistic regression? ", "start_char_idx": 24256, "end_char_idx": 24285, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4068a141-349c-49c0-ae7a-4e7c91970b5e": {"__data__": {"id_": "4068a141-349c-49c0-ae7a-4e7c91970b5e", "embedding": null, "metadata": {"window": "He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it. ", "original_text": "Was it the PCA? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8363622d-49a1-4e80-8e76-901b73846325", "node_type": "1", "metadata": {"window": "So my friend was very excited.  He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n", "original_text": "Was it \nlogistic regression? "}, "hash": "4a37f5cb444f9b3685f9c25f538d00ea49c9ba2dcb59149ec666987d2086a726", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9909d7e4-bb59-4f6a-a329-225f699e70cc", "node_type": "1", "metadata": {"window": "That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n", "original_text": "Was it the data ne tworks? "}, "hash": "4920528934840f8a76bf13456f155723b0c991fac69eb0c25d983aed7e25e7ff", "class_name": "RelatedNodeInfo"}}, "hash": "84a86e297e3e7102d1fa45426d759bd9befdb2f1335873b264b98ce99c39ff6a", "text": "Was it the PCA? ", "start_char_idx": 24285, "end_char_idx": 24301, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9909d7e4-bb59-4f6a-a329-225f699e70cc": {"__data__": {"id_": "9909d7e4-bb59-4f6a-a329-225f699e70cc", "embedding": null, "metadata": {"window": "That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n", "original_text": "Was it the data ne tworks? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4068a141-349c-49c0-ae7a-4e7c91970b5e", "node_type": "1", "metadata": {"window": "He said, \"W ow.  That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it. ", "original_text": "Was it the PCA? "}, "hash": "84a86e297e3e7102d1fa45426d759bd9befdb2f1335873b264b98ce99c39ff6a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3bc30b87-869d-4ae6-8916-66e917294fc7", "node_type": "1", "metadata": {"window": "I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay. ", "original_text": "What was it that you \nlearned that was so helpful?\" "}, "hash": "936cfcf1e4879a111656cd3b974513905aff92ee63e7db63051b722ddd78635c", "class_name": "RelatedNodeInfo"}}, "hash": "4920528934840f8a76bf13456f155723b0c991fac69eb0c25d983aed7e25e7ff", "text": "Was it the data ne tworks? ", "start_char_idx": 24301, "end_char_idx": 24328, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3bc30b87-869d-4ae6-8916-66e917294fc7": {"__data__": {"id_": "3bc30b87-869d-4ae6-8916-66e917294fc7", "embedding": null, "metadata": {"window": "I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay. ", "original_text": "What was it that you \nlearned that was so helpful?\" "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9909d7e4-bb59-4f6a-a329-225f699e70cc", "node_type": "1", "metadata": {"window": "That's great.  I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n", "original_text": "Was it the data ne tworks? "}, "hash": "4920528934840f8a76bf13456f155723b0c991fac69eb0c25d983aed7e25e7ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec29f5f1-2c36-4aff-a31f-edf7630f7b51", "node_type": "1", "metadata": {"window": "So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections. ", "original_text": "And the student said, \"Oh, it was the MATLAB.\"  \n"}, "hash": "f252503d7c51b455ae51685f537e9a3efc32d4c655f0432008cdd7172cabfa83", "class_name": "RelatedNodeInfo"}}, "hash": "936cfcf1e4879a111656cd3b974513905aff92ee63e7db63051b722ddd78635c", "text": "What was it that you \nlearned that was so helpful?\" ", "start_char_idx": 24328, "end_char_idx": 24380, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec29f5f1-2c36-4aff-a31f-edf7630f7b51": {"__data__": {"id_": "ec29f5f1-2c36-4aff-a31f-edf7630f7b51", "embedding": null, "metadata": {"window": "So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections. ", "original_text": "And the student said, \"Oh, it was the MATLAB.\"  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3bc30b87-869d-4ae6-8916-66e917294fc7", "node_type": "1", "metadata": {"window": "I'm glad to hear this \nmachine learning stuff was actually useful.  So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay. ", "original_text": "What was it that you \nlearned that was so helpful?\" "}, "hash": "936cfcf1e4879a111656cd3b974513905aff92ee63e7db63051b722ddd78635c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2102f03-d10a-4d44-ae00-fda7dc4edfeb", "node_type": "1", "metadata": {"window": "Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. ", "original_text": "So for those of you that don't know MATLAB yet, I hope you do learn it. "}, "hash": "dafb8522cc2cc518ad0031d849c2acf5cdf66fbd11f260bb1fe4e5566cd3d4e6", "class_name": "RelatedNodeInfo"}}, "hash": "f252503d7c51b455ae51685f537e9a3efc32d4c655f0432008cdd7172cabfa83", "text": "And the student said, \"Oh, it was the MATLAB.\"  \n", "start_char_idx": 24380, "end_char_idx": 24429, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2102f03-d10a-4d44-ae00-fda7dc4edfeb": {"__data__": {"id_": "a2102f03-d10a-4d44-ae00-fda7dc4edfeb", "embedding": null, "metadata": {"window": "Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. ", "original_text": "So for those of you that don't know MATLAB yet, I hope you do learn it. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec29f5f1-2c36-4aff-a31f-edf7630f7b51", "node_type": "1", "metadata": {"window": "So what was it that you learned?  Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections. ", "original_text": "And the student said, \"Oh, it was the MATLAB.\"  \n"}, "hash": "f252503d7c51b455ae51685f537e9a3efc32d4c655f0432008cdd7172cabfa83", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54e5eff1-8ad2-4eda-8be0-7c8ba0e0ad59", "node_type": "1", "metadata": {"window": "Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things. ", "original_text": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n"}, "hash": "cd1147a99bf127a0c6341bac475eb734873db0c69b620f4acaa38aa048aafca0", "class_name": "RelatedNodeInfo"}}, "hash": "dafb8522cc2cc518ad0031d849c2acf5cdf66fbd11f260bb1fe4e5566cd3d4e6", "text": "So for those of you that don't know MATLAB yet, I hope you do learn it. ", "start_char_idx": 24429, "end_char_idx": 24501, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54e5eff1-8ad2-4eda-8be0-7c8ba0e0ad59": {"__data__": {"id_": "54e5eff1-8ad2-4eda-8be0-7c8ba0e0ad59", "embedding": null, "metadata": {"window": "Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things. ", "original_text": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2102f03-d10a-4d44-ae00-fda7dc4edfeb", "node_type": "1", "metadata": {"window": "Was it \nlogistic regression?  Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. ", "original_text": "So for those of you that don't know MATLAB yet, I hope you do learn it. "}, "hash": "dafb8522cc2cc518ad0031d849c2acf5cdf66fbd11f260bb1fe4e5566cd3d4e6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81f7c04a-7200-4495-8658-0be80b3aaaac", "node_type": "1", "metadata": {"window": "Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "cd1147a99bf127a0c6341bac475eb734873db0c69b620f4acaa38aa048aafca0", "text": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n", "start_char_idx": 24501, "end_char_idx": 24640, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81f7c04a-7200-4495-8658-0be80b3aaaac": {"__data__": {"id_": "81f7c04a-7200-4495-8658-0be80b3aaaac", "embedding": null, "metadata": {"window": "Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54e5eff1-8ad2-4eda-8be0-7c8ba0e0ad59", "node_type": "1", "metadata": {"window": "Was it the PCA?  Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things. ", "original_text": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n"}, "hash": "cd1147a99bf127a0c6341bac475eb734873db0c69b620f4acaa38aa048aafca0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af2459ad-e308-4c5a-ad5f-660a9d34682e", "node_type": "1", "metadata": {"window": "What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. ", "original_text": "The very last piece of logistical th ing is the discussion s ections. "}, "hash": "f60d0281c8cb1cc45777afaec0d0b758c7649feb8851f9d2a0a34a3ca0be24af", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "af2459ad-e308-4c5a-ad5f-660a9d34682e": {"__data__": {"id_": "af2459ad-e308-4c5a-ad5f-660a9d34682e", "embedding": null, "metadata": {"window": "What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. ", "original_text": "The very last piece of logistical th ing is the discussion s ections. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81f7c04a-7200-4495-8658-0be80b3aaaac", "node_type": "1", "metadata": {"window": "Was it the data ne tworks?  What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b07d6d19-618e-4c11-9b18-e9a8c9911d63", "node_type": "1", "metadata": {"window": "And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n", "original_text": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. "}, "hash": "112e23fcc3d433f7f0cc2e054c2789472c5ca93a38cf4112ae2605afaa19c52f", "class_name": "RelatedNodeInfo"}}, "hash": "f60d0281c8cb1cc45777afaec0d0b758c7649feb8851f9d2a0a34a3ca0be24af", "text": "The very last piece of logistical th ing is the discussion s ections. ", "start_char_idx": 24646, "end_char_idx": 24716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b07d6d19-618e-4c11-9b18-e9a8c9911d63": {"__data__": {"id_": "b07d6d19-618e-4c11-9b18-e9a8c9911d63", "embedding": null, "metadata": {"window": "And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n", "original_text": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af2459ad-e308-4c5a-ad5f-660a9d34682e", "node_type": "1", "metadata": {"window": "What was it that you \nlearned that was so helpful?\"  And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. ", "original_text": "The very last piece of logistical th ing is the discussion s ections. "}, "hash": "f60d0281c8cb1cc45777afaec0d0b758c7649feb8851f9d2a0a34a3ca0be24af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "92d4c178-cc23-453d-abaa-97385495533f", "node_type": "1", "metadata": {"window": "So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. ", "original_text": "And we'll use the discussion sections \nmainly for two things. "}, "hash": "09cff1dfdecc95b0bdb6d08ecea74a3544d652cb054b5e8ddb02071d13bb2371", "class_name": "RelatedNodeInfo"}}, "hash": "112e23fcc3d433f7f0cc2e054c2789472c5ca93a38cf4112ae2605afaa19c52f", "text": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. ", "start_char_idx": 24716, "end_char_idx": 24870, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "92d4c178-cc23-453d-abaa-97385495533f": {"__data__": {"id_": "92d4c178-cc23-453d-abaa-97385495533f", "embedding": null, "metadata": {"window": "So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. ", "original_text": "And we'll use the discussion sections \nmainly for two things. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b07d6d19-618e-4c11-9b18-e9a8c9911d63", "node_type": "1", "metadata": {"window": "And the student said, \"Oh, it was the MATLAB.\"  \n So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n", "original_text": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. "}, "hash": "112e23fcc3d433f7f0cc2e054c2789472c5ca93a38cf4112ae2605afaa19c52f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e764e927-e752-4a03-b86f-58634e751ff7", "node_type": "1", "metadata": {"window": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n", "original_text": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n"}, "hash": "622fbc8ce36cf8f5b0c365ae18f491a8ceba1136dcc2fe840d23afd02ac0ebf1", "class_name": "RelatedNodeInfo"}}, "hash": "09cff1dfdecc95b0bdb6d08ecea74a3544d652cb054b5e8ddb02071d13bb2371", "text": "And we'll use the discussion sections \nmainly for two things. ", "start_char_idx": 24870, "end_char_idx": 24932, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e764e927-e752-4a03-b86f-58634e751ff7": {"__data__": {"id_": "e764e927-e752-4a03-b86f-58634e751ff7", "embedding": null, "metadata": {"window": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n", "original_text": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "92d4c178-cc23-453d-abaa-97385495533f", "node_type": "1", "metadata": {"window": "So for those of you that don't know MATLAB yet, I hope you do learn it.  It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. ", "original_text": "And we'll use the discussion sections \nmainly for two things. "}, "hash": "09cff1dfdecc95b0bdb6d08ecea74a3544d652cb054b5e8ddb02071d13bb2371", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84dcebc1-2b55-4ce5-80ca-612e9428e47b", "node_type": "1", "metadata": {"window": "Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics. ", "original_text": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. "}, "hash": "209e018c28b9868f139312906a5f553fcda42917b6a77a209bc657b785581674", "class_name": "RelatedNodeInfo"}}, "hash": "622fbc8ce36cf8f5b0c365ae18f491a8ceba1136dcc2fe840d23afd02ac0ebf1", "text": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n", "start_char_idx": 24932, "end_char_idx": 25229, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "84dcebc1-2b55-4ce5-80ca-612e9428e47b": {"__data__": {"id_": "84dcebc1-2b55-4ce5-80ca-612e9428e47b", "embedding": null, "metadata": {"window": "Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics. ", "original_text": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e764e927-e752-4a03-b86f-58634e751ff7", "node_type": "1", "metadata": {"window": "It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \n Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n", "original_text": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n"}, "hash": "622fbc8ce36cf8f5b0c365ae18f491a8ceba1136dcc2fe840d23afd02ac0ebf1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0bba52b5-54a7-4839-abdc-8d3a2f600998", "node_type": "1", "metadata": {"window": "The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. ", "original_text": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n"}, "hash": "56d9199bbf8dfa6ed9e9f8803dbba04eaaec125aae5ec149a4cf9a0cb792965a", "class_name": "RelatedNodeInfo"}}, "hash": "209e018c28b9868f139312906a5f553fcda42917b6a77a209bc657b785581674", "text": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. ", "start_char_idx": 25229, "end_char_idx": 25373, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0bba52b5-54a7-4839-abdc-8d3a2f600998": {"__data__": {"id_": "0bba52b5-54a7-4839-abdc-8d3a2f600998", "embedding": null, "metadata": {"window": "The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. ", "original_text": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84dcebc1-2b55-4ce5-80ca-612e9428e47b", "node_type": "1", "metadata": {"window": "Okay.  The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics. ", "original_text": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es. "}, "hash": "209e018c28b9868f139312906a5f553fcda42917b6a77a209bc657b785581674", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8c5f989-1f9d-47cc-9dc3-a8f3f8c4dcd6", "node_type": "1", "metadata": {"window": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n", "original_text": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. "}, "hash": "c8340150f074ca6d3101f902b7f6e6a7cf6edd3aff08fe1f2dbef6aaa9384c15", "class_name": "RelatedNodeInfo"}}, "hash": "56d9199bbf8dfa6ed9e9f8803dbba04eaaec125aae5ec149a4cf9a0cb792965a", "text": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n", "start_char_idx": 25373, "end_char_idx": 25523, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8c5f989-1f9d-47cc-9dc3-a8f3f8c4dcd6": {"__data__": {"id_": "a8c5f989-1f9d-47cc-9dc3-a8f3f8c4dcd6", "embedding": null, "metadata": {"window": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n", "original_text": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0bba52b5-54a7-4839-abdc-8d3a2f600998", "node_type": "1", "metadata": {"window": "The very last piece of logistical th ing is the discussion s ections.  So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. ", "original_text": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n"}, "hash": "56d9199bbf8dfa6ed9e9f8803dbba04eaaec125aae5ec149a4cf9a0cb792965a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca62825f-4161-4bb9-a40e-e21735d0965b", "node_type": "1", "metadata": {"window": "And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n", "original_text": "And attend ance at the discussion \nsections is optional, okay?  \n"}, "hash": "6caf08d1ea9959d9d1b9f7f870e7fd53d532bd90de02e7aab1b7464a85363fa7", "class_name": "RelatedNodeInfo"}}, "hash": "c8340150f074ca6d3101f902b7f6e6a7cf6edd3aff08fe1f2dbef6aaa9384c15", "text": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. ", "start_char_idx": 25523, "end_char_idx": 25852, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca62825f-4161-4bb9-a40e-e21735d0965b": {"__data__": {"id_": "ca62825f-4161-4bb9-a40e-e21735d0965b", "embedding": null, "metadata": {"window": "And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n", "original_text": "And attend ance at the discussion \nsections is optional, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8c5f989-1f9d-47cc-9dc3-a8f3f8c4dcd6", "node_type": "1", "metadata": {"window": "So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed.  And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n", "original_text": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures. "}, "hash": "c8340150f074ca6d3101f902b7f6e6a7cf6edd3aff08fe1f2dbef6aaa9384c15", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "25874d31-a647-4518-b7d7-dfa7835bb3c8", "node_type": "1", "metadata": {"window": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right. ", "original_text": "So that was all I had from l ogistics. "}, "hash": "11b95ad1ef65cbc5608e249eb4f13b97c11e3a6bd32abb17689b73dcbd849833", "class_name": "RelatedNodeInfo"}}, "hash": "6caf08d1ea9959d9d1b9f7f870e7fd53d532bd90de02e7aab1b7464a85363fa7", "text": "And attend ance at the discussion \nsections is optional, okay?  \n", "start_char_idx": 25852, "end_char_idx": 25917, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "25874d31-a647-4518-b7d7-dfa7835bb3c8": {"__data__": {"id_": "25874d31-a647-4518-b7d7-dfa7835bb3c8", "embedding": null, "metadata": {"window": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right. ", "original_text": "So that was all I had from l ogistics. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca62825f-4161-4bb9-a40e-e21735d0965b", "node_type": "1", "metadata": {"window": "And we'll use the discussion sections \nmainly for two things.  For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n", "original_text": "And attend ance at the discussion \nsections is optional, okay?  \n"}, "hash": "6caf08d1ea9959d9d1b9f7f870e7fd53d532bd90de02e7aab1b7464a85363fa7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee221613-118c-449c-8e60-693cf911487b", "node_type": "1", "metadata": {"window": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. ", "original_text": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. "}, "hash": "d3a16bdc0f5ccf2f01f5fc3f8b9ddc21e3b032c1b8ce5342e62439841cd4359c", "class_name": "RelatedNodeInfo"}}, "hash": "11b95ad1ef65cbc5608e249eb4f13b97c11e3a6bd32abb17689b73dcbd849833", "text": "So that was all I had from l ogistics. ", "start_char_idx": 25917, "end_char_idx": 25956, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee221613-118c-449c-8e60-693cf911487b": {"__data__": {"id_": "ee221613-118c-449c-8e60-693cf911487b", "embedding": null, "metadata": {"window": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. ", "original_text": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25874d31-a647-4518-b7d7-dfa7835bb3c8", "node_type": "1", "metadata": {"window": "For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.  \n Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right. ", "original_text": "So that was all I had from l ogistics. "}, "hash": "11b95ad1ef65cbc5608e249eb4f13b97c11e3a6bd32abb17689b73dcbd849833", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08ab1390-5664-4c72-bb4e-eff0190b29d8", "node_type": "1", "metadata": {"window": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. ", "original_text": "Yeah?  \n"}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "class_name": "RelatedNodeInfo"}}, "hash": "d3a16bdc0f5ccf2f01f5fc3f8b9ddc21e3b032c1b8ce5342e62439841cd4359c", "text": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. ", "start_char_idx": 25956, "end_char_idx": 26060, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08ab1390-5664-4c72-bb4e-eff0190b29d8": {"__data__": {"id_": "08ab1390-5664-4c72-bb4e-eff0190b29d8", "embedding": null, "metadata": {"window": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. ", "original_text": "Yeah?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee221613-118c-449c-8e60-693cf911487b", "node_type": "1", "metadata": {"window": "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \nmaterial that I'm teaching in the main lectur es.  So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. ", "original_text": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have. "}, "hash": "d3a16bdc0f5ccf2f01f5fc3f8b9ddc21e3b032c1b8ce5342e62439841cd4359c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67336796-0460-4d8d-80b8-ba0a3b52fd60", "node_type": "1", "metadata": {"window": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning. ", "original_text": "Student : [Inaudible] R or something like that?  \n"}, "hash": "47560d612eb3626e9f7040ffd2f1ecbfd9eb6f6d85fcbc05082f4a23d36c57dd", "class_name": "RelatedNodeInfo"}}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "text": "Yeah?  \n", "start_char_idx": 26060, "end_char_idx": 26068, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67336796-0460-4d8d-80b8-ba0a3b52fd60": {"__data__": {"id_": "67336796-0460-4d8d-80b8-ba0a3b52fd60", "embedding": null, "metadata": {"window": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning. ", "original_text": "Student : [Inaudible] R or something like that?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "08ab1390-5664-4c72-bb4e-eff0190b29d8", "node_type": "1", "metadata": {"window": "So machine learning is a huge field, and \nthere are a few extensions that we really want  to teach but didn't have time in the main \nlectures for.  \n\n So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. ", "original_text": "Yeah?  \n"}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e298afc5-aab8-49e8-ba0d-9ac3ff6472f8", "node_type": "1", "metadata": {"window": "And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. ", "original_text": "Instructor (Andrew Ng) : Oh, yeah, let's see, right. "}, "hash": "6a618855b492c206aacdb4b579de841f0e5be09d2d9b546d091013271f23b602", "class_name": "RelatedNodeInfo"}}, "hash": "47560d612eb3626e9f7040ffd2f1ecbfd9eb6f6d85fcbc05082f4a23d36c57dd", "text": "Student : [Inaudible] R or something like that?  \n", "start_char_idx": 26068, "end_char_idx": 26118, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e298afc5-aab8-49e8-ba0d-9ac3ff6472f8": {"__data__": {"id_": "e298afc5-aab8-49e8-ba0d-9ac3ff6472f8", "embedding": null, "metadata": {"window": "And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. ", "original_text": "Instructor (Andrew Ng) : Oh, yeah, let's see, right. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67336796-0460-4d8d-80b8-ba0a3b52fd60", "node_type": "1", "metadata": {"window": "So later this quarter, we'll use the discussion sections to talk about things like convex \noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \nlearning algorithm for modeling time series and a few other things, so  extensions to the \nmaterials that I'll be covering in the main  lectures.  And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning. ", "original_text": "Student : [Inaudible] R or something like that?  \n"}, "hash": "47560d612eb3626e9f7040ffd2f1ecbfd9eb6f6d85fcbc05082f4a23d36c57dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "252be990-a8e3-4425-a48d-e92f12f7538a", "node_type": "1", "metadata": {"window": "So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n", "original_text": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. "}, "hash": "fd3973677aeb12abf79000e0a1ea36392e2941f8c4e6f6478b2a534edc8e7840", "class_name": "RelatedNodeInfo"}}, "hash": "6a618855b492c206aacdb4b579de841f0e5be09d2d9b546d091013271f23b602", "text": "Instructor (Andrew Ng) : Oh, yeah, let's see, right. ", "start_char_idx": 26118, "end_char_idx": 26171, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "252be990-a8e3-4425-a48d-e92f12f7538a": {"__data__": {"id_": "252be990-a8e3-4425-a48d-e92f12f7538a", "embedding": null, "metadata": {"window": "So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n", "original_text": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e298afc5-aab8-49e8-ba0d-9ac3ff6472f8", "node_type": "1", "metadata": {"window": "And attend ance at the discussion \nsections is optional, okay?  \n So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. ", "original_text": "Instructor (Andrew Ng) : Oh, yeah, let's see, right. "}, "hash": "6a618855b492c206aacdb4b579de841f0e5be09d2d9b546d091013271f23b602", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8218ce64-45e7-48d7-97ac-9463d7059266", "node_type": "1", "metadata": {"window": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n", "original_text": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. "}, "hash": "d6d8f925758160986fe05252ab735b5ec627339d692e95415b24300f0e18208c", "class_name": "RelatedNodeInfo"}}, "hash": "fd3973677aeb12abf79000e0a1ea36392e2941f8c4e6f6478b2a534edc8e7840", "text": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. ", "start_char_idx": 26171, "end_char_idx": 26436, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8218ce64-45e7-48d7-97ac-9463d7059266": {"__data__": {"id_": "8218ce64-45e7-48d7-97ac-9463d7059266", "embedding": null, "metadata": {"window": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n", "original_text": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "252be990-a8e3-4425-a48d-e92f12f7538a", "node_type": "1", "metadata": {"window": "So that was all I had from l ogistics.  Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n", "original_text": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself. "}, "hash": "fd3973677aeb12abf79000e0a1ea36392e2941f8c4e6f6478b2a534edc8e7840", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5401eef0-2bbe-4894-9bca-a6188088b6c1", "node_type": "1", "metadata": {"window": "Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. ", "original_text": "But I think MATLAB is actually totally \nworth learning. "}, "hash": "5b64145f5bdcfd598163f53696f5722a9e78ed4a3758a08b5aa762987c52988d", "class_name": "RelatedNodeInfo"}}, "hash": "d6d8f925758160986fe05252ab735b5ec627339d692e95415b24300f0e18208c", "text": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. ", "start_char_idx": 26436, "end_char_idx": 26519, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5401eef0-2bbe-4894-9bca-a6188088b6c1": {"__data__": {"id_": "5401eef0-2bbe-4894-9bca-a6188088b6c1", "embedding": null, "metadata": {"window": "Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. ", "original_text": "But I think MATLAB is actually totally \nworth learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8218ce64-45e7-48d7-97ac-9463d7059266", "node_type": "1", "metadata": {"window": "Before we move on to start talking a bit about \nmachine learning, let me check what questions you have.  Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n", "original_text": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne. "}, "hash": "d6d8f925758160986fe05252ab735b5ec627339d692e95415b24300f0e18208c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "054971db-481f-42fd-876b-c393c2c7b897", "node_type": "1", "metadata": {"window": "Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n", "original_text": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. "}, "hash": "9d9dcbf03121fb904c1ef7e766da2e2fec0087316a409b56015d926cbee83416", "class_name": "RelatedNodeInfo"}}, "hash": "5b64145f5bdcfd598163f53696f5722a9e78ed4a3758a08b5aa762987c52988d", "text": "But I think MATLAB is actually totally \nworth learning. ", "start_char_idx": 26519, "end_char_idx": 26575, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "054971db-481f-42fd-876b-c393c2c7b897": {"__data__": {"id_": "054971db-481f-42fd-876b-c393c2c7b897", "embedding": null, "metadata": {"window": "Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n", "original_text": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5401eef0-2bbe-4894-9bca-a6188088b6c1", "node_type": "1", "metadata": {"window": "Yeah?  \n Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. ", "original_text": "But I think MATLAB is actually totally \nworth learning. "}, "hash": "5b64145f5bdcfd598163f53696f5722a9e78ed4a3758a08b5aa762987c52988d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "67e62451-bac5-423c-a8ad-c5aef43f199e", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n", "original_text": "Yeah?  \n"}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "class_name": "RelatedNodeInfo"}}, "hash": "9d9dcbf03121fb904c1ef7e766da2e2fec0087316a409b56015d926cbee83416", "text": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. ", "start_char_idx": 26575, "end_char_idx": 26678, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67e62451-bac5-423c-a8ad-c5aef43f199e": {"__data__": {"id_": "67e62451-bac5-423c-a8ad-c5aef43f199e", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n", "original_text": "Yeah?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "054971db-481f-42fd-876b-c393c2c7b897", "node_type": "1", "metadata": {"window": "Student : [Inaudible] R or something like that?  \n Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n", "original_text": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons. "}, "hash": "9d9dcbf03121fb904c1ef7e766da2e2fec0087316a409b56015d926cbee83416", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0ef445c-da19-41ac-ada4-0a7805d1f960", "node_type": "1", "metadata": {"window": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see. ", "original_text": "Student : For the [inaudible] pr oject [inaudible]?  \n"}, "hash": "948a5a2b86355d72963c05a1136c024f5cc2197a3bb2794ee5e1d75e5369a2c5", "class_name": "RelatedNodeInfo"}}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "text": "Yeah?  \n", "start_char_idx": 26060, "end_char_idx": 26068, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d0ef445c-da19-41ac-ada4-0a7805d1f960": {"__data__": {"id_": "d0ef445c-da19-41ac-ada4-0a7805d1f960", "embedding": null, "metadata": {"window": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see. ", "original_text": "Student : For the [inaudible] pr oject [inaudible]?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67e62451-bac5-423c-a8ad-c5aef43f199e", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Oh, yeah, let's see, right.  So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n", "original_text": "Yeah?  \n"}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6c87b7a3-ffb8-4e1f-9e6d-b620c2a40632", "node_type": "1", "metadata": {"window": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project. ", "original_text": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. "}, "hash": "e2e049121a994e2583642bd869ad3e31374cc55786e7077740b63f94027ea587", "class_name": "RelatedNodeInfo"}}, "hash": "948a5a2b86355d72963c05a1136c024f5cc2197a3bb2794ee5e1d75e5369a2c5", "text": "Student : For the [inaudible] pr oject [inaudible]?  \n", "start_char_idx": 26686, "end_char_idx": 26740, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c87b7a3-ffb8-4e1f-9e6d-b620c2a40632": {"__data__": {"id_": "6c87b7a3-ffb8-4e1f-9e6d-b620c2a40632", "embedding": null, "metadata": {"window": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project. ", "original_text": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d0ef445c-da19-41ac-ada4-0a7805d1f960", "node_type": "1", "metadata": {"window": "So our policy has been that you're \nwelcome to use R, but I would strongly advi se against it, mainly because in the last \nproblem set, we actually supply some code th at will run in Octave  but that would be \nsomewhat painful for you to translate into R yourself.  So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see. ", "original_text": "Student : For the [inaudible] pr oject [inaudible]?  \n"}, "hash": "948a5a2b86355d72963c05a1136c024f5cc2197a3bb2794ee5e1d75e5369a2c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c77ecf5-c14e-4884-8812-cd2155b39201", "node_type": "1", "metadata": {"window": "But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see. ", "original_text": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n"}, "hash": "9f5d107744512434adcdce4aa19520f3cd5aecb805e298686484f32cb3614a53", "class_name": "RelatedNodeInfo"}}, "hash": "e2e049121a994e2583642bd869ad3e31374cc55786e7077740b63f94027ea587", "text": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. ", "start_char_idx": 26740, "end_char_idx": 26904, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c77ecf5-c14e-4884-8812-cd2155b39201": {"__data__": {"id_": "8c77ecf5-c14e-4884-8812-cd2155b39201", "embedding": null, "metadata": {"window": "But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see. ", "original_text": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6c87b7a3-ffb8-4e1f-9e6d-b620c2a40632", "node_type": "1", "metadata": {"window": "So for your other assignments, if \nyou wanna submit a solution in R, that's fi ne.  But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project. ", "original_text": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two. "}, "hash": "e2e049121a994e2583642bd869ad3e31374cc55786e7077740b63f94027ea587", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42de9c82-463c-4ebf-bbcc-41580abfeef2", "node_type": "1", "metadata": {"window": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. ", "original_text": "Student : [Inaudible] what language [inaudible]?  \n"}, "hash": "15440b00c7dc791f4f724c02d7a7e4e3fdca335d7edc875c3aa38bc268721882", "class_name": "RelatedNodeInfo"}}, "hash": "9f5d107744512434adcdce4aa19520f3cd5aecb805e298686484f32cb3614a53", "text": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n", "start_char_idx": 26904, "end_char_idx": 27106, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "42de9c82-463c-4ebf-bbcc-41580abfeef2": {"__data__": {"id_": "42de9c82-463c-4ebf-bbcc-41580abfeef2", "embedding": null, "metadata": {"window": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. ", "original_text": "Student : [Inaudible] what language [inaudible]?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c77ecf5-c14e-4884-8812-cd2155b39201", "node_type": "1", "metadata": {"window": "But I think MATLAB is actually totally \nworth learning.  I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see. ", "original_text": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n"}, "hash": "9f5d107744512434adcdce4aa19520f3cd5aecb805e298686484f32cb3614a53", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "373dba26-600a-4ed4-875f-8bf326292e21", "node_type": "1", "metadata": {"window": "Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n", "original_text": "Instructor (Andrew Ng): So let's see. "}, "hash": "7cb552d952e611550ebbbda05e049eaada1ba627a910891f1bbd74476c40d3d0", "class_name": "RelatedNodeInfo"}}, "hash": "15440b00c7dc791f4f724c02d7a7e4e3fdca335d7edc875c3aa38bc268721882", "text": "Student : [Inaudible] what language [inaudible]?  \n", "start_char_idx": 27106, "end_char_idx": 27157, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "373dba26-600a-4ed4-875f-8bf326292e21": {"__data__": {"id_": "373dba26-600a-4ed4-875f-8bf326292e21", "embedding": null, "metadata": {"window": "Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n", "original_text": "Instructor (Andrew Ng): So let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42de9c82-463c-4ebf-bbcc-41580abfeef2", "node_type": "1", "metadata": {"window": "I know R and MATLAB, and I personally end up using MATLAB quite a \nbit more often for various reasons.  Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. ", "original_text": "Student : [Inaudible] what language [inaudible]?  \n"}, "hash": "15440b00c7dc791f4f724c02d7a7e4e3fdca335d7edc875c3aa38bc268721882", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "adc72803-b12f-4b0b-aed0-4394228f8951", "node_type": "1", "metadata": {"window": "Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? ", "original_text": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project. "}, "hash": "ab24ad0fc75f36e826730ae378f67b5b7cfbb64413b540c7457263bf079b1dab", "class_name": "RelatedNodeInfo"}}, "hash": "7cb552d952e611550ebbbda05e049eaada1ba627a910891f1bbd74476c40d3d0", "text": "Instructor (Andrew Ng): So let's see. ", "start_char_idx": 27157, "end_char_idx": 27195, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "adc72803-b12f-4b0b-aed0-4394228f8951": {"__data__": {"id_": "adc72803-b12f-4b0b-aed0-4394228f8951", "embedding": null, "metadata": {"window": "Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? ", "original_text": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "373dba26-600a-4ed4-875f-8bf326292e21", "node_type": "1", "metadata": {"window": "Yeah?  \n Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n", "original_text": "Instructor (Andrew Ng): So let's see. "}, "hash": "7cb552d952e611550ebbbda05e049eaada1ba627a910891f1bbd74476c40d3d0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "50405a5d-6cc9-426f-a102-3ed604fff919", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n", "original_text": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see. "}, "hash": "a7bb13e8a4b775b799e52b29aa10fbe74ac9424623d016bf837af51cd29db082", "class_name": "RelatedNodeInfo"}}, "hash": "ab24ad0fc75f36e826730ae378f67b5b7cfbb64413b540c7457263bf079b1dab", "text": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project. ", "start_char_idx": 27195, "end_char_idx": 27303, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "50405a5d-6cc9-426f-a102-3ed604fff919": {"__data__": {"id_": "50405a5d-6cc9-426f-a102-3ed604fff919", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n", "original_text": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "adc72803-b12f-4b0b-aed0-4394228f8951", "node_type": "1", "metadata": {"window": "Student : For the [inaudible] pr oject [inaudible]?  \n Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? ", "original_text": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project. "}, "hash": "ab24ad0fc75f36e826730ae378f67b5b7cfbb64413b540c7457263bf079b1dab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc524ca9-2cad-4760-ba2c-b99fe0406f9f", "node_type": "1", "metadata": {"window": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n", "original_text": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. "}, "hash": "2a4ee7cba5339320f9ee4b608857fa43e74cf3e0fe4e870be6f41339b1136019", "class_name": "RelatedNodeInfo"}}, "hash": "a7bb13e8a4b775b799e52b29aa10fbe74ac9424623d016bf837af51cd29db082", "text": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see. ", "start_char_idx": 27303, "end_char_idx": 27373, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc524ca9-2cad-4760-ba2c-b99fe0406f9f": {"__data__": {"id_": "bc524ca9-2cad-4760-ba2c-b99fe0406f9f", "embedding": null, "metadata": {"window": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n", "original_text": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "50405a5d-6cc9-426f-a102-3ed604fff919", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \ngroups of three, or you're welcome to do it by yo urself or in groups of two.  Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n", "original_text": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see. "}, "hash": "a7bb13e8a4b775b799e52b29aa10fbe74ac9424623d016bf837af51cd29db082", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad439c6f-0873-411a-b4a6-c9bc9c6917e3", "node_type": "1", "metadata": {"window": "Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n", "original_text": "Yeah?  \n"}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "class_name": "RelatedNodeInfo"}}, "hash": "2a4ee7cba5339320f9ee4b608857fa43e74cf3e0fe4e870be6f41339b1136019", "text": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. ", "start_char_idx": 27373, "end_char_idx": 27614, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad439c6f-0873-411a-b4a6-c9bc9c6917e3": {"__data__": {"id_": "ad439c6f-0873-411a-b4a6-c9bc9c6917e3", "embedding": null, "metadata": {"window": "Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n", "original_text": "Yeah?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc524ca9-2cad-4760-ba2c-b99fe0406f9f", "node_type": "1", "metadata": {"window": "Grading is the \nsame regardless of the group size, so with  a larger group, you probably \u2014 I recommend \ntrying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n", "original_text": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically. "}, "hash": "2a4ee7cba5339320f9ee4b608857fa43e74cf3e0fe4e870be6f41339b1136019", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ce58424-61bb-4898-bb9b-7bd506cf4be0", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.  ", "original_text": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? "}, "hash": "6809c43326473b1cf2214f5a47654e9d103dfbfe2ca4371814a40d4e134627f7", "class_name": "RelatedNodeInfo"}}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "text": "Yeah?  \n", "start_char_idx": 26060, "end_char_idx": 26068, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ce58424-61bb-4898-bb9b-7bd506cf4be0": {"__data__": {"id_": "7ce58424-61bb-4898-bb9b-7bd506cf4be0", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.  ", "original_text": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad439c6f-0873-411a-b4a6-c9bc9c6917e3", "node_type": "1", "metadata": {"window": "Student : [Inaudible] what language [inaudible]?  \n Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n", "original_text": "Yeah?  \n"}, "hash": "6ac734491e5aa356ff5e250aff73cd7230d5dcba685a8ae938f83d26d3cf1a84", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0e080014-3ecd-40cf-9cbb-d1960ee5cc31", "node_type": "1", "metadata": {"window": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. ", "original_text": "[Inaudible]?  \n"}, "hash": "73e926040df32d66b6c50bd24b4700924d9d473234f64a181f50d02da15b25b1", "class_name": "RelatedNodeInfo"}}, "hash": "6809c43326473b1cf2214f5a47654e9d103dfbfe2ca4371814a40d4e134627f7", "text": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? ", "start_char_idx": 27622, "end_char_idx": 27723, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0e080014-3ecd-40cf-9cbb-d1960ee5cc31": {"__data__": {"id_": "0e080014-3ecd-40cf-9cbb-d1960ee5cc31", "embedding": null, "metadata": {"window": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. ", "original_text": "[Inaudible]?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ce58424-61bb-4898-bb9b-7bd506cf4be0", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): So let's see.  There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.  ", "original_text": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there? "}, "hash": "6809c43326473b1cf2214f5a47654e9d103dfbfe2ca4371814a40d4e134627f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0eee668e-a6ba-4b39-86b7-3e3d99a50353", "node_type": "1", "metadata": {"window": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n", "original_text": "Instructor (Andrew Ng) : Of the project?  \n"}, "hash": "c57864a154383a0d023ffceac8a47fe84d65584c215824f454a12a0a7045980c", "class_name": "RelatedNodeInfo"}}, "hash": "73e926040df32d66b6c50bd24b4700924d9d473234f64a181f50d02da15b25b1", "text": "[Inaudible]?  \n", "start_char_idx": 27723, "end_char_idx": 27738, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0eee668e-a6ba-4b39-86b7-3e3d99a50353": {"__data__": {"id_": "0eee668e-a6ba-4b39-86b7-3e3d99a50353", "embedding": null, "metadata": {"window": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n", "original_text": "Instructor (Andrew Ng) : Of the project?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0e080014-3ecd-40cf-9cbb-d1960ee5cc31", "node_type": "1", "metadata": {"window": "There is no C programming in this class other \nthan any that you may choose to do yourself in your project.  So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. ", "original_text": "[Inaudible]?  \n"}, "hash": "73e926040df32d66b6c50bd24b4700924d9d473234f64a181f50d02da15b25b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ef4c38a-4dca-49fa-be11-07db6b12bdd1", "node_type": "1", "metadata": {"window": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application. ", "original_text": "Student : Yeah.  \n"}, "hash": "a180f2173055cf08d15b5f94c29fb66b1c74140ab0a5ea967979594dd0d34b20", "class_name": "RelatedNodeInfo"}}, "hash": "c57864a154383a0d023ffceac8a47fe84d65584c215824f454a12a0a7045980c", "text": "Instructor (Andrew Ng) : Of the project?  \n", "start_char_idx": 27738, "end_char_idx": 27781, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ef4c38a-4dca-49fa-be11-07db6b12bdd1": {"__data__": {"id_": "0ef4c38a-4dca-49fa-be11-07db6b12bdd1", "embedding": null, "metadata": {"window": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application. ", "original_text": "Student : Yeah.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0eee668e-a6ba-4b39-86b7-3e3d99a50353", "node_type": "1", "metadata": {"window": "So all the homeworks can be \ndone in MATLAB or Octave, and let's see.  A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n", "original_text": "Instructor (Andrew Ng) : Of the project?  \n"}, "hash": "c57864a154383a0d023ffceac8a47fe84d65584c215824f454a12a0a7045980c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c3734bd2-7746-47b2-a46e-803cfd4a079d", "node_type": "1", "metadata": {"window": "Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project. ", "original_text": "Instructor (Andrew Ng) : Yeah, let me answer that later.  "}, "hash": "a342be0bea5b70a8083692169fa1ec1d7cf6f34c7e621aa9f8a4dcb94ffd25a8", "class_name": "RelatedNodeInfo"}}, "hash": "a180f2173055cf08d15b5f94c29fb66b1c74140ab0a5ea967979594dd0d34b20", "text": "Student : Yeah.  \n", "start_char_idx": 27781, "end_char_idx": 27799, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c3734bd2-7746-47b2-a46e-803cfd4a079d": {"__data__": {"id_": "c3734bd2-7746-47b2-a46e-803cfd4a079d", "embedding": null, "metadata": {"window": "Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project. ", "original_text": "Instructor (Andrew Ng) : Yeah, let me answer that later.  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ef4c38a-4dca-49fa-be11-07db6b12bdd1", "node_type": "1", "metadata": {"window": "A nd I guess the program prerequisites is more \nthe ability to understand big?O notation and know ledge of what a data structure, like a \nlinked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \nspecifically.  Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application. ", "original_text": "Student : Yeah.  \n"}, "hash": "a180f2173055cf08d15b5f94c29fb66b1c74140ab0a5ea967979594dd0d34b20", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a958387-558f-4844-b2db-dab6b4551adc", "node_type": "1", "metadata": {"window": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning. ", "original_text": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. "}, "hash": "1299c16dce13957b5dcf738f489bcece8aa83d649ca77cafe775dac18b0db222", "class_name": "RelatedNodeInfo"}}, "hash": "a342be0bea5b70a8083692169fa1ec1d7cf6f34c7e621aa9f8a4dcb94ffd25a8", "text": "Instructor (Andrew Ng) : Yeah, let me answer that later.  ", "start_char_idx": 27799, "end_char_idx": 27857, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0a958387-558f-4844-b2db-dab6b4551adc": {"__data__": {"id_": "0a958387-558f-4844-b2db-dab6b4551adc", "embedding": null, "metadata": {"window": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning. ", "original_text": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3734bd2-7746-47b2-a46e-803cfd4a079d", "node_type": "1", "metadata": {"window": "Yeah?  \n Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project. ", "original_text": "Instructor (Andrew Ng) : Yeah, let me answer that later.  "}, "hash": "a342be0bea5b70a8083692169fa1ec1d7cf6f34c7e621aa9f8a4dcb94ffd25a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e1227ac8-7ad1-40e3-8f9c-068d250de59e", "node_type": "1", "metadata": {"window": "[Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful. ", "original_text": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n"}, "hash": "d4ee850b32c0f40ea1fa6163aa5517171a7d62a4e4127d9b4b05d1571fa3752d", "class_name": "RelatedNodeInfo"}}, "hash": "1299c16dce13957b5dcf738f489bcece8aa83d649ca77cafe775dac18b0db222", "text": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. ", "start_char_idx": 27857, "end_char_idx": 27941, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1227ac8-7ad1-40e3-8f9c-068d250de59e": {"__data__": {"id_": "e1227ac8-7ad1-40e3-8f9c-068d250de59e", "embedding": null, "metadata": {"window": "[Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful. ", "original_text": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a958387-558f-4844-b2db-dab6b4551adc", "node_type": "1", "metadata": {"window": "Student : Looking at the end semester project, I mean, what exactly will you be testing \nover there?  [Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning. ", "original_text": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject. "}, "hash": "1299c16dce13957b5dcf738f489bcece8aa83d649ca77cafe775dac18b0db222", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f969084-1db0-4ca8-b160-29778c662ad5", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do. ", "original_text": "So many students will try to build a cool machine learning application. "}, "hash": "2433c9871eec33d7525ab49017fcabc8791189500bceb8b205de36b4be6bf62b", "class_name": "RelatedNodeInfo"}}, "hash": "d4ee850b32c0f40ea1fa6163aa5517171a7d62a4e4127d9b4b05d1571fa3752d", "text": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n", "start_char_idx": 27941, "end_char_idx": 28177, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6f969084-1db0-4ca8-b160-29778c662ad5": {"__data__": {"id_": "6f969084-1db0-4ca8-b160-29778c662ad5", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do. ", "original_text": "So many students will try to build a cool machine learning application. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e1227ac8-7ad1-40e3-8f9c-068d250de59e", "node_type": "1", "metadata": {"window": "[Inaudible]?  \n Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful. ", "original_text": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n"}, "hash": "d4ee850b32c0f40ea1fa6163aa5517171a7d62a4e4127d9b4b05d1571fa3752d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b43632ed-ec41-45ec-985a-43a065cb005c", "node_type": "1", "metadata": {"window": "Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. ", "original_text": "That's probably \nthe most common project. "}, "hash": "2c1f4d531ac8f889f66a245c03db9d650eee40b8a27c14b6bcb610c7d2937bb2", "class_name": "RelatedNodeInfo"}}, "hash": "2433c9871eec33d7525ab49017fcabc8791189500bceb8b205de36b4be6bf62b", "text": "So many students will try to build a cool machine learning application. ", "start_char_idx": 28177, "end_char_idx": 28249, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b43632ed-ec41-45ec-985a-43a065cb005c": {"__data__": {"id_": "b43632ed-ec41-45ec-985a-43a065cb005c", "embedding": null, "metadata": {"window": "Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. ", "original_text": "That's probably \nthe most common project. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f969084-1db0-4ca8-b160-29778c662ad5", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Of the project?  \n Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do. ", "original_text": "So many students will try to build a cool machine learning application. "}, "hash": "2433c9871eec33d7525ab49017fcabc8791189500bceb8b205de36b4be6bf62b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56569be7-5fe0-4d83-8fb6-12215d31d229", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. ", "original_text": "Some students will try to improve state-of-the-art machine \nlearning. "}, "hash": "ded8cdb8b728f43e6f778692644564622b4405b6bc1d19ca50db7b1458bb4ba0", "class_name": "RelatedNodeInfo"}}, "hash": "2c1f4d531ac8f889f66a245c03db9d650eee40b8a27c14b6bcb610c7d2937bb2", "text": "That's probably \nthe most common project. ", "start_char_idx": 28249, "end_char_idx": 28291, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "56569be7-5fe0-4d83-8fb6-12215d31d229": {"__data__": {"id_": "56569be7-5fe0-4d83-8fb6-12215d31d229", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. ", "original_text": "Some students will try to improve state-of-the-art machine \nlearning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b43632ed-ec41-45ec-985a-43a065cb005c", "node_type": "1", "metadata": {"window": "Student : Yeah.  \n Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. ", "original_text": "That's probably \nthe most common project. "}, "hash": "2c1f4d531ac8f889f66a245c03db9d650eee40b8a27c14b6bcb610c7d2937bb2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "16695142-6e3b-40f2-b3e1-d0eba4e50ba1", "node_type": "1", "metadata": {"window": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else? ", "original_text": "Some of those projects are also very  successful. "}, "hash": "6e891042570a6df8ae55985800735b73b9fc7eb86d0d8eb3ff889174b61c770e", "class_name": "RelatedNodeInfo"}}, "hash": "ded8cdb8b728f43e6f778692644564622b4405b6bc1d19ca50db7b1458bb4ba0", "text": "Some students will try to improve state-of-the-art machine \nlearning. ", "start_char_idx": 28291, "end_char_idx": 28361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "16695142-6e3b-40f2-b3e1-d0eba4e50ba1": {"__data__": {"id_": "16695142-6e3b-40f2-b3e1-d0eba4e50ba1", "embedding": null, "metadata": {"window": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else? ", "original_text": "Some of those projects are also very  successful. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "56569be7-5fe0-4d83-8fb6-12215d31d229", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Yeah, let me answer that later.   In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. ", "original_text": "Some students will try to improve state-of-the-art machine \nlearning. "}, "hash": "ded8cdb8b728f43e6f778692644564622b4405b6bc1d19ca50db7b1458bb4ba0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7fa3de7-e1bf-4501-b46b-8b9a892e920d", "node_type": "1", "metadata": {"window": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n", "original_text": "It's a littl e bit harder to do. "}, "hash": "7fe487c9c00e47baafd41d6bd2fe55b12b68b962a042d7f6e67b0ba48f39aa80", "class_name": "RelatedNodeInfo"}}, "hash": "6e891042570a6df8ae55985800735b73b9fc7eb86d0d8eb3ff889174b61c770e", "text": "Some of those projects are also very  successful. ", "start_char_idx": 28361, "end_char_idx": 28411, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d7fa3de7-e1bf-4501-b46b-8b9a892e920d": {"__data__": {"id_": "d7fa3de7-e1bf-4501-b46b-8b9a892e920d", "embedding": null, "metadata": {"window": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n", "original_text": "It's a littl e bit harder to do. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16695142-6e3b-40f2-b3e1-d0eba4e50ba1", "node_type": "1", "metadata": {"window": "In a couple of weeks, I shall \ngive out a handout with guidelines for the pr oject.  But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else? ", "original_text": "Some of those projects are also very  successful. "}, "hash": "6e891042570a6df8ae55985800735b73b9fc7eb86d0d8eb3ff889174b61c770e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2093060e-029d-4fda-ba72-30d184000110", "node_type": "1", "metadata": {"window": "So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics. ", "original_text": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. "}, "hash": "25a932c92889f475d490c3221cbc0371724dbfbbf32fba1bf7dfc43076c5a721", "class_name": "RelatedNodeInfo"}}, "hash": "7fe487c9c00e47baafd41d6bd2fe55b12b68b962a042d7f6e67b0ba48f39aa80", "text": "It's a littl e bit harder to do. ", "start_char_idx": 28411, "end_char_idx": 28444, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2093060e-029d-4fda-ba72-30d184000110": {"__data__": {"id_": "2093060e-029d-4fda-ba72-30d184000110", "embedding": null, "metadata": {"window": "So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics. ", "original_text": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7fa3de7-e1bf-4501-b46b-8b9a892e920d", "node_type": "1", "metadata": {"window": "But for now, we should think of the \ngoal as being to do a cool piec e of machine learning work that  will let you experience the \n\njoys of machine learning firs thand and really try to think about doing a publishable piece \nof work.  \n So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n", "original_text": "It's a littl e bit harder to do. "}, "hash": "7fe487c9c00e47baafd41d6bd2fe55b12b68b962a042d7f6e67b0ba48f39aa80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e9264d9c-2877-460d-bf32-e40dd1c3ee00", "node_type": "1", "metadata": {"window": "That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms. ", "original_text": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. "}, "hash": "dcce54556c73c35a5f0239214a5af506780556c9f5fdd4791071ba2c94e2c735", "class_name": "RelatedNodeInfo"}}, "hash": "25a932c92889f475d490c3221cbc0371724dbfbbf32fba1bf7dfc43076c5a721", "text": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. ", "start_char_idx": 28444, "end_char_idx": 28627, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e9264d9c-2877-460d-bf32-e40dd1c3ee00": {"__data__": {"id_": "e9264d9c-2877-460d-bf32-e40dd1c3ee00", "embedding": null, "metadata": {"window": "That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms. ", "original_text": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2093060e-029d-4fda-ba72-30d184000110", "node_type": "1", "metadata": {"window": "So many students will try to build a cool machine learning application.  That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics. ", "original_text": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning. "}, "hash": "25a932c92889f475d490c3221cbc0371724dbfbbf32fba1bf7dfc43076c5a721", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "96d32e80-6438-460b-a9c6-5bd08d0ba45a", "node_type": "1", "metadata": {"window": "Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector? ", "original_text": "Anything else? "}, "hash": "d33b2f8350d6934a52d497df78a7c433c57733b3986b8007f9effec0f764fe2d", "class_name": "RelatedNodeInfo"}}, "hash": "dcce54556c73c35a5f0239214a5af506780556c9f5fdd4791071ba2c94e2c735", "text": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. ", "start_char_idx": 28627, "end_char_idx": 28747, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96d32e80-6438-460b-a9c6-5bd08d0ba45a": {"__data__": {"id_": "96d32e80-6438-460b-a9c6-5bd08d0ba45a", "embedding": null, "metadata": {"window": "Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector? ", "original_text": "Anything else? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e9264d9c-2877-460d-bf32-e40dd1c3ee00", "node_type": "1", "metadata": {"window": "That's probably \nthe most common project.  Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms. ", "original_text": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common. "}, "hash": "dcce54556c73c35a5f0239214a5af506780556c9f5fdd4791071ba2c94e2c735", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e7666f87-c6a0-4619-aa9e-f7817982bb5c", "node_type": "1", "metadata": {"window": "Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen? ", "original_text": "Okay, cool.  \n"}, "hash": "b7489754e841725e23d257f2e36de1de0db1552e3297dc90922ad57130089baa", "class_name": "RelatedNodeInfo"}}, "hash": "d33b2f8350d6934a52d497df78a7c433c57733b3986b8007f9effec0f764fe2d", "text": "Anything else? ", "start_char_idx": 28747, "end_char_idx": 28762, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e7666f87-c6a0-4619-aa9e-f7817982bb5c": {"__data__": {"id_": "e7666f87-c6a0-4619-aa9e-f7817982bb5c", "embedding": null, "metadata": {"window": "Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen? ", "original_text": "Okay, cool.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "96d32e80-6438-460b-a9c6-5bd08d0ba45a", "node_type": "1", "metadata": {"window": "Some students will try to improve state-of-the-art machine \nlearning.  Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector? ", "original_text": "Anything else? "}, "hash": "d33b2f8350d6934a52d497df78a7c433c57733b3986b8007f9effec0f764fe2d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dfa109d8-42dc-4895-ba13-073baa55b5e7", "node_type": "1", "metadata": {"window": "It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool. ", "original_text": "So that was it for logistics. "}, "hash": "781f398ca0eede664e5e174b52188a04f6f7ec2c278b0f2d8b94e05b74b115a9", "class_name": "RelatedNodeInfo"}}, "hash": "b7489754e841725e23d257f2e36de1de0db1552e3297dc90922ad57130089baa", "text": "Okay, cool.  \n", "start_char_idx": 28762, "end_char_idx": 28776, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dfa109d8-42dc-4895-ba13-073baa55b5e7": {"__data__": {"id_": "dfa109d8-42dc-4895-ba13-073baa55b5e7", "embedding": null, "metadata": {"window": "It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool. ", "original_text": "So that was it for logistics. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7666f87-c6a0-4619-aa9e-f7817982bb5c", "node_type": "1", "metadata": {"window": "Some of those projects are also very  successful.  It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen? ", "original_text": "Okay, cool.  \n"}, "hash": "b7489754e841725e23d257f2e36de1de0db1552e3297dc90922ad57130089baa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cf829cbc-0002-421d-a1fc-9b7b27d6f842", "node_type": "1", "metadata": {"window": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service. ", "original_text": "Let's talk about  learning algorithms. "}, "hash": "12342bcee9f44ceaca3dd5f4eb4fa9ae88dfd78f0c919bad184b498054e00c88", "class_name": "RelatedNodeInfo"}}, "hash": "781f398ca0eede664e5e174b52188a04f6f7ec2c278b0f2d8b94e05b74b115a9", "text": "So that was it for logistics. ", "start_char_idx": 28776, "end_char_idx": 28806, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cf829cbc-0002-421d-a1fc-9b7b27d6f842": {"__data__": {"id_": "cf829cbc-0002-421d-a1fc-9b7b27d6f842", "embedding": null, "metadata": {"window": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service. ", "original_text": "Let's talk about  learning algorithms. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dfa109d8-42dc-4895-ba13-073baa55b5e7", "node_type": "1", "metadata": {"window": "It's a littl e bit harder to do.  And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool. ", "original_text": "So that was it for logistics. "}, "hash": "781f398ca0eede664e5e174b52188a04f6f7ec2c278b0f2d8b94e05b74b115a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5db2958a-c8b4-4678-93ee-7734fb878db8", "node_type": "1", "metadata": {"window": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you. ", "original_text": "So can I have the laptop \ndisplay, please, or the projector? "}, "hash": "3c4863ef2f5ea00d9ea1db5955998117470a617547439a6f103f3037220f87fa", "class_name": "RelatedNodeInfo"}}, "hash": "12342bcee9f44ceaca3dd5f4eb4fa9ae88dfd78f0c919bad184b498054e00c88", "text": "Let's talk about  learning algorithms. ", "start_char_idx": 28806, "end_char_idx": 28845, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5db2958a-c8b4-4678-93ee-7734fb878db8": {"__data__": {"id_": "5db2958a-c8b4-4678-93ee-7734fb878db8", "embedding": null, "metadata": {"window": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you. ", "original_text": "So can I have the laptop \ndisplay, please, or the projector? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cf829cbc-0002-421d-a1fc-9b7b27d6f842", "node_type": "1", "metadata": {"window": "And \nthere's also a smaller minority of students th at will sometimes try to prove \u2014 develop the \ntheory of machine learning further or try to  prove theorems about machine learning.  So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service. ", "original_text": "Let's talk about  learning algorithms. "}, "hash": "12342bcee9f44ceaca3dd5f4eb4fa9ae88dfd78f0c919bad184b498054e00c88", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8e984d72-23c3-4a78-9c08-a196b7d673f3", "node_type": "1", "metadata": {"window": "Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see. ", "original_text": "Actually, co uld you lower the big sc reen? "}, "hash": "a1d2c072d0008beaee99cd5e15ec19c4c4525b2fe8bbe7c8eebb8898780fdcc3", "class_name": "RelatedNodeInfo"}}, "hash": "3c4863ef2f5ea00d9ea1db5955998117470a617547439a6f103f3037220f87fa", "text": "So can I have the laptop \ndisplay, please, or the projector? ", "start_char_idx": 28845, "end_char_idx": 28906, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8e984d72-23c3-4a78-9c08-a196b7d673f3": {"__data__": {"id_": "8e984d72-23c3-4a78-9c08-a196b7d673f3", "embedding": null, "metadata": {"window": "Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see. ", "original_text": "Actually, co uld you lower the big sc reen? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5db2958a-c8b4-4678-93ee-7734fb878db8", "node_type": "1", "metadata": {"window": "So \nthey're usually great projects of all of those types with applications and machine learning \nbeing the most common.  Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you. ", "original_text": "So can I have the laptop \ndisplay, please, or the projector? "}, "hash": "3c4863ef2f5ea00d9ea1db5955998117470a617547439a6f103f3037220f87fa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "092c305b-839f-48d0-94c8-622d9580af9b", "node_type": "1", "metadata": {"window": "Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool. ", "original_text": "Cool. "}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "class_name": "RelatedNodeInfo"}}, "hash": "a1d2c072d0008beaee99cd5e15ec19c4c4525b2fe8bbe7c8eebb8898780fdcc3", "text": "Actually, co uld you lower the big sc reen? ", "start_char_idx": 28906, "end_char_idx": 28950, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "092c305b-839f-48d0-94c8-622d9580af9b": {"__data__": {"id_": "092c305b-839f-48d0-94c8-622d9580af9b", "embedding": null, "metadata": {"window": "Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool. ", "original_text": "Cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e984d72-23c3-4a78-9c08-a196b7d673f3", "node_type": "1", "metadata": {"window": "Anything else?  Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see. ", "original_text": "Actually, co uld you lower the big sc reen? "}, "hash": "a1d2c072d0008beaee99cd5e15ec19c4c4525b2fe8bbe7c8eebb8898780fdcc3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "510b9171-c206-40b0-85b7-b9f6022910df", "node_type": "1", "metadata": {"window": "So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay. ", "original_text": "This is \namazing customer service. "}, "hash": "659a4f747207c72fd9c1b14f2c0f0bd44f95dade3a449913ad111e5784320a59", "class_name": "RelatedNodeInfo"}}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "text": "Cool. ", "start_char_idx": 3386, "end_char_idx": 3392, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "510b9171-c206-40b0-85b7-b9f6022910df": {"__data__": {"id_": "510b9171-c206-40b0-85b7-b9f6022910df", "embedding": null, "metadata": {"window": "So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay. ", "original_text": "This is \namazing customer service. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "092c305b-839f-48d0-94c8-622d9580af9b", "node_type": "1", "metadata": {"window": "Okay, cool.  \n So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool. ", "original_text": "Cool. "}, "hash": "48cf212ffeb87331bcd9f6a28b0a45fd5693cd813ecd70bc5435da820d1c7508", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bf85a60c-9fbf-4e01-8f52-086b9a521948", "node_type": "1", "metadata": {"window": "Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine. ", "original_text": "Thank you. "}, "hash": "fe28f3979c8f08b246482519774f9bab99334a4610bb72d543bd990ea780d723", "class_name": "RelatedNodeInfo"}}, "hash": "659a4f747207c72fd9c1b14f2c0f0bd44f95dade3a449913ad111e5784320a59", "text": "This is \namazing customer service. ", "start_char_idx": 28956, "end_char_idx": 28991, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf85a60c-9fbf-4e01-8f52-086b9a521948": {"__data__": {"id_": "bf85a60c-9fbf-4e01-8f52-086b9a521948", "embedding": null, "metadata": {"window": "Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine. ", "original_text": "Thank you. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "510b9171-c206-40b0-85b7-b9f6022910df", "node_type": "1", "metadata": {"window": "So that was it for logistics.  Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay. ", "original_text": "This is \namazing customer service. "}, "hash": "659a4f747207c72fd9c1b14f2c0f0bd44f95dade3a449913ad111e5784320a59", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fbf2cb4e-998e-4b2e-8205-bd4bf073a697", "node_type": "1", "metadata": {"window": "So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n", "original_text": "I see. "}, "hash": "1905c79600fb4c5277f315abd83460e0a2a9d0d8aa028ec1b21a73af5731bf18", "class_name": "RelatedNodeInfo"}}, "hash": "fe28f3979c8f08b246482519774f9bab99334a4610bb72d543bd990ea780d723", "text": "Thank you. ", "start_char_idx": 28991, "end_char_idx": 29002, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fbf2cb4e-998e-4b2e-8205-bd4bf073a697": {"__data__": {"id_": "fbf2cb4e-998e-4b2e-8205-bd4bf073a697", "embedding": null, "metadata": {"window": "So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n", "original_text": "I see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf85a60c-9fbf-4e01-8f52-086b9a521948", "node_type": "1", "metadata": {"window": "Let's talk about  learning algorithms.  So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine. ", "original_text": "Thank you. "}, "hash": "fe28f3979c8f08b246482519774f9bab99334a4610bb72d543bd990ea780d723", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "83f2e9c3-c196-4bc3-b702-b3860ecd7c2b", "node_type": "1", "metadata": {"window": "Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay. ", "original_text": "Okay, cool. "}, "hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "class_name": "RelatedNodeInfo"}}, "hash": "1905c79600fb4c5277f315abd83460e0a2a9d0d8aa028ec1b21a73af5731bf18", "text": "I see. ", "start_char_idx": 29002, "end_char_idx": 29009, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "83f2e9c3-c196-4bc3-b702-b3860ecd7c2b": {"__data__": {"id_": "83f2e9c3-c196-4bc3-b702-b3860ecd7c2b", "embedding": null, "metadata": {"window": "Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay. ", "original_text": "Okay, cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbf2cb4e-998e-4b2e-8205-bd4bf073a697", "node_type": "1", "metadata": {"window": "So can I have the laptop \ndisplay, please, or the projector?  Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n", "original_text": "I see. "}, "hash": "1905c79600fb4c5277f315abd83460e0a2a9d0d8aa028ec1b21a73af5731bf18", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "342aab5d-7892-4b81-b850-077ebc8a2a6b", "node_type": "1", "metadata": {"window": "Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "text": "Okay, cool. ", "start_char_idx": 13651, "end_char_idx": 13663, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "342aab5d-7892-4b81-b850-077ebc8a2a6b": {"__data__": {"id_": "342aab5d-7892-4b81-b850-077ebc8a2a6b", "embedding": null, "metadata": {"window": "Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool. ", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83f2e9c3-c196-4bc3-b702-b3860ecd7c2b", "node_type": "1", "metadata": {"window": "Actually, co uld you lower the big sc reen?  Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay. ", "original_text": "Okay, cool. "}, "hash": "651a438336944c1a05d1af2c4a419a85c548efcf76685a962e5fb3ceed7e1617", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f59754b6-d749-4251-a90d-996373696a7b", "node_type": "1", "metadata": {"window": "This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks. ", "original_text": "No, that's fine. "}, "hash": "28aade4aa9c58e834c36d27514100d082361e17507c6ebdc42673cef6257e05e", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f59754b6-d749-4251-a90d-996373696a7b": {"__data__": {"id_": "f59754b6-d749-4251-a90d-996373696a7b", "embedding": null, "metadata": {"window": "This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks. ", "original_text": "No, that's fine. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "342aab5d-7892-4b81-b850-077ebc8a2a6b", "node_type": "1", "metadata": {"window": "Cool.  This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "59999ab1-a9af-4c8c-bca1-7ca826e6d79d", "node_type": "1", "metadata": {"window": "Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n", "original_text": "I see. \n"}, "hash": "806ab0e5882b32c2d6760b9647a2547fa489eb738ba5d58ad50d660f70d57178", "class_name": "RelatedNodeInfo"}}, "hash": "28aade4aa9c58e834c36d27514100d082361e17507c6ebdc42673cef6257e05e", "text": "No, that's fine. ", "start_char_idx": 29027, "end_char_idx": 29044, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "59999ab1-a9af-4c8c-bca1-7ca826e6d79d": {"__data__": {"id_": "59999ab1-a9af-4c8c-bca1-7ca826e6d79d", "embedding": null, "metadata": {"window": "Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n", "original_text": "I see. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f59754b6-d749-4251-a90d-996373696a7b", "node_type": "1", "metadata": {"window": "This is \namazing customer service.  Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks. ", "original_text": "No, that's fine. "}, "hash": "28aade4aa9c58e834c36d27514100d082361e17507c6ebdc42673cef6257e05e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "202864df-a567-47c3-9d1d-aa3c7d251e98", "node_type": "1", "metadata": {"window": "I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "806ab0e5882b32c2d6760b9647a2547fa489eb738ba5d58ad50d660f70d57178", "text": "I see. \n", "start_char_idx": 29044, "end_char_idx": 29052, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "202864df-a567-47c3-9d1d-aa3c7d251e98": {"__data__": {"id_": "202864df-a567-47c3-9d1d-aa3c7d251e98", "embedding": null, "metadata": {"window": "I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. ", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "59999ab1-a9af-4c8c-bca1-7ca826e6d79d", "node_type": "1", "metadata": {"window": "Thank you.  I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n", "original_text": "I see. \n"}, "hash": "806ab0e5882b32c2d6760b9647a2547fa489eb738ba5d58ad50d660f70d57178", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2189dffd-ac61-4087-aade-14a962618de4", "node_type": "1", "metadata": {"window": "Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? ", "original_text": "That's cool. "}, "hash": "6714af9b8fb7be252722744606d70feb4f7e6a9518ff8e1ef0a36c41e0fee049", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2189dffd-ac61-4087-aade-14a962618de4": {"__data__": {"id_": "2189dffd-ac61-4087-aade-14a962618de4", "embedding": null, "metadata": {"window": "Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? ", "original_text": "That's cool. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "202864df-a567-47c3-9d1d-aa3c7d251e98", "node_type": "1", "metadata": {"window": "I see.  Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "222d9279-f6fc-49d3-a9b3-b2f7c167c672", "node_type": "1", "metadata": {"window": "Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. ", "original_text": "Thanks. "}, "hash": "bce951a7d0cba18805dd2b360e8bf3fd3aa5980cc5179ff333b6bf2caa2493ae", "class_name": "RelatedNodeInfo"}}, "hash": "6714af9b8fb7be252722744606d70feb4f7e6a9518ff8e1ef0a36c41e0fee049", "text": "That's cool. ", "start_char_idx": 29058, "end_char_idx": 29071, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "222d9279-f6fc-49d3-a9b3-b2f7c167c672": {"__data__": {"id_": "222d9279-f6fc-49d3-a9b3-b2f7c167c672", "embedding": null, "metadata": {"window": "Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. ", "original_text": "Thanks. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2189dffd-ac61-4087-aade-14a962618de4", "node_type": "1", "metadata": {"window": "Okay, cool.  Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? ", "original_text": "That's cool. "}, "hash": "6714af9b8fb7be252722744606d70feb4f7e6a9518ff8e1ef0a36c41e0fee049", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c28a0364-cab9-4c21-95e1-f2723674570d", "node_type": "1", "metadata": {"window": "No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know. ", "original_text": "Okay.  \n"}, "hash": "4fedbccede58a414ca239a8db20e13fdbd42a9e46e055d187cd347c67fec85fc", "class_name": "RelatedNodeInfo"}}, "hash": "bce951a7d0cba18805dd2b360e8bf3fd3aa5980cc5179ff333b6bf2caa2493ae", "text": "Thanks. ", "start_char_idx": 13663, "end_char_idx": 13671, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c28a0364-cab9-4c21-95e1-f2723674570d": {"__data__": {"id_": "c28a0364-cab9-4c21-95e1-f2723674570d", "embedding": null, "metadata": {"window": "No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know. ", "original_text": "Okay.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "222d9279-f6fc-49d3-a9b3-b2f7c167c672", "node_type": "1", "metadata": {"window": "Okay.  No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. ", "original_text": "Thanks. "}, "hash": "bce951a7d0cba18805dd2b360e8bf3fd3aa5980cc5179ff333b6bf2caa2493ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "088d796f-a556-4721-b0c5-33b4e74c0765", "node_type": "1", "metadata": {"window": "I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n", "original_text": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. "}, "hash": "c11dd6c7ab7f70b7b98fe56b4afdeeb9fbbe95f863e89fc8bb3659d37a2d32e7", "class_name": "RelatedNodeInfo"}}, "hash": "4fedbccede58a414ca239a8db20e13fdbd42a9e46e055d187cd347c67fec85fc", "text": "Okay.  \n", "start_char_idx": 29079, "end_char_idx": 29087, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "088d796f-a556-4721-b0c5-33b4e74c0765": {"__data__": {"id_": "088d796f-a556-4721-b0c5-33b4e74c0765", "embedding": null, "metadata": {"window": "I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n", "original_text": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c28a0364-cab9-4c21-95e1-f2723674570d", "node_type": "1", "metadata": {"window": "No, that's fine.  I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know. ", "original_text": "Okay.  \n"}, "hash": "4fedbccede58a414ca239a8db20e13fdbd42a9e46e055d187cd347c67fec85fc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ccd4e2f8-2b5b-4ed6-9d48-7e01aebce9ec", "node_type": "1", "metadata": {"window": "Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is. ", "original_text": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? "}, "hash": "55c67e17fae87f73b6073b48078dd5f864070b5ac839903b49b2f96abbe0351b", "class_name": "RelatedNodeInfo"}}, "hash": "c11dd6c7ab7f70b7b98fe56b4afdeeb9fbbe95f863e89fc8bb3659d37a2d32e7", "text": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. ", "start_char_idx": 29087, "end_char_idx": 29187, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ccd4e2f8-2b5b-4ed6-9d48-7e01aebce9ec": {"__data__": {"id_": "ccd4e2f8-2b5b-4ed6-9d48-7e01aebce9ec", "embedding": null, "metadata": {"window": "Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is. ", "original_text": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "088d796f-a556-4721-b0c5-33b4e74c0765", "node_type": "1", "metadata": {"window": "I see. \n Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n", "original_text": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere. "}, "hash": "c11dd6c7ab7f70b7b98fe56b4afdeeb9fbbe95f863e89fc8bb3659d37a2d32e7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ddc08779-eacf-47f9-bb6e-e635439bd951", "node_type": "1", "metadata": {"window": "That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning? ", "original_text": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. "}, "hash": "23878ab960ccc3cd30b24213e7675ff5aae0dd6b9b4a80e363fa94d6c95e2059", "class_name": "RelatedNodeInfo"}}, "hash": "55c67e17fae87f73b6073b48078dd5f864070b5ac839903b49b2f96abbe0351b", "text": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? ", "start_char_idx": 29187, "end_char_idx": 29320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ddc08779-eacf-47f9-bb6e-e635439bd951": {"__data__": {"id_": "ddc08779-eacf-47f9-bb6e-e635439bd951", "embedding": null, "metadata": {"window": "That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning? ", "original_text": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ccd4e2f8-2b5b-4ed6-9d48-7e01aebce9ec", "node_type": "1", "metadata": {"window": "Okay.  That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is. ", "original_text": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay? "}, "hash": "55c67e17fae87f73b6073b48078dd5f864070b5ac839903b49b2f96abbe0351b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8526cdb7-54bb-40d4-9450-77c8f096783f", "node_type": "1", "metadata": {"window": "Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there? ", "original_text": "I don't know. "}, "hash": "7e2a783ee55ca291c073b05927cc684af3f4517fdc2d6e74bb407dcf945d4490", "class_name": "RelatedNodeInfo"}}, "hash": "23878ab960ccc3cd30b24213e7675ff5aae0dd6b9b4a80e363fa94d6c95e2059", "text": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. ", "start_char_idx": 29320, "end_char_idx": 29421, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8526cdb7-54bb-40d4-9450-77c8f096783f": {"__data__": {"id_": "8526cdb7-54bb-40d4-9450-77c8f096783f", "embedding": null, "metadata": {"window": "Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there? ", "original_text": "I don't know. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ddc08779-eacf-47f9-bb6e-e635439bd951", "node_type": "1", "metadata": {"window": "That's cool.  Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning? ", "original_text": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio. "}, "hash": "23878ab960ccc3cd30b24213e7675ff5aae0dd6b9b4a80e363fa94d6c95e2059", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7d15597e-f6d6-403c-bdc1-9afb9fd305d2", "node_type": "1", "metadata": {"window": "Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n", "original_text": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n"}, "hash": "c43f8fa28b91ad8825fbdc370fbc51e6cd3c5370071c3aab03c5eb50e2aa79ef", "class_name": "RelatedNodeInfo"}}, "hash": "7e2a783ee55ca291c073b05927cc684af3f4517fdc2d6e74bb407dcf945d4490", "text": "I don't know. ", "start_char_idx": 29421, "end_char_idx": 29435, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d15597e-f6d6-403c-bdc1-9afb9fd305d2": {"__data__": {"id_": "7d15597e-f6d6-403c-bdc1-9afb9fd305d2", "embedding": null, "metadata": {"window": "Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n", "original_text": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8526cdb7-54bb-40d4-9450-77c8f096783f", "node_type": "1", "metadata": {"window": "Thanks.  Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there? ", "original_text": "I don't know. "}, "hash": "7e2a783ee55ca291c073b05927cc684af3f4517fdc2d6e74bb407dcf945d4490", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a6f2a966-7781-466d-afd0-9a5ba4405863", "node_type": "1", "metadata": {"window": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible. ", "original_text": "So start by talking about what machine learni ng is. "}, "hash": "ac4bdd17d4e560c40b596fd63bbc22fd5646720c321c3d11a2561d875ba3d486", "class_name": "RelatedNodeInfo"}}, "hash": "c43f8fa28b91ad8825fbdc370fbc51e6cd3c5370071c3aab03c5eb50e2aa79ef", "text": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n", "start_char_idx": 29435, "end_char_idx": 29556, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a6f2a966-7781-466d-afd0-9a5ba4405863": {"__data__": {"id_": "a6f2a966-7781-466d-afd0-9a5ba4405863", "embedding": null, "metadata": {"window": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible. ", "original_text": "So start by talking about what machine learni ng is. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d15597e-f6d6-403c-bdc1-9afb9fd305d2", "node_type": "1", "metadata": {"window": "Okay.  \n Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n", "original_text": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n"}, "hash": "c43f8fa28b91ad8825fbdc370fbc51e6cd3c5370071c3aab03c5eb50e2aa79ef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc9b0375-2447-4653-a6d0-22a4af575a13", "node_type": "1", "metadata": {"window": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay. ", "original_text": "What is machine learning? "}, "hash": "eb966a58ea5dc3227bf9c8d7c40db5d18b9c78ef00a9d32f36f8b63dacff40e1", "class_name": "RelatedNodeInfo"}}, "hash": "ac4bdd17d4e560c40b596fd63bbc22fd5646720c321c3d11a2561d875ba3d486", "text": "So start by talking about what machine learni ng is. ", "start_char_idx": 29556, "end_char_idx": 29609, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc9b0375-2447-4653-a6d0-22a4af575a13": {"__data__": {"id_": "bc9b0375-2447-4653-a6d0-22a4af575a13", "embedding": null, "metadata": {"window": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay. ", "original_text": "What is machine learning? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a6f2a966-7781-466d-afd0-9a5ba4405863", "node_type": "1", "metadata": {"window": "Big screen isn't working toda y, but I hope you can read things  on the smaller screens out \nthere.  Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible. ", "original_text": "So start by talking about what machine learni ng is. "}, "hash": "ac4bdd17d4e560c40b596fd63bbc22fd5646720c321c3d11a2561d875ba3d486", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "167e91f4-3528-4f83-b480-877d996449cd", "node_type": "1", "metadata": {"window": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n", "original_text": "Actually, \ncan you read the text out there? "}, "hash": "f0b29b6fc2e6e694a5d54224d28040290a05f2ad7f65a67c9a4d057b9c0c16b0", "class_name": "RelatedNodeInfo"}}, "hash": "eb966a58ea5dc3227bf9c8d7c40db5d18b9c78ef00a9d32f36f8b63dacff40e1", "text": "What is machine learning? ", "start_char_idx": 29609, "end_char_idx": 29635, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "167e91f4-3528-4f83-b480-877d996449cd": {"__data__": {"id_": "167e91f4-3528-4f83-b480-877d996449cd", "embedding": null, "metadata": {"window": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n", "original_text": "Actually, \ncan you read the text out there? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc9b0375-2447-4653-a6d0-22a4af575a13", "node_type": "1", "metadata": {"window": "Actually, [inaudible] I think this room just got a new projector that \u2014 someone \nsent you an excited email \u2014 was it just on Frid ay?  \u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay. ", "original_text": "What is machine learning? "}, "hash": "eb966a58ea5dc3227bf9c8d7c40db5d18b9c78ef00a9d32f36f8b63dacff40e1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "633f72b6-a13f-4b79-93c8-95e408f14726", "node_type": "1", "metadata": {"window": "I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning? ", "original_text": "Raise your hand if the text on the small screens is legible. \n"}, "hash": "2d9e30d6129397c26a509d729a9287331001c3a46837fd92e245cb4a53b11a91", "class_name": "RelatedNodeInfo"}}, "hash": "f0b29b6fc2e6e694a5d54224d28040290a05f2ad7f65a67c9a4d057b9c0c16b0", "text": "Actually, \ncan you read the text out there? ", "start_char_idx": 29635, "end_char_idx": 29679, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "633f72b6-a13f-4b79-93c8-95e408f14726": {"__data__": {"id_": "633f72b6-a13f-4b79-93c8-95e408f14726", "embedding": null, "metadata": {"window": "I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning? ", "original_text": "Raise your hand if the text on the small screens is legible. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "167e91f4-3528-4f83-b480-877d996449cd", "node_type": "1", "metadata": {"window": "\u2014 saying we just got a new projector \nand they said 4,000-to-1 something or othe r brightness ratio.  I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n", "original_text": "Actually, \ncan you read the text out there? "}, "hash": "f0b29b6fc2e6e694a5d54224d28040290a05f2ad7f65a67c9a4d057b9c0c16b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b724a9ee-da0f-4b78-874b-a2d3ec1b8b3f", "node_type": "1", "metadata": {"window": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. ", "original_text": "Oh, okay, cool, mostly legible. "}, "hash": "c51152fe2b65b5b1daf83b5fd4c3e1d2e6c0ba12297777822e00ebdf6c25a401", "class_name": "RelatedNodeInfo"}}, "hash": "2d9e30d6129397c26a509d729a9287331001c3a46837fd92e245cb4a53b11a91", "text": "Raise your hand if the text on the small screens is legible. \n", "start_char_idx": 29679, "end_char_idx": 29741, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b724a9ee-da0f-4b78-874b-a2d3ec1b8b3f": {"__data__": {"id_": "b724a9ee-da0f-4b78-874b-a2d3ec1b8b3f", "embedding": null, "metadata": {"window": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. ", "original_text": "Oh, okay, cool, mostly legible. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "633f72b6-a13f-4b79-93c8-95e408f14726", "node_type": "1", "metadata": {"window": "I don't know.  Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning? ", "original_text": "Raise your hand if the text on the small screens is legible. \n"}, "hash": "2d9e30d6129397c26a509d729a9287331001c3a46837fd92e245cb4a53b11a91", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e6fd3c46-e3b6-406c-a1ea-b9e23c1e97fe", "node_type": "1", "metadata": {"window": "So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "c51152fe2b65b5b1daf83b5fd4c3e1d2e6c0ba12297777822e00ebdf6c25a401", "text": "Oh, okay, cool, mostly legible. ", "start_char_idx": 29741, "end_char_idx": 29773, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e6fd3c46-e3b6-406c-a1ea-b9e23c1e97fe": {"__data__": {"id_": "e6fd3c46-e3b6-406c-a1ea-b9e23c1e97fe", "embedding": null, "metadata": {"window": "So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b724a9ee-da0f-4b78-874b-a2d3ec1b8b3f", "node_type": "1", "metadata": {"window": "Someone was \nvery excited about the new projector in this room, but I guess we'll see that in operation \non Wednesday.  \n So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. ", "original_text": "Oh, okay, cool, mostly legible. "}, "hash": "c51152fe2b65b5b1daf83b5fd4c3e1d2e6c0ba12297777822e00ebdf6c25a401", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f2a1fe0a-d52b-4982-8d5c-249783e3aaa3", "node_type": "1", "metadata": {"window": "What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. ", "original_text": "So I'll just read it out.  \n"}, "hash": "186b19de15623c636960f74ef198cd367e99309ace52c527c401f1cbc929bd93", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f2a1fe0a-d52b-4982-8d5c-249783e3aaa3": {"__data__": {"id_": "f2a1fe0a-d52b-4982-8d5c-249783e3aaa3", "embedding": null, "metadata": {"window": "What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. ", "original_text": "So I'll just read it out.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e6fd3c46-e3b6-406c-a1ea-b9e23c1e97fe", "node_type": "1", "metadata": {"window": "So start by talking about what machine learni ng is.  What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42536a61-7fec-4ce6-8d17-68f22096d746", "node_type": "1", "metadata": {"window": "Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n", "original_text": "So what is machine learning? "}, "hash": "8e781df4c9bceccb40b0ff165889def472e3db2bccc3c7ea86d94c6643a389c8", "class_name": "RelatedNodeInfo"}}, "hash": "186b19de15623c636960f74ef198cd367e99309ace52c527c401f1cbc929bd93", "text": "So I'll just read it out.  \n", "start_char_idx": 29779, "end_char_idx": 29807, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "42536a61-7fec-4ce6-8d17-68f22096d746": {"__data__": {"id_": "42536a61-7fec-4ce6-8d17-68f22096d746", "embedding": null, "metadata": {"window": "Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n", "original_text": "So what is machine learning? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f2a1fe0a-d52b-4982-8d5c-249783e3aaa3", "node_type": "1", "metadata": {"window": "What is machine learning?  Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. ", "original_text": "So I'll just read it out.  \n"}, "hash": "186b19de15623c636960f74ef198cd367e99309ace52c527c401f1cbc929bd93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86a5c506-2cf2-4c86-a456-6406eaf045cd", "node_type": "1", "metadata": {"window": "Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. ", "original_text": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. "}, "hash": "5f601a2c5dd38b29399683bb70eddae1746eddd0a27e02bda08e39066e422796", "class_name": "RelatedNodeInfo"}}, "hash": "8e781df4c9bceccb40b0ff165889def472e3db2bccc3c7ea86d94c6643a389c8", "text": "So what is machine learning? ", "start_char_idx": 29807, "end_char_idx": 29836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "86a5c506-2cf2-4c86-a456-6406eaf045cd": {"__data__": {"id_": "86a5c506-2cf2-4c86-a456-6406eaf045cd", "embedding": null, "metadata": {"window": "Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. ", "original_text": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42536a61-7fec-4ce6-8d17-68f22096d746", "node_type": "1", "metadata": {"window": "Actually, \ncan you read the text out there?  Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n", "original_text": "So what is machine learning? "}, "hash": "8e781df4c9bceccb40b0ff165889def472e3db2bccc3c7ea86d94c6643a389c8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3061d59a-5cdb-411f-b7c0-02758b27e31a", "node_type": "1", "metadata": {"window": "Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n", "original_text": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n"}, "hash": "23c1f2ced0050ab0cb42972ac2f4a480b4b69b9cfbf1d9f1cee6c1f2f5668c8f", "class_name": "RelatedNodeInfo"}}, "hash": "5f601a2c5dd38b29399683bb70eddae1746eddd0a27e02bda08e39066e422796", "text": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. ", "start_char_idx": 29836, "end_char_idx": 30056, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3061d59a-5cdb-411f-b7c0-02758b27e31a": {"__data__": {"id_": "3061d59a-5cdb-411f-b7c0-02758b27e31a", "embedding": null, "metadata": {"window": "Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n", "original_text": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "86a5c506-2cf2-4c86-a456-6406eaf045cd", "node_type": "1", "metadata": {"window": "Raise your hand if the text on the small screens is legible. \n Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. ", "original_text": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed. "}, "hash": "5f601a2c5dd38b29399683bb70eddae1746eddd0a27e02bda08e39066e422796", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8bc8da4d-88db-45f4-ac10-2a1d19a34075", "node_type": "1", "metadata": {"window": "Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. ", "original_text": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. "}, "hash": "036aea1dca4a7a639c9773dede5a327fca8f8c03073a35e0e95ce2d8eb85d8b2", "class_name": "RelatedNodeInfo"}}, "hash": "23c1f2ced0050ab0cb42972ac2f4a480b4b69b9cfbf1d9f1cee6c1f2f5668c8f", "text": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n", "start_char_idx": 30056, "end_char_idx": 30253, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8bc8da4d-88db-45f4-ac10-2a1d19a34075": {"__data__": {"id_": "8bc8da4d-88db-45f4-ac10-2a1d19a34075", "embedding": null, "metadata": {"window": "Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. ", "original_text": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3061d59a-5cdb-411f-b7c0-02758b27e31a", "node_type": "1", "metadata": {"window": "Oh, okay, cool, mostly legible.  Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n", "original_text": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n"}, "hash": "23c1f2ced0050ab0cb42972ac2f4a480b4b69b9cfbf1d9f1cee6c1f2f5668c8f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f1c568b3-641d-43aa-bd1d-f140fadd0032", "node_type": "1", "metadata": {"window": "So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n", "original_text": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n"}, "hash": "f97f448c296307792cdcf2298d5dd2984aa6841b85fc32ca6a138d35a3109210", "class_name": "RelatedNodeInfo"}}, "hash": "036aea1dca4a7a639c9773dede5a327fca8f8c03073a35e0e95ce2d8eb85d8b2", "text": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. ", "start_char_idx": 30253, "end_char_idx": 30531, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f1c568b3-641d-43aa-bd1d-f140fadd0032": {"__data__": {"id_": "f1c568b3-641d-43aa-bd1d-f140fadd0032", "embedding": null, "metadata": {"window": "So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n", "original_text": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8bc8da4d-88db-45f4-ac10-2a1d19a34075", "node_type": "1", "metadata": {"window": "Okay.  So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. ", "original_text": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses. "}, "hash": "036aea1dca4a7a639c9773dede5a327fca8f8c03073a35e0e95ce2d8eb85d8b2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1f5b154-1cb3-40f8-b5a6-5c9947c2dd56", "node_type": "1", "metadata": {"window": "So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. ", "original_text": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. "}, "hash": "ffee4d7cd7350e8af1b0fc899bf6a84078aaede784b8c0b225f04c1b6ea339f9", "class_name": "RelatedNodeInfo"}}, "hash": "f97f448c296307792cdcf2298d5dd2984aa6841b85fc32ca6a138d35a3109210", "text": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n", "start_char_idx": 30531, "end_char_idx": 30780, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c1f5b154-1cb3-40f8-b5a6-5c9947c2dd56": {"__data__": {"id_": "c1f5b154-1cb3-40f8-b5a6-5c9947c2dd56", "embedding": null, "metadata": {"window": "So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. ", "original_text": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f1c568b3-641d-43aa-bd1d-f140fadd0032", "node_type": "1", "metadata": {"window": "So I'll just read it out.  \n So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n", "original_text": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n"}, "hash": "f97f448c296307792cdcf2298d5dd2984aa6841b85fc32ca6a138d35a3109210", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b8ee043c-5dfb-4cf9-b080-56dc31385179", "node_type": "1", "metadata": {"window": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n", "original_text": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n"}, "hash": "f1cb325d7c9f36d79aed15da5d8a1b0e003d675f3fdf48a0f80c1f55d0eeaf61", "class_name": "RelatedNodeInfo"}}, "hash": "ffee4d7cd7350e8af1b0fc899bf6a84078aaede784b8c0b225f04c1b6ea339f9", "text": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. ", "start_char_idx": 30780, "end_char_idx": 31043, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b8ee043c-5dfb-4cf9-b080-56dc31385179": {"__data__": {"id_": "b8ee043c-5dfb-4cf9-b080-56dc31385179", "embedding": null, "metadata": {"window": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n", "original_text": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1f5b154-1cb3-40f8-b5a6-5c9947c2dd56", "node_type": "1", "metadata": {"window": "So what is machine learning?  Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. ", "original_text": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses. "}, "hash": "ffee4d7cd7350e8af1b0fc899bf6a84078aaede784b8c0b225f04c1b6ea339f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f5643665-1982-4f0b-802b-8ca1b05d6964", "node_type": "1", "metadata": {"window": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. ", "original_text": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. "}, "hash": "6112f6b824b2ae3d9f67935f25510359e815cad7f9cdd013b00a5ac65e144d54", "class_name": "RelatedNodeInfo"}}, "hash": "f1cb325d7c9f36d79aed15da5d8a1b0e003d675f3fdf48a0f80c1f55d0eeaf61", "text": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n", "start_char_idx": 31043, "end_char_idx": 31205, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5643665-1982-4f0b-802b-8ca1b05d6964": {"__data__": {"id_": "f5643665-1982-4f0b-802b-8ca1b05d6964", "embedding": null, "metadata": {"window": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. ", "original_text": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b8ee043c-5dfb-4cf9-b080-56dc31385179", "node_type": "1", "metadata": {"window": "Way back in  about 1959, Arthur Samuel defined machine \nlearning informally as the [inaudible] that gives computers to learn \u2014 [inaudible] that \ngives computers the ability to learn without  being explicitly programmed.  So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n", "original_text": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n"}, "hash": "f1cb325d7c9f36d79aed15da5d8a1b0e003d675f3fdf48a0f80c1f55d0eeaf61", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "92c50d46-b1b2-4017-baa1-ec721536d0ea", "node_type": "1", "metadata": {"window": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. ", "original_text": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n"}, "hash": "fc81766f594f59ebe8f0248bd4a16f21b6d6e5e2ec729d901c8e3bb840e6934f", "class_name": "RelatedNodeInfo"}}, "hash": "6112f6b824b2ae3d9f67935f25510359e815cad7f9cdd013b00a5ac65e144d54", "text": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. ", "start_char_idx": 31205, "end_char_idx": 31330, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "92c50d46-b1b2-4017-baa1-ec721536d0ea": {"__data__": {"id_": "92c50d46-b1b2-4017-baa1-ec721536d0ea", "embedding": null, "metadata": {"window": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. ", "original_text": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5643665-1982-4f0b-802b-8ca1b05d6964", "node_type": "1", "metadata": {"window": "So Arthur \nSamuel, so way back in the history of m achine learning, actually did something very \ncool, which was he wrote a checkers progr am, which would play games of checkers \nagainst itself.  \n And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. ", "original_text": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to. "}, "hash": "6112f6b824b2ae3d9f67935f25510359e815cad7f9cdd013b00a5ac65e144d54", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "01b92a2a-24d8-404f-b126-7eddc6c6a93d", "node_type": "1", "metadata": {"window": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n", "original_text": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. "}, "hash": "73400ec00989ef8a1a08c7cddf4042543fddcda19e11c26d567cd49eaacdba1d", "class_name": "RelatedNodeInfo"}}, "hash": "fc81766f594f59ebe8f0248bd4a16f21b6d6e5e2ec729d901c8e3bb840e6934f", "text": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n", "start_char_idx": 31330, "end_char_idx": 31682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "01b92a2a-24d8-404f-b126-7eddc6c6a93d": {"__data__": {"id_": "01b92a2a-24d8-404f-b126-7eddc6c6a93d", "embedding": null, "metadata": {"window": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n", "original_text": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "92c50d46-b1b2-4017-baa1-ec721536d0ea", "node_type": "1", "metadata": {"window": "And so because a computer can play thousands  of games against itself relatively quickly, \nArthur Samuel had his program play thousands  of games against itself, and over time it \nwould start to learn to rec ognize patterns which led to wi ns and patterns which led to \nlosses.  So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. ", "original_text": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n"}, "hash": "fc81766f594f59ebe8f0248bd4a16f21b6d6e5e2ec729d901c8e3bb840e6934f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9192c182-3451-4d87-83c2-76a71dd483b1", "node_type": "1", "metadata": {"window": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. ", "original_text": "So not  only is it a definition, it even rhymes.  \n"}, "hash": "72dca34d784c72a51cf0cad049a345bbdd97363c73cfbcf677b86a250f10b12b", "class_name": "RelatedNodeInfo"}}, "hash": "73400ec00989ef8a1a08c7cddf4042543fddcda19e11c26d567cd49eaacdba1d", "text": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. ", "start_char_idx": 31682, "end_char_idx": 32060, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9192c182-3451-4d87-83c2-76a71dd483b1": {"__data__": {"id_": "9192c182-3451-4d87-83c2-76a71dd483b1", "embedding": null, "metadata": {"window": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. ", "original_text": "So not  only is it a definition, it even rhymes.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01b92a2a-24d8-404f-b126-7eddc6c6a93d", "node_type": "1", "metadata": {"window": "So over time it learned things like that , \"Gee, if I get a lot of pieces taken by the \nopponent, then I'm more likely to lose than win,\" or, \"Gee, if I get my pieces into a \ncertain position, then I'm especially li kely to win rather than lose.\"  \n And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n", "original_text": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay. "}, "hash": "73400ec00989ef8a1a08c7cddf4042543fddcda19e11c26d567cd49eaacdba1d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56f9ab29-1a2b-49d4-89e5-4073ee42b7d8", "node_type": "1", "metadata": {"window": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning. ", "original_text": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. "}, "hash": "c175a8b9b5f7bc0cd0fb5a7b9efd2911fbeb58ad342e7517a25fc794a54555d9", "class_name": "RelatedNodeInfo"}}, "hash": "72dca34d784c72a51cf0cad049a345bbdd97363c73cfbcf677b86a250f10b12b", "text": "So not  only is it a definition, it even rhymes.  \n", "start_char_idx": 32060, "end_char_idx": 32111, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "56f9ab29-1a2b-49d4-89e5-4073ee42b7d8": {"__data__": {"id_": "56f9ab29-1a2b-49d4-89e5-4073ee42b7d8", "embedding": null, "metadata": {"window": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning. ", "original_text": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9192c182-3451-4d87-83c2-76a71dd483b1", "node_type": "1", "metadata": {"window": "And so over time, Arthur Samuel had a check ers program that woul d actually learn to \nplay checkers by learning what are the sort of  board positions that tend to be associated \nwith wins and what are the boa rd positions that tend to be associated with losses.  And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. ", "original_text": "So not  only is it a definition, it even rhymes.  \n"}, "hash": "72dca34d784c72a51cf0cad049a345bbdd97363c73cfbcf677b86a250f10b12b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c70e0e1e-73e4-4a64-af16-150b8aa13cfc", "node_type": "1", "metadata": {"window": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n", "original_text": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. "}, "hash": "e46463a566c62ea7bb453c78f360540d2c8bade3f441d219acb15ddc935420f2", "class_name": "RelatedNodeInfo"}}, "hash": "c175a8b9b5f7bc0cd0fb5a7b9efd2911fbeb58ad342e7517a25fc794a54555d9", "text": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. ", "start_char_idx": 32111, "end_char_idx": 32273, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c70e0e1e-73e4-4a64-af16-150b8aa13cfc": {"__data__": {"id_": "c70e0e1e-73e4-4a64-af16-150b8aa13cfc", "embedding": null, "metadata": {"window": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n", "original_text": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "56f9ab29-1a2b-49d4-89e5-4073ee42b7d8", "node_type": "1", "metadata": {"window": "And \nway back around 1959, the amazing thing about this was that his program actually \nlearned to play checkers much better than Arthur Samuel  himself could.  \n\n So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning. ", "original_text": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say. "}, "hash": "c175a8b9b5f7bc0cd0fb5a7b9efd2911fbeb58ad342e7517a25fc794a54555d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3823b812-c038-409f-8e10-6e89752ccb85", "node_type": "1", "metadata": {"window": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices. ", "original_text": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n"}, "hash": "e6610b164558c9f38792d8feeea57af2b9259ed7bb664f84213fe0b460fe29c0", "class_name": "RelatedNodeInfo"}}, "hash": "e46463a566c62ea7bb453c78f360540d2c8bade3f441d219acb15ddc935420f2", "text": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. ", "start_char_idx": 32273, "end_char_idx": 32446, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3823b812-c038-409f-8e10-6e89752ccb85": {"__data__": {"id_": "3823b812-c038-409f-8e10-6e89752ccb85", "embedding": null, "metadata": {"window": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices. ", "original_text": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c70e0e1e-73e4-4a64-af16-150b8aa13cfc", "node_type": "1", "metadata": {"window": "So even today, there are some people that say, well, computers can't do anything that \nthey're not explicitly programmed to.  And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n", "original_text": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents. "}, "hash": "e46463a566c62ea7bb453c78f360540d2c8bade3f441d219acb15ddc935420f2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ce1f887-dfce-4e46-89f0-01cdaba3a4af", "node_type": "1", "metadata": {"window": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. ", "original_text": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. "}, "hash": "2a43db64338f978076abb3cdadf983dffaa00a9454fc5c15b861d8b11f49ae52", "class_name": "RelatedNodeInfo"}}, "hash": "e6610b164558c9f38792d8feeea57af2b9259ed7bb664f84213fe0b460fe29c0", "text": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n", "start_char_idx": 32446, "end_char_idx": 32559, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6ce1f887-dfce-4e46-89f0-01cdaba3a4af": {"__data__": {"id_": "6ce1f887-dfce-4e46-89f0-01cdaba3a4af", "embedding": null, "metadata": {"window": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. ", "original_text": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3823b812-c038-409f-8e10-6e89752ccb85", "node_type": "1", "metadata": {"window": "And Ar thur Samuel's checkers program was maybe \nthe first I think really convi ncing refutation of this clai m. Namely, Arthur Samuel \nmanaged to write a checkers program that could play checkers much better than he \npersonally could, and this is an instance of maybe computers learning to do things that \nthey were not programmed explicitly to do.  \n Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices. ", "original_text": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n"}, "hash": "e6610b164558c9f38792d8feeea57af2b9259ed7bb664f84213fe0b460fe29c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "436f8801-c6bb-4343-ab0e-d2d0feddc612", "node_type": "1", "metadata": {"window": "So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. ", "original_text": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning. "}, "hash": "e4d412b65ff634a9912308caf776f3cb476089092edbae2f809b640b2e5f2f1b", "class_name": "RelatedNodeInfo"}}, "hash": "2a43db64338f978076abb3cdadf983dffaa00a9454fc5c15b861d8b11f49ae52", "text": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. ", "start_char_idx": 32559, "end_char_idx": 32677, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "436f8801-c6bb-4343-ab0e-d2d0feddc612": {"__data__": {"id_": "436f8801-c6bb-4343-ab0e-d2d0feddc612", "embedding": null, "metadata": {"window": "So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. ", "original_text": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ce1f887-dfce-4e46-89f0-01cdaba3a4af", "node_type": "1", "metadata": {"window": "Here's a more recent, a more modern, more formal definition of machine learning due to \nTom Mitchell, who says that a well-posed le arning problem is defined as follows: He \nsays that a computer program is set to lear n from an experience E with respect to some \ntask T and some performance measure P if  its performance on T as measured by P \nimproves with experience E. Okay.  So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. ", "original_text": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections. "}, "hash": "2a43db64338f978076abb3cdadf983dffaa00a9454fc5c15b861d8b11f49ae52", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7b9ae755-5bc8-4e1c-b5dc-fdcc924de302", "node_type": "1", "metadata": {"window": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. ", "original_text": "So le t me give you an example of that.  \n"}, "hash": "fc83963dfeff5245c99a5dae9bf690136e4f322174dda48669089ce2f20f83ea", "class_name": "RelatedNodeInfo"}}, "hash": "e4d412b65ff634a9912308caf776f3cb476089092edbae2f809b640b2e5f2f1b", "text": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning. ", "start_char_idx": 32677, "end_char_idx": 32777, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7b9ae755-5bc8-4e1c-b5dc-fdcc924de302": {"__data__": {"id_": "7b9ae755-5bc8-4e1c-b5dc-fdcc924de302", "embedding": null, "metadata": {"window": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. ", "original_text": "So le t me give you an example of that.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "436f8801-c6bb-4343-ab0e-d2d0feddc612", "node_type": "1", "metadata": {"window": "So not  only is it a definition, it even rhymes.  \n So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. ", "original_text": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning. "}, "hash": "e4d412b65ff634a9912308caf776f3cb476089092edbae2f809b640b2e5f2f1b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "173df658-519d-447e-9b4e-fab76b0f50eb", "node_type": "1", "metadata": {"window": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. ", "original_text": "So suppose you collect a data set of housing prices. "}, "hash": "81e804312c30d77f23bc9602507eb9b2878e41d9378ad43d24ce31bb1c2e0053", "class_name": "RelatedNodeInfo"}}, "hash": "fc83963dfeff5245c99a5dae9bf690136e4f322174dda48669089ce2f20f83ea", "text": "So le t me give you an example of that.  \n", "start_char_idx": 32777, "end_char_idx": 32819, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "173df658-519d-447e-9b4e-fab76b0f50eb": {"__data__": {"id_": "173df658-519d-447e-9b4e-fab76b0f50eb", "embedding": null, "metadata": {"window": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. ", "original_text": "So suppose you collect a data set of housing prices. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b9ae755-5bc8-4e1c-b5dc-fdcc924de302", "node_type": "1", "metadata": {"window": "So, for example, in the case of checkers, th e experience E that a program has would be \nthe experience of playing lots of games of checkers against itself, say.  The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. ", "original_text": "So le t me give you an example of that.  \n"}, "hash": "fc83963dfeff5245c99a5dae9bf690136e4f322174dda48669089ce2f20f83ea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fe36dd03-859c-4c65-bb1e-30774442eec6", "node_type": "1", "metadata": {"window": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n", "original_text": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. "}, "hash": "2765217b620dfdef7f2a589de83a47370da100d8dcc07a9b38cd2b5d0034749f", "class_name": "RelatedNodeInfo"}}, "hash": "81e804312c30d77f23bc9602507eb9b2878e41d9378ad43d24ce31bb1c2e0053", "text": "So suppose you collect a data set of housing prices. ", "start_char_idx": 32819, "end_char_idx": 32872, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fe36dd03-859c-4c65-bb1e-30774442eec6": {"__data__": {"id_": "fe36dd03-859c-4c65-bb1e-30774442eec6", "embedding": null, "metadata": {"window": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n", "original_text": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "173df658-519d-447e-9b4e-fab76b0f50eb", "node_type": "1", "metadata": {"window": "The task T is the \ntask of playing checkers, a nd the performance measure P will be something like the \nfraction of games it wins against a cert ain set of human opponents.  And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. ", "original_text": "So suppose you collect a data set of housing prices. "}, "hash": "81e804312c30d77f23bc9602507eb9b2878e41d9378ad43d24ce31bb1c2e0053", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "940653ce-c065-4558-ac0b-08b5c6c85974", "node_type": "1", "metadata": {"window": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. ", "original_text": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. "}, "hash": "92110bf823cd7fbe60ce5d5801d4e2f7a56186ec5b41ec389fe587434e9a7b69", "class_name": "RelatedNodeInfo"}}, "hash": "2765217b620dfdef7f2a589de83a47370da100d8dcc07a9b38cd2b5d0034749f", "text": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. ", "start_char_idx": 32872, "end_char_idx": 32981, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "940653ce-c065-4558-ac0b-08b5c6c85974": {"__data__": {"id_": "940653ce-c065-4558-ac0b-08b5c6c85974", "embedding": null, "metadata": {"window": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. ", "original_text": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fe36dd03-859c-4c65-bb1e-30774442eec6", "node_type": "1", "metadata": {"window": "And by this \ndefinition, we'll say that Arthur Samuel's ch eckers program has learned to play checkers, \nokay?  \n So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n", "original_text": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later. "}, "hash": "2765217b620dfdef7f2a589de83a47370da100d8dcc07a9b38cd2b5d0034749f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b321be4-a0d4-4b5c-a13d-a15b99f964f3", "node_type": "1", "metadata": {"window": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. ", "original_text": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. "}, "hash": "1ba9b428a29a9c85375a5032641ff89d3fb661fcb9e3f2a0417cf140e0c9f52d", "class_name": "RelatedNodeInfo"}}, "hash": "92110bf823cd7fbe60ce5d5801d4e2f7a56186ec5b41ec389fe587434e9a7b69", "text": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. ", "start_char_idx": 32981, "end_char_idx": 33086, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b321be4-a0d4-4b5c-a13d-a15b99f964f3": {"__data__": {"id_": "4b321be4-a0d4-4b5c-a13d-a15b99f964f3", "embedding": null, "metadata": {"window": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. ", "original_text": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "940653ce-c065-4558-ac0b-08b5c6c85974", "node_type": "1", "metadata": {"window": "So as an overview of what we're going to do in this class, this class is sort of organized \ninto four major sections.  We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. ", "original_text": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area. "}, "hash": "92110bf823cd7fbe60ce5d5801d4e2f7a56186ec5b41ec389fe587434e9a7b69", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d9c5d5f-b3f9-43c6-9c35-fc794c435a88", "node_type": "1", "metadata": {"window": "So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n", "original_text": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. "}, "hash": "8734f5f2827e3dbd04dc3a62f66eaf37c63eabbad2cf453328ac09b4129f7432", "class_name": "RelatedNodeInfo"}}, "hash": "1ba9b428a29a9c85375a5032641ff89d3fb661fcb9e3f2a0417cf140e0c9f52d", "text": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. ", "start_char_idx": 33086, "end_char_idx": 33161, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4d9c5d5f-b3f9-43c6-9c35-fc794c435a88": {"__data__": {"id_": "4d9c5d5f-b3f9-43c6-9c35-fc794c435a88", "embedding": null, "metadata": {"window": "So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n", "original_text": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b321be4-a0d4-4b5c-a13d-a15b99f964f3", "node_type": "1", "metadata": {"window": "We're gonna talk about four major topics in this class, the first \nof which is supervised learning.  So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. ", "original_text": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon. "}, "hash": "1ba9b428a29a9c85375a5032641ff89d3fb661fcb9e3f2a0417cf140e0c9f52d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b63ba5b-d487-4c00-a9e5-aaf9a0436c44", "node_type": "1", "metadata": {"window": "So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it. ", "original_text": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n"}, "hash": "f4e8b5f5d74d4bc25a30565d14b8d467bb89c80cbf497dcc909af9b37a38c9e7", "class_name": "RelatedNodeInfo"}}, "hash": "8734f5f2827e3dbd04dc3a62f66eaf37c63eabbad2cf453328ac09b4129f7432", "text": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. ", "start_char_idx": 33161, "end_char_idx": 33319, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b63ba5b-d487-4c00-a9e5-aaf9a0436c44": {"__data__": {"id_": "1b63ba5b-d487-4c00-a9e5-aaf9a0436c44", "embedding": null, "metadata": {"window": "So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it. ", "original_text": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d9c5d5f-b3f9-43c6-9c35-fc794c435a88", "node_type": "1", "metadata": {"window": "So le t me give you an example of that.  \n So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n", "original_text": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses. "}, "hash": "8734f5f2827e3dbd04dc3a62f66eaf37c63eabbad2cf453328ac09b4129f7432", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b6491ac-10a1-4a1b-a2e4-6071e53b4337", "node_type": "1", "metadata": {"window": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? ", "original_text": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. "}, "hash": "66b701fef33780ca1855e71bc893711ca964070dd9dad858c4e6bb8a069656b3", "class_name": "RelatedNodeInfo"}}, "hash": "f4e8b5f5d74d4bc25a30565d14b8d467bb89c80cbf497dcc909af9b37a38c9e7", "text": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n", "start_char_idx": 33319, "end_char_idx": 33446, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b6491ac-10a1-4a1b-a2e4-6071e53b4337": {"__data__": {"id_": "1b6491ac-10a1-4a1b-a2e4-6071e53b4337", "embedding": null, "metadata": {"window": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? ", "original_text": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b63ba5b-d487-4c00-a9e5-aaf9a0436c44", "node_type": "1", "metadata": {"window": "So suppose you collect a data set of housing prices.  And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it. ", "original_text": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n"}, "hash": "f4e8b5f5d74d4bc25a30565d14b8d467bb89c80cbf497dcc909af9b37a38c9e7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "92787f47-1f73-4a61-8d9d-000c47ec75a0", "node_type": "1", "metadata": {"window": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n", "original_text": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. "}, "hash": "009b46198304b82263b804aa2aa12bdfae5be4ec10e436282cc8822e70570ef9", "class_name": "RelatedNodeInfo"}}, "hash": "66b701fef33780ca1855e71bc893711ca964070dd9dad858c4e6bb8a069656b3", "text": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. ", "start_char_idx": 33446, "end_char_idx": 33562, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "92787f47-1f73-4a61-8d9d-000c47ec75a0": {"__data__": {"id_": "92787f47-1f73-4a61-8d9d-000c47ec75a0", "embedding": null, "metadata": {"window": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n", "original_text": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b6491ac-10a1-4a1b-a2e4-6071e53b4337", "node_type": "1", "metadata": {"window": "And one of the TAs, Dan Ramage, \nactually collected a data set for me last week to use in the example later.  But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? ", "original_text": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from. "}, "hash": "66b701fef33780ca1855e71bc893711ca964070dd9dad858c4e6bb8a069656b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f9d255d-30d6-4f1f-9694-a993ac9fb1c3", "node_type": "1", "metadata": {"window": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it. ", "original_text": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n"}, "hash": "3d3f1a95a95d3d036b75fa904e1812f351aadb857be59e90936f6221eda7c8f9", "class_name": "RelatedNodeInfo"}}, "hash": "009b46198304b82263b804aa2aa12bdfae5be4ec10e436282cc8822e70570ef9", "text": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. ", "start_char_idx": 33562, "end_char_idx": 33713, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f9d255d-30d6-4f1f-9694-a993ac9fb1c3": {"__data__": {"id_": "4f9d255d-30d6-4f1f-9694-a993ac9fb1c3", "embedding": null, "metadata": {"window": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it. ", "original_text": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "92787f47-1f73-4a61-8d9d-000c47ec75a0", "node_type": "1", "metadata": {"window": "But suppose that \nyou go to collect statistics about how much hous es cost in a certain geographic area.  And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n", "original_text": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for. "}, "hash": "009b46198304b82263b804aa2aa12bdfae5be4ec10e436282cc8822e70570ef9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f92d030-6ba9-46d2-9756-52f544518590", "node_type": "1", "metadata": {"window": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n", "original_text": "So one thing you could do is look at this data and maybe put a straight  line to it. "}, "hash": "c77617c9694b45f02a9cb17120f9938079523398502828cdf5f2e218c88807f4", "class_name": "RelatedNodeInfo"}}, "hash": "3d3f1a95a95d3d036b75fa904e1812f351aadb857be59e90936f6221eda7c8f9", "text": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n", "start_char_idx": 33713, "end_char_idx": 33826, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f92d030-6ba9-46d2-9756-52f544518590": {"__data__": {"id_": "5f92d030-6ba9-46d2-9756-52f544518590", "embedding": null, "metadata": {"window": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n", "original_text": "So one thing you could do is look at this data and maybe put a straight  line to it. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f9d255d-30d6-4f1f-9694-a993ac9fb1c3", "node_type": "1", "metadata": {"window": "And \nDan, the TA, collected data from housing pr ices in Portland, Oregon.  So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it. ", "original_text": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n"}, "hash": "3d3f1a95a95d3d036b75fa904e1812f351aadb857be59e90936f6221eda7c8f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ca2e4da-aecb-43fb-9185-247a5c059b67", "node_type": "1", "metadata": {"window": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n", "original_text": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? "}, "hash": "8f072edcd67834e4574013689285f0fce8176b308d62e6a28bc59354677a8eb0", "class_name": "RelatedNodeInfo"}}, "hash": "c77617c9694b45f02a9cb17120f9938079523398502828cdf5f2e218c88807f4", "text": "So one thing you could do is look at this data and maybe put a straight  line to it. ", "start_char_idx": 33826, "end_char_idx": 33911, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6ca2e4da-aecb-43fb-9185-247a5c059b67": {"__data__": {"id_": "6ca2e4da-aecb-43fb-9185-247a5c059b67", "embedding": null, "metadata": {"window": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n", "original_text": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f92d030-6ba9-46d2-9756-52f544518590", "node_type": "1", "metadata": {"window": "So what you can do \nis let's say plot the square footage of the house against the list price of  the house, right, so \nyou collect data on a bunch of houses.  And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n", "original_text": "So one thing you could do is look at this data and maybe put a straight  line to it. "}, "hash": "c77617c9694b45f02a9cb17120f9938079523398502828cdf5f2e218c88807f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "233127e7-1d18-42da-83d2-0f5b3169a373", "node_type": "1", "metadata": {"window": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. ", "original_text": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n"}, "hash": "65c42ea16b715c5b70ed18d05912d434267b134f3e7784aa02ff10a81c63eaa6", "class_name": "RelatedNodeInfo"}}, "hash": "8f072edcd67834e4574013689285f0fce8176b308d62e6a28bc59354677a8eb0", "text": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? ", "start_char_idx": 33911, "end_char_idx": 34055, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "233127e7-1d18-42da-83d2-0f5b3169a373": {"__data__": {"id_": "233127e7-1d18-42da-83d2-0f5b3169a373", "embedding": null, "metadata": {"window": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. ", "original_text": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ca2e4da-aecb-43fb-9185-247a5c059b67", "node_type": "1", "metadata": {"window": "And let' s say you get a data set like this with \nhouses of different sizes that are li sted for different amounts of money.  \n Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n", "original_text": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right? "}, "hash": "8f072edcd67834e4574013689285f0fce8176b308d62e6a28bc59354677a8eb0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fb5e3eba-31b4-41da-96ea-cc4e2ea537db", "node_type": "1", "metadata": {"window": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n", "original_text": "Maybe I should put a quadratic function to it. "}, "hash": "f629cf30639120fbee2dc68b2c9caafd4ceb02d2e94df1bc1b33c93fe4b69434", "class_name": "RelatedNodeInfo"}}, "hash": "65c42ea16b715c5b70ed18d05912d434267b134f3e7784aa02ff10a81c63eaa6", "text": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n", "start_char_idx": 34055, "end_char_idx": 34192, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fb5e3eba-31b4-41da-96ea-cc4e2ea537db": {"__data__": {"id_": "fb5e3eba-31b4-41da-96ea-cc4e2ea537db", "embedding": null, "metadata": {"window": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n", "original_text": "Maybe I should put a quadratic function to it. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "233127e7-1d18-42da-83d2-0f5b3169a373", "node_type": "1", "metadata": {"window": "Now, let's say that I'm trying to sell a hous e in the same area as Portland, Oregon as \nwhere the data comes from.  Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. ", "original_text": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n"}, "hash": "65c42ea16b715c5b70ed18d05912d434267b134f3e7784aa02ff10a81c63eaa6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc1447ff-258a-40e2-a1c7-635500249f04", "node_type": "1", "metadata": {"window": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. ", "original_text": "Ma ybe that fits the data a little bit better. \n"}, "hash": "877cd2560357e024cee2b1ccc3e28fd6482e5ebee6371087ae3b81eba01d6126", "class_name": "RelatedNodeInfo"}}, "hash": "f629cf30639120fbee2dc68b2c9caafd4ceb02d2e94df1bc1b33c93fe4b69434", "text": "Maybe I should put a quadratic function to it. ", "start_char_idx": 34192, "end_char_idx": 34239, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc1447ff-258a-40e2-a1c7-635500249f04": {"__data__": {"id_": "fc1447ff-258a-40e2-a1c7-635500249f04", "embedding": null, "metadata": {"window": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. ", "original_text": "Ma ybe that fits the data a little bit better. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb5e3eba-31b4-41da-96ea-cc4e2ea537db", "node_type": "1", "metadata": {"window": "Let's say I have a hou se that's this size in square footage, and \nI want an algorithm to tell me about how much should I expect my house to sell for.  So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n", "original_text": "Maybe I should put a quadratic function to it. "}, "hash": "f629cf30639120fbee2dc68b2c9caafd4ceb02d2e94df1bc1b33c93fe4b69434", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f63144e-ec88-411a-a0fb-a886305105f7", "node_type": "1", "metadata": {"window": "So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n", "original_text": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n"}, "hash": "0a4f12a12e6fb9bc43ec2dd6199ddc6fdb97e90bb281878899df13dbc4d6e013", "class_name": "RelatedNodeInfo"}}, "hash": "877cd2560357e024cee2b1ccc3e28fd6482e5ebee6371087ae3b81eba01d6126", "text": "Ma ybe that fits the data a little bit better. \n", "start_char_idx": 34239, "end_char_idx": 34287, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9f63144e-ec88-411a-a0fb-a886305105f7": {"__data__": {"id_": "9f63144e-ec88-411a-a0fb-a886305105f7", "embedding": null, "metadata": {"window": "So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n", "original_text": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc1447ff-258a-40e2-a1c7-635500249f04", "node_type": "1", "metadata": {"window": "So there are lots of ways to do this, and some of you may have seen elements of what I'm \nabout to say before.  \n So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. ", "original_text": "Ma ybe that fits the data a little bit better. \n"}, "hash": "877cd2560357e024cee2b1ccc3e28fd6482e5ebee6371087ae3b81eba01d6126", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e405a364-12dc-45a2-972d-f4a81135e7f4", "node_type": "1", "metadata": {"window": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. ", "original_text": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. "}, "hash": "ff0af035b794f8233ef567fb5bce33e6175e19efe78ba176e1ca679aeb393c35", "class_name": "RelatedNodeInfo"}}, "hash": "0a4f12a12e6fb9bc43ec2dd6199ddc6fdb97e90bb281878899df13dbc4d6e013", "text": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n", "start_char_idx": 34287, "end_char_idx": 34373, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e405a364-12dc-45a2-972d-f4a81135e7f4": {"__data__": {"id_": "e405a364-12dc-45a2-972d-f4a81135e7f4", "embedding": null, "metadata": {"window": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. ", "original_text": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f63144e-ec88-411a-a0fb-a886305105f7", "node_type": "1", "metadata": {"window": "So one thing you could do is look at this data and maybe put a straight  line to it.  And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n", "original_text": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n"}, "hash": "0a4f12a12e6fb9bc43ec2dd6199ddc6fdb97e90bb281878899df13dbc4d6e013", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7fc85ab9-e8ac-45a6-8861-35dd6dc25ff5", "node_type": "1", "metadata": {"window": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n", "original_text": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n"}, "hash": "37cf3512823511238f4773f7c73fc52aad000c219bcd89481ae1abcbeded5f8d", "class_name": "RelatedNodeInfo"}}, "hash": "ff0af035b794f8233ef567fb5bce33e6175e19efe78ba176e1ca679aeb393c35", "text": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. ", "start_char_idx": 34373, "end_char_idx": 34510, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7fc85ab9-e8ac-45a6-8861-35dd6dc25ff5": {"__data__": {"id_": "7fc85ab9-e8ac-45a6-8861-35dd6dc25ff5", "embedding": null, "metadata": {"window": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n", "original_text": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e405a364-12dc-45a2-972d-f4a81135e7f4", "node_type": "1", "metadata": {"window": "And then \nif this is my house, you may then look at th e straight line and predict that my house is \ngonna go for about that much money, right?  Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. ", "original_text": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem. "}, "hash": "ff0af035b794f8233ef567fb5bce33e6175e19efe78ba176e1ca679aeb393c35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81b6366b-4a6d-482b-8da2-dcef2cb4998b", "node_type": "1", "metadata": {"window": "Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. ", "original_text": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. "}, "hash": "efe62d4649e19937d16243d3592db3dc4ff34a40681114d3c124403acf6f7e3a", "class_name": "RelatedNodeInfo"}}, "hash": "37cf3512823511238f4773f7c73fc52aad000c219bcd89481ae1abcbeded5f8d", "text": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n", "start_char_idx": 34510, "end_char_idx": 34779, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81b6366b-4a6d-482b-8da2-dcef2cb4998b": {"__data__": {"id_": "81b6366b-4a6d-482b-8da2-dcef2cb4998b", "embedding": null, "metadata": {"window": "Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. ", "original_text": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7fc85ab9-e8ac-45a6-8861-35dd6dc25ff5", "node_type": "1", "metadata": {"window": "Ther e are other decisions that we can make, \nwhich we'll talk about later, which is, well, what if I don' t wanna put a straight line? \n Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n", "original_text": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n"}, "hash": "37cf3512823511238f4773f7c73fc52aad000c219bcd89481ae1abcbeded5f8d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8fbe5fb7-5d72-458f-a803-318a4d623be7", "node_type": "1", "metadata": {"window": "Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . ", "original_text": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n"}, "hash": "59edb531b3120b32907adeee58381ee841981b55e05cc1e986dc7a09f17c2291", "class_name": "RelatedNodeInfo"}}, "hash": "efe62d4649e19937d16243d3592db3dc4ff34a40681114d3c124403acf6f7e3a", "text": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. ", "start_char_idx": 34779, "end_char_idx": 34953, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fbe5fb7-5d72-458f-a803-318a4d623be7": {"__data__": {"id_": "8fbe5fb7-5d72-458f-a803-318a4d623be7", "embedding": null, "metadata": {"window": "Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . ", "original_text": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81b6366b-4a6d-482b-8da2-dcef2cb4998b", "node_type": "1", "metadata": {"window": "Maybe I should put a quadratic function to it.  Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. ", "original_text": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses. "}, "hash": "efe62d4649e19937d16243d3592db3dc4ff34a40681114d3c124403acf6f7e3a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "560fe639-663c-40c1-ad8f-4bd5cedea4a8", "node_type": "1", "metadata": {"window": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. ", "original_text": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. "}, "hash": "64f3c1e936da8bfba140b2356af0b9870dac41cc38a2967df732c8386ffbc323", "class_name": "RelatedNodeInfo"}}, "hash": "59edb531b3120b32907adeee58381ee841981b55e05cc1e986dc7a09f17c2291", "text": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n", "start_char_idx": 34953, "end_char_idx": 35105, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "560fe639-663c-40c1-ad8f-4bd5cedea4a8": {"__data__": {"id_": "560fe639-663c-40c1-ad8f-4bd5cedea4a8", "embedding": null, "metadata": {"window": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. ", "original_text": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8fbe5fb7-5d72-458f-a803-318a4d623be7", "node_type": "1", "metadata": {"window": "Ma ybe that fits the data a little bit better. \n You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . ", "original_text": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n"}, "hash": "59edb531b3120b32907adeee58381ee841981b55e05cc1e986dc7a09f17c2291", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5be39312-f6a1-45f5-bce9-40f55948454d", "node_type": "1", "metadata": {"window": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n", "original_text": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n"}, "hash": "12654b841c363bd8e953d386cc4fdc6adb28124a784aadbdd237287a7a192d52", "class_name": "RelatedNodeInfo"}}, "hash": "64f3c1e936da8bfba140b2356af0b9870dac41cc38a2967df732c8386ffbc323", "text": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. ", "start_char_idx": 35105, "end_char_idx": 35215, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5be39312-f6a1-45f5-bce9-40f55948454d": {"__data__": {"id_": "5be39312-f6a1-45f5-bce9-40f55948454d", "embedding": null, "metadata": {"window": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n", "original_text": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "560fe639-663c-40c1-ad8f-4bd5cedea4a8", "node_type": "1", "metadata": {"window": "You notice if you do that, the price of my house goes up a bit, so that'd be nice.  \n\n And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. ", "original_text": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem. "}, "hash": "64f3c1e936da8bfba140b2356af0b9870dac41cc38a2967df732c8386ffbc323", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0e25442-e36c-4a65-a817-7c7ad165a7fb", "node_type": "1", "metadata": {"window": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n", "original_text": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. "}, "hash": "7ac1295f9b7bb605adea5060dc02774da15e6352a0003a65e76bd659f9151c90", "class_name": "RelatedNodeInfo"}}, "hash": "12654b841c363bd8e953d386cc4fdc6adb28124a784aadbdd237287a7a192d52", "text": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n", "start_char_idx": 35215, "end_char_idx": 35345, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d0e25442-e36c-4a65-a817-7c7ad165a7fb": {"__data__": {"id_": "d0e25442-e36c-4a65-a817-7c7ad165a7fb", "embedding": null, "metadata": {"window": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n", "original_text": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5be39312-f6a1-45f5-bce9-40f55948454d", "node_type": "1", "metadata": {"window": "And this sort of learning pr oblem of learning to predict hous ing prices is an example of \nwhat's called a supervised learning problem.  And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n", "original_text": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n"}, "hash": "12654b841c363bd8e953d386cc4fdc6adb28124a784aadbdd237287a7a192d52", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c258e92f-9976-47b2-bb00-85a1d4e4c87e", "node_type": "1", "metadata": {"window": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n", "original_text": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . "}, "hash": "a592fd82559002f381e7fd532c1ae4d0cca1867917ca670e113298ad69b0bbb3", "class_name": "RelatedNodeInfo"}}, "hash": "7ac1295f9b7bb605adea5060dc02774da15e6352a0003a65e76bd659f9151c90", "text": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. ", "start_char_idx": 35345, "end_char_idx": 35459, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c258e92f-9976-47b2-bb00-85a1d4e4c87e": {"__data__": {"id_": "c258e92f-9976-47b2-bb00-85a1d4e4c87e", "embedding": null, "metadata": {"window": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n", "original_text": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d0e25442-e36c-4a65-a817-7c7ad165a7fb", "node_type": "1", "metadata": {"window": "And the reason that it's called supervised \nlearning is because we're providing the al gorithm a data set of a bunch of square \nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \nactual prices of a number  of houses were, right?  \n So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n", "original_text": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems. "}, "hash": "7ac1295f9b7bb605adea5060dc02774da15e6352a0003a65e76bd659f9151c90", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bf3be2d7-0ffe-4c4e-821a-21ebb08c69d8", "node_type": "1", "metadata": {"window": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? ", "original_text": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. "}, "hash": "adbfd70a304b475a8333a8d1e36b22c95b0e231fa8284c57ef99ac064b9c2639", "class_name": "RelatedNodeInfo"}}, "hash": "a592fd82559002f381e7fd532c1ae4d0cca1867917ca670e113298ad69b0bbb3", "text": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . ", "start_char_idx": 35459, "end_char_idx": 35574, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf3be2d7-0ffe-4c4e-821a-21ebb08c69d8": {"__data__": {"id_": "bf3be2d7-0ffe-4c4e-821a-21ebb08c69d8", "embedding": null, "metadata": {"window": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? ", "original_text": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c258e92f-9976-47b2-bb00-85a1d4e4c87e", "node_type": "1", "metadata": {"window": "So we call this supervised learning because we're supervising the algorithm or, in other \nwords, we're giving the algorithm the, quote,  right answer for a number of houses.  And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n", "original_text": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous . "}, "hash": "a592fd82559002f381e7fd532c1ae4d0cca1867917ca670e113298ad69b0bbb3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b6556c8-8c54-48c4-ad26-159e2713f3b3", "node_type": "1", "metadata": {"window": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay? ", "original_text": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n"}, "hash": "e851997c0cb8cd8b127c48576ef4661028e75e5c8bc05627e6d2b9cd95d39a4c", "class_name": "RelatedNodeInfo"}}, "hash": "adbfd70a304b475a8333a8d1e36b22c95b0e231fa8284c57ef99ac064b9c2639", "text": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. ", "start_char_idx": 35574, "end_char_idx": 35729, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b6556c8-8c54-48c4-ad26-159e2713f3b3": {"__data__": {"id_": "6b6556c8-8c54-48c4-ad26-159e2713f3b3", "embedding": null, "metadata": {"window": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay? ", "original_text": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf3be2d7-0ffe-4c4e-821a-21ebb08c69d8", "node_type": "1", "metadata": {"window": "And \nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \nand to sort of give us more of the right answers, okay?  \n It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? ", "original_text": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with. "}, "hash": "adbfd70a304b475a8333a8d1e36b22c95b0e231fa8284c57ef99ac064b9c2639", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be5fc25b-491b-4caa-93fd-1543644d6d88", "node_type": "1", "metadata": {"window": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. ", "original_text": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n"}, "hash": "ecbbe0e2e441e96c37da354240415274e668b46137e3664dfb87e06d6fab12de", "class_name": "RelatedNodeInfo"}}, "hash": "e851997c0cb8cd8b127c48576ef4661028e75e5c8bc05627e6d2b9cd95d39a4c", "text": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n", "start_char_idx": 35729, "end_char_idx": 35884, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "be5fc25b-491b-4caa-93fd-1543644d6d88": {"__data__": {"id_": "be5fc25b-491b-4caa-93fd-1543644d6d88", "embedding": null, "metadata": {"window": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. ", "original_text": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b6556c8-8c54-48c4-ad26-159e2713f3b3", "node_type": "1", "metadata": {"window": "It turns out this specific exam ple that I drew here is an example of something called a \nregression problem.  And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay? ", "original_text": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n"}, "hash": "e851997c0cb8cd8b127c48576ef4661028e75e5c8bc05627e6d2b9cd95d39a4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20866efb-a8e8-4d1d-898e-96192bd3cb0f", "node_type": "1", "metadata": {"window": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n", "original_text": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n"}, "hash": "04eab4d797a395ee3cab75de85fca5c7521e1a07794d2b77d309bb71e9d5bf5f", "class_name": "RelatedNodeInfo"}}, "hash": "ecbbe0e2e441e96c37da354240415274e668b46137e3664dfb87e06d6fab12de", "text": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n", "start_char_idx": 35884, "end_char_idx": 35977, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20866efb-a8e8-4d1d-898e-96192bd3cb0f": {"__data__": {"id_": "20866efb-a8e8-4d1d-898e-96192bd3cb0f", "embedding": null, "metadata": {"window": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n", "original_text": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be5fc25b-491b-4caa-93fd-1543644d6d88", "node_type": "1", "metadata": {"window": "And the term regression sort of refers to the fact that the variable \nyou're trying to predict is a continuous value and price.  \n There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. ", "original_text": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n"}, "hash": "ecbbe0e2e441e96c37da354240415274e668b46137e3664dfb87e06d6fab12de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "de64ba66-3be1-4902-a820-51ab63ac5643", "node_type": "1", "metadata": {"window": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. ", "original_text": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? "}, "hash": "d2e9e36b405676227ba832e95ee2180fc4131cf0fe3cca77d03f2be76147e259", "class_name": "RelatedNodeInfo"}}, "hash": "04eab4d797a395ee3cab75de85fca5c7521e1a07794d2b77d309bb71e9d5bf5f", "text": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n", "start_char_idx": 35977, "end_char_idx": 36315, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de64ba66-3be1-4902-a820-51ab63ac5643": {"__data__": {"id_": "de64ba66-3be1-4902-a820-51ab63ac5643", "embedding": null, "metadata": {"window": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. ", "original_text": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20866efb-a8e8-4d1d-898e-96192bd3cb0f", "node_type": "1", "metadata": {"window": "There's another class of supervised learning problems which we'll talk about, which are \nclassification problems.  And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n", "original_text": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n"}, "hash": "04eab4d797a395ee3cab75de85fca5c7521e1a07794d2b77d309bb71e9d5bf5f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9aeaff09-d364-46dd-a6c9-a350dabf81a1", "node_type": "1", "metadata": {"window": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this. ", "original_text": "And that's 1 and that's \nzero, okay? "}, "hash": "2b8059fb226bc49748d4a02723814ad78898004ff23b8ea482cdf87a535cb9bd", "class_name": "RelatedNodeInfo"}}, "hash": "d2e9e36b405676227ba832e95ee2180fc4131cf0fe3cca77d03f2be76147e259", "text": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? ", "start_char_idx": 36315, "end_char_idx": 36476, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9aeaff09-d364-46dd-a6c9-a350dabf81a1": {"__data__": {"id_": "9aeaff09-d364-46dd-a6c9-a350dabf81a1", "embedding": null, "metadata": {"window": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this. ", "original_text": "And that's 1 and that's \nzero, okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "de64ba66-3be1-4902-a820-51ab63ac5643", "node_type": "1", "metadata": {"window": "And so, in a classifi cation problem, the variab le you're trying to \npredict is discreet rather than continuous .  So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. ", "original_text": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t? "}, "hash": "d2e9e36b405676227ba832e95ee2180fc4131cf0fe3cca77d03f2be76147e259", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "087e092c-d370-4dfd-a980-6ab272206c3f", "node_type": "1", "metadata": {"window": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now. ", "original_text": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. "}, "hash": "8cc5458e92d0cc9a03620f101388bda5d76922013495738923af9239f1d05887", "class_name": "RelatedNodeInfo"}}, "hash": "2b8059fb226bc49748d4a02723814ad78898004ff23b8ea482cdf87a535cb9bd", "text": "And that's 1 and that's \nzero, okay? ", "start_char_idx": 36476, "end_char_idx": 36513, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "087e092c-d370-4dfd-a980-6ab272206c3f": {"__data__": {"id_": "087e092c-d370-4dfd-a980-6ab272206c3f", "embedding": null, "metadata": {"window": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now. ", "original_text": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9aeaff09-d364-46dd-a6c9-a350dabf81a1", "node_type": "1", "metadata": {"window": "So as one specific example \u2014 so actually a \nstandard data set you can download online [i naudible] that lots of machine learning \npeople have played with.  Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this. ", "original_text": "And that's 1 and that's \nzero, okay? "}, "hash": "2b8059fb226bc49748d4a02723814ad78898004ff23b8ea482cdf87a535cb9bd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da8efc37-025e-4b0a-9aa2-794a383b9d07", "node_type": "1", "metadata": {"window": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n", "original_text": "It 's either zero or 1.  \n"}, "hash": "f620e731b36871b288b0ae19f801955b499ace2982e6636c7c1a11776f8897ab", "class_name": "RelatedNodeInfo"}}, "hash": "8cc5458e92d0cc9a03620f101388bda5d76922013495738923af9239f1d05887", "text": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. ", "start_char_idx": 36513, "end_char_idx": 36633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "da8efc37-025e-4b0a-9aa2-794a383b9d07": {"__data__": {"id_": "da8efc37-025e-4b0a-9aa2-794a383b9d07", "embedding": null, "metadata": {"window": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n", "original_text": "It 's either zero or 1.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "087e092c-d370-4dfd-a980-6ab272206c3f", "node_type": "1", "metadata": {"window": "Let's say you collect  a data set on breast cancer tumors, and you \nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \n Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now. ", "original_text": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value. "}, "hash": "8cc5458e92d0cc9a03620f101388bda5d76922013495738923af9239f1d05887", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "72ad0e16-f164-4fa7-b74e-e089b6f92717", "node_type": "1", "metadata": {"window": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. ", "original_text": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. "}, "hash": "9db80a4139a0f60c2d972b050a7239326aa142ff43363866894dd303552c36e8", "class_name": "RelatedNodeInfo"}}, "hash": "f620e731b36871b288b0ae19f801955b499ace2982e6636c7c1a11776f8897ab", "text": "It 's either zero or 1.  \n", "start_char_idx": 36633, "end_char_idx": 36659, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "72ad0e16-f164-4fa7-b74e-e089b6f92717": {"__data__": {"id_": "72ad0e16-f164-4fa7-b74e-e089b6f92717", "embedding": null, "metadata": {"window": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. ", "original_text": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da8efc37-025e-4b0a-9aa2-794a383b9d07", "node_type": "1", "metadata": {"window": "Malignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \n So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n", "original_text": "It 's either zero or 1.  \n"}, "hash": "f620e731b36871b288b0ae19f801955b499ace2982e6636c7c1a11776f8897ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "57c667c7-0943-47ad-a4f7-ffde6251281f", "node_type": "1", "metadata": {"window": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. ", "original_text": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this. "}, "hash": "046753b58ce5c131f9175045d36872f4bfea25372065da19b0d5fb399dc45501", "class_name": "RelatedNodeInfo"}}, "hash": "9db80a4139a0f60c2d972b050a7239326aa142ff43363866894dd303552c36e8", "text": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. ", "start_char_idx": 36659, "end_char_idx": 36899, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "57c667c7-0943-47ad-a4f7-ffde6251281f": {"__data__": {"id_": "57c667c7-0943-47ad-a4f7-ffde6251281f", "embedding": null, "metadata": {"window": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. ", "original_text": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72ad0e16-f164-4fa7-b74e-e089b6f92717", "node_type": "1", "metadata": {"window": "So we collect some number of features, some  number of properties of these tumors, and \nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're \ngoing to look at the size of the tumor and depe nding on the size of the tumor, we'll try to \nfigure out whether or not the tu mor is malignant or benign.  \n So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. ", "original_text": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign. "}, "hash": "9db80a4139a0f60c2d972b050a7239326aa142ff43363866894dd303552c36e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6692aadd-d554-4ee9-aef6-231be019b66c", "node_type": "1", "metadata": {"window": "And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n", "original_text": "I'm gonna part this data set in a \nslightly different way now. "}, "hash": "1f6396c1b4fd41c07fd6c1e8506b51f1363ca262748a0d43cf27b31499350321", "class_name": "RelatedNodeInfo"}}, "hash": "046753b58ce5c131f9175045d36872f4bfea25372065da19b0d5fb399dc45501", "text": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this. ", "start_char_idx": 36899, "end_char_idx": 36994, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6692aadd-d554-4ee9-aef6-231be019b66c": {"__data__": {"id_": "6692aadd-d554-4ee9-aef6-231be019b66c", "embedding": null, "metadata": {"window": "And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n", "original_text": "I'm gonna part this data set in a \nslightly different way now. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "57c667c7-0943-47ad-a4f7-ffde6251281f", "node_type": "1", "metadata": {"window": "So the tumor is either malignant or benign, and so  the variable in the Y axis is either zero \nor 1, and so your data set ma y look something like that, righ t?  And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. ", "original_text": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this. "}, "hash": "046753b58ce5c131f9175045d36872f4bfea25372065da19b0d5fb399dc45501", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84de6c86-6af8-41a6-8181-6dd5916ca4a6", "node_type": "1", "metadata": {"window": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? ", "original_text": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n"}, "hash": "b82f603a2eb38005d80ccd423cd0db28dadcda94dcbba922d023fc135ae726b9", "class_name": "RelatedNodeInfo"}}, "hash": "1f6396c1b4fd41c07fd6c1e8506b51f1363ca262748a0d43cf27b31499350321", "text": "I'm gonna part this data set in a \nslightly different way now. ", "start_char_idx": 36994, "end_char_idx": 37057, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "84de6c86-6af8-41a6-8181-6dd5916ca4a6": {"__data__": {"id_": "84de6c86-6af8-41a6-8181-6dd5916ca4a6", "embedding": null, "metadata": {"window": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? ", "original_text": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6692aadd-d554-4ee9-aef6-231be019b66c", "node_type": "1", "metadata": {"window": "And that's 1 and that's \nzero, okay?  And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n", "original_text": "I'm gonna part this data set in a \nslightly different way now. "}, "hash": "1f6396c1b4fd41c07fd6c1e8506b51f1363ca262748a0d43cf27b31499350321", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "18d709f6-df82-43db-bc32-711bacb2f7a8", "node_type": "1", "metadata": {"window": "It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n", "original_text": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. "}, "hash": "f2b66b58cdee9996bd28402b1b369d64dc94cba7a9f3d246cc7800ab3cd8e1e4", "class_name": "RelatedNodeInfo"}}, "hash": "b82f603a2eb38005d80ccd423cd0db28dadcda94dcbba922d023fc135ae726b9", "text": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n", "start_char_idx": 37057, "end_char_idx": 37161, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "18d709f6-df82-43db-bc32-711bacb2f7a8": {"__data__": {"id_": "18d709f6-df82-43db-bc32-711bacb2f7a8", "embedding": null, "metadata": {"window": "It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n", "original_text": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84de6c86-6af8-41a6-8181-6dd5916ca4a6", "node_type": "1", "metadata": {"window": "And so this is an example of a classification problem where the variable \nyou're trying to predict is a discreet value.  It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? ", "original_text": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n"}, "hash": "b82f603a2eb38005d80ccd423cd0db28dadcda94dcbba922d023fc135ae726b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca94a2cc-7c2a-4849-8ff1-87eb54daae6e", "node_type": "1", "metadata": {"window": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. ", "original_text": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. "}, "hash": "d5c763c42ab07898d86a2d35063a71c0233a1adb182414ea986aba522c1c596f", "class_name": "RelatedNodeInfo"}}, "hash": "f2b66b58cdee9996bd28402b1b369d64dc94cba7a9f3d246cc7800ab3cd8e1e4", "text": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. ", "start_char_idx": 37161, "end_char_idx": 37261, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca94a2cc-7c2a-4849-8ff1-87eb54daae6e": {"__data__": {"id_": "ca94a2cc-7c2a-4849-8ff1-87eb54daae6e", "embedding": null, "metadata": {"window": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. ", "original_text": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18d709f6-df82-43db-bc32-711bacb2f7a8", "node_type": "1", "metadata": {"window": "It 's either zero or 1.  \n And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n", "original_text": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors. "}, "hash": "f2b66b58cdee9996bd28402b1b369d64dc94cba7a9f3d246cc7800ab3cd8e1e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "692f7dd1-740b-42a7-aebb-42688ec8a792", "node_type": "1", "metadata": {"window": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . ", "original_text": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n"}, "hash": "ce90bcb69a6bbdcc288ca472bc5b28011fbc24db62d0eb64b820661d8dec0810", "class_name": "RelatedNodeInfo"}}, "hash": "d5c763c42ab07898d86a2d35063a71c0233a1adb182414ea986aba522c1c596f", "text": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. ", "start_char_idx": 37261, "end_char_idx": 37454, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "692f7dd1-740b-42a7-aebb-42688ec8a792": {"__data__": {"id_": "692f7dd1-740b-42a7-aebb-42688ec8a792", "embedding": null, "metadata": {"window": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . ", "original_text": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca94a2cc-7c2a-4849-8ff1-87eb54daae6e", "node_type": "1", "metadata": {"window": "And in fact, more generally, there will be many learning problems where we'll have more \nthan one input variable, more than one input f eature and use more than one variable to try \nto predict, say, whether a tumor is malignant  or benign.  So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. ", "original_text": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor. "}, "hash": "d5c763c42ab07898d86a2d35063a71c0233a1adb182414ea986aba522c1c596f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "418d1b80-a717-4020-be1a-14a37375a174", "node_type": "1", "metadata": {"window": "I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n", "original_text": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? "}, "hash": "6621d82fb1e80cc2c9ddf01f51e3ec1c9f612606715d91b404c21c0fbca9d965", "class_name": "RelatedNodeInfo"}}, "hash": "ce90bcb69a6bbdcc288ca472bc5b28011fbc24db62d0eb64b820661d8dec0810", "text": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n", "start_char_idx": 37454, "end_char_idx": 37576, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "418d1b80-a717-4020-be1a-14a37375a174": {"__data__": {"id_": "418d1b80-a717-4020-be1a-14a37375a174", "embedding": null, "metadata": {"window": "I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n", "original_text": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "692f7dd1-740b-42a7-aebb-42688ec8a792", "node_type": "1", "metadata": {"window": "So, for example, continuing with \nthis, you may instead have a data  set that looks like this.  I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . ", "original_text": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n"}, "hash": "ce90bcb69a6bbdcc288ca472bc5b28011fbc24db62d0eb64b820661d8dec0810", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e680e814-8244-4e03-84fb-556ed89daa91", "node_type": "1", "metadata": {"window": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? ", "original_text": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n"}, "hash": "599d80f3c5cb74a6823438773c89757e6981927097c91795fd0bb8561281aa00", "class_name": "RelatedNodeInfo"}}, "hash": "6621d82fb1e80cc2c9ddf01f51e3ec1c9f612606715d91b404c21c0fbca9d965", "text": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? ", "start_char_idx": 37576, "end_char_idx": 37899, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e680e814-8244-4e03-84fb-556ed89daa91": {"__data__": {"id_": "e680e814-8244-4e03-84fb-556ed89daa91", "embedding": null, "metadata": {"window": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? ", "original_text": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "418d1b80-a717-4020-be1a-14a37375a174", "node_type": "1", "metadata": {"window": "I'm gonna part this data set in a \nslightly different way now.  And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n", "original_text": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y? "}, "hash": "6621d82fb1e80cc2c9ddf01f51e3ec1c9f612606715d91b404c21c0fbca9d965", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c9d8608-7408-429f-898b-cbe4de1c8846", "node_type": "1", "metadata": {"window": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space. ", "original_text": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. "}, "hash": "b130e450deccf85f32793ed6aba5c54928a957a22fedc8ea7933cca7c74425d7", "class_name": "RelatedNodeInfo"}}, "hash": "599d80f3c5cb74a6823438773c89757e6981927097c91795fd0bb8561281aa00", "text": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n", "start_char_idx": 37899, "end_char_idx": 38009, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5c9d8608-7408-429f-898b-cbe4de1c8846": {"__data__": {"id_": "5c9d8608-7408-429f-898b-cbe4de1c8846", "embedding": null, "metadata": {"window": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space. ", "original_text": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e680e814-8244-4e03-84fb-556ed89daa91", "node_type": "1", "metadata": {"window": "And I'm making this  data set look much cleaner than it really \nis in reality for illustration, okay?  \n For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? ", "original_text": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n"}, "hash": "599d80f3c5cb74a6823438773c89757e6981927097c91795fd0bb8561281aa00", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab63e732-32d1-4e6b-a901-845538228cdc", "node_type": "1", "metadata": {"window": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right? ", "original_text": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . "}, "hash": "5a6367a2ddb49be08830ccbc4f540e1b1408a6208d13241e3cab1cbb4a5fb706", "class_name": "RelatedNodeInfo"}}, "hash": "b130e450deccf85f32793ed6aba5c54928a957a22fedc8ea7933cca7c74425d7", "text": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. ", "start_char_idx": 38009, "end_char_idx": 38288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab63e732-32d1-4e6b-a901-845538228cdc": {"__data__": {"id_": "ab63e732-32d1-4e6b-a901-845538228cdc", "embedding": null, "metadata": {"window": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right? ", "original_text": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c9d8608-7408-429f-898b-cbe4de1c8846", "node_type": "1", "metadata": {"window": "For example, maybe the crosses indicate ma lignant tumors and the \"O\"s may indicate \nbenign tumors.  And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space. ", "original_text": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize. "}, "hash": "b130e450deccf85f32793ed6aba5c54928a957a22fedc8ea7933cca7c74425d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f06b19c-3f90-4eb3-b89b-a1fa8cc7ebe0", "node_type": "1", "metadata": {"window": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n", "original_text": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n"}, "hash": "add437646668e48ae7f48a4897b0fa6405ecfd7c0e259ebba6d21f7ff8fa13b6", "class_name": "RelatedNodeInfo"}}, "hash": "5a6367a2ddb49be08830ccbc4f540e1b1408a6208d13241e3cab1cbb4a5fb706", "text": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . ", "start_char_idx": 38288, "end_char_idx": 38412, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f06b19c-3f90-4eb3-b89b-a1fa8cc7ebe0": {"__data__": {"id_": "4f06b19c-3f90-4eb3-b89b-a1fa8cc7ebe0", "embedding": null, "metadata": {"window": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n", "original_text": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab63e732-32d1-4e6b-a901-845538228cdc", "node_type": "1", "metadata": {"window": "And so you may have a data se t comprising patients of  different ages and \nwho have different tumor sizes and where a cross indicates a mali gnant tumor, and an \n\"O\" indicates a benign tumor.  And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right? ", "original_text": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features . "}, "hash": "5a6367a2ddb49be08830ccbc4f540e1b1408a6208d13241e3cab1cbb4a5fb706", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c24bce16-a880-448c-9a25-ea7c4e148edc", "node_type": "1", "metadata": {"window": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. ", "original_text": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? "}, "hash": "19f962cd27253f2a7ea4139525046170de5942b4b6bd63948d71a884932a4177", "class_name": "RelatedNodeInfo"}}, "hash": "add437646668e48ae7f48a4897b0fa6405ecfd7c0e259ebba6d21f7ff8fa13b6", "text": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n", "start_char_idx": 38412, "end_char_idx": 38635, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c24bce16-a880-448c-9a25-ea7c4e148edc": {"__data__": {"id_": "c24bce16-a880-448c-9a25-ea7c4e148edc", "embedding": null, "metadata": {"window": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. ", "original_text": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f06b19c-3f90-4eb3-b89b-a1fa8cc7ebe0", "node_type": "1", "metadata": {"window": "And you may want  an algorithm to learn to predict, given a \nnew patient, whether their tumo r is malignant or benign.  \n\n So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n", "original_text": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n"}, "hash": "add437646668e48ae7f48a4897b0fa6405ecfd7c0e259ebba6d21f7ff8fa13b6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3103ed96-c9cf-4e27-9f0b-b253d5a1dc94", "node_type": "1", "metadata": {"window": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? ", "original_text": "Our plots here are two-dime nsional space. "}, "hash": "c919ed73177d2e686c2d9fd3f26880bda5548f55c31d6143a221a2a2015232f6", "class_name": "RelatedNodeInfo"}}, "hash": "19f962cd27253f2a7ea4139525046170de5942b4b6bd63948d71a884932a4177", "text": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? ", "start_char_idx": 38635, "end_char_idx": 38921, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3103ed96-c9cf-4e27-9f0b-b253d5a1dc94": {"__data__": {"id_": "3103ed96-c9cf-4e27-9f0b-b253d5a1dc94", "embedding": null, "metadata": {"window": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? ", "original_text": "Our plots here are two-dime nsional space. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c24bce16-a880-448c-9a25-ea7c4e148edc", "node_type": "1", "metadata": {"window": "So, for example, what a learning algorithm ma y do is maybe come in and decide that a \nstraight line like that separates the two classes of tumors really well, and so if you have a \nnew patient who's age and tumor size fall over there, then the algorithm may predict that \nthe tumor is benign rather than malignant, oka y?  So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. ", "original_text": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space? "}, "hash": "19f962cd27253f2a7ea4139525046170de5942b4b6bd63948d71a884932a4177", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f0d9448c-3ff0-4712-90a5-5fad151780c4", "node_type": "1", "metadata": {"window": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers. ", "original_text": "I can't plot you an infinite \ndimensional space, right? "}, "hash": "01ef874c7ee4bedd8036d4fe794385e6ccc063e841f21658aa7e8ebf996611d1", "class_name": "RelatedNodeInfo"}}, "hash": "c919ed73177d2e686c2d9fd3f26880bda5548f55c31d6143a221a2a2015232f6", "text": "Our plots here are two-dime nsional space. ", "start_char_idx": 38921, "end_char_idx": 38964, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f0d9448c-3ff0-4712-90a5-5fad151780c4": {"__data__": {"id_": "f0d9448c-3ff0-4712-90a5-5fad151780c4", "embedding": null, "metadata": {"window": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers. ", "original_text": "I can't plot you an infinite \ndimensional space, right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3103ed96-c9cf-4e27-9f0b-b253d5a1dc94", "node_type": "1", "metadata": {"window": "So this is just another example of \nanother supervised learning problem and another classification problem.  \n And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? ", "original_text": "Our plots here are two-dime nsional space. "}, "hash": "c919ed73177d2e686c2d9fd3f26880bda5548f55c31d6143a221a2a2015232f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eeb60c27-6864-4a27-8bf2-8f2d857ba9ae", "node_type": "1", "metadata": {"window": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace? ", "original_text": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n"}, "hash": "c4d3f5118a726147f64a44aed66f17657c5eaf7d7c196106d17e7ad3ea024a00", "class_name": "RelatedNodeInfo"}}, "hash": "01ef874c7ee4bedd8036d4fe794385e6ccc063e841f21658aa7e8ebf996611d1", "text": "I can't plot you an infinite \ndimensional space, right? ", "start_char_idx": 38964, "end_char_idx": 39020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eeb60c27-6864-4a27-8bf2-8f2d857ba9ae": {"__data__": {"id_": "eeb60c27-6864-4a27-8bf2-8f2d857ba9ae", "embedding": null, "metadata": {"window": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace? ", "original_text": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f0d9448c-3ff0-4712-90a5-5fad151780c4", "node_type": "1", "metadata": {"window": "And so it turns out that one of the issues we' ll talk about later in this class is in this \nspecific example, we're going to try to predic t whether a tumor is malignant or benign \nbased on two features or based on two inputs, namely the age of the patient and the tumor \nsize.  It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers. ", "original_text": "I can't plot you an infinite \ndimensional space, right? "}, "hash": "01ef874c7ee4bedd8036d4fe794385e6ccc063e841f21658aa7e8ebf996611d1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7afa542-95d0-421b-bd0c-56e3954aad6a", "node_type": "1", "metadata": {"window": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n", "original_text": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. "}, "hash": "a6ccf01a00c3adae25ac853d88882d7b64936b6c0cde0e9798051d53ccd75df7", "class_name": "RelatedNodeInfo"}}, "hash": "c4d3f5118a726147f64a44aed66f17657c5eaf7d7c196106d17e7ad3ea024a00", "text": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n", "start_char_idx": 39020, "end_char_idx": 39336, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c7afa542-95d0-421b-bd0c-56e3954aad6a": {"__data__": {"id_": "c7afa542-95d0-421b-bd0c-56e3954aad6a", "embedding": null, "metadata": {"window": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n", "original_text": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eeb60c27-6864-4a27-8bf2-8f2d857ba9ae", "node_type": "1", "metadata": {"window": "It turns out that when you look at a real  data set, you find th at learning algorithms \noften use other sets of features .  In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace? ", "original_text": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n"}, "hash": "c4d3f5118a726147f64a44aed66f17657c5eaf7d7c196106d17e7ad3ea024a00", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "11d94d92-0455-40a1-99ac-13c774d3355a", "node_type": "1", "metadata": {"window": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see. ", "original_text": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? "}, "hash": "11417dc76e6a6a4091e44c1de3b9ac875a9c6f87222e6c14652181987916eb96", "class_name": "RelatedNodeInfo"}}, "hash": "a6ccf01a00c3adae25ac853d88882d7b64936b6c0cde0e9798051d53ccd75df7", "text": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. ", "start_char_idx": 39336, "end_char_idx": 39464, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "11d94d92-0455-40a1-99ac-13c774d3355a": {"__data__": {"id_": "11d94d92-0455-40a1-99ac-13c774d3355a", "embedding": null, "metadata": {"window": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see. ", "original_text": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7afa542-95d0-421b-bd0c-56e3954aad6a", "node_type": "1", "metadata": {"window": "In the breast cancer data ex ample, you also use properties \nof the tumors, like clump thic kness, uniformity of cell size, uniformity of cell shape, \n[inaudible] adhesion and so on, so va rious other medical properties.  \n And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n", "original_text": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms. "}, "hash": "a6ccf01a00c3adae25ac853d88882d7b64936b6c0cde0e9798051d53ccd75df7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41540f32-0ae6-4666-b963-634be7e46146", "node_type": "1", "metadata": {"window": "Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning. ", "original_text": "You don't have an infinite amount of computers. "}, "hash": "e8137a0db6057487260f3b0d60c52cd2e82a85b670b179cae80e4424b093b7ea", "class_name": "RelatedNodeInfo"}}, "hash": "11417dc76e6a6a4091e44c1de3b9ac875a9c6f87222e6c14652181987916eb96", "text": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? ", "start_char_idx": 39464, "end_char_idx": 39610, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "41540f32-0ae6-4666-b963-634be7e46146": {"__data__": {"id_": "41540f32-0ae6-4666-b963-634be7e46146", "embedding": null, "metadata": {"window": "Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning. ", "original_text": "You don't have an infinite amount of computers. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "11d94d92-0455-40a1-99ac-13c774d3355a", "node_type": "1", "metadata": {"window": "And one of the most interesting things we'll ta lk about later this quarter is what if your \ndata doesn't lie in a two-dimensional or th ree-dimensional or sort of even a finite \ndimensional space, but is it possible \u2014 what if your data actually lies in an infinite \ndimensional space?  Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see. ", "original_text": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory? "}, "hash": "11417dc76e6a6a4091e44c1de3b9ac875a9c6f87222e6c14652181987916eb96", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6dea187-d1ab-40fe-8785-25acdf617b8d", "node_type": "1", "metadata": {"window": "I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory. ", "original_text": "How do you even represent a \npoint that lies in an infinite dimensional sp ace? "}, "hash": "a9f97362c8d9f4fef407970d45212e9bb7b60e494fa4bc0283cbf2a3daf3bc60", "class_name": "RelatedNodeInfo"}}, "hash": "e8137a0db6057487260f3b0d60c52cd2e82a85b670b179cae80e4424b093b7ea", "text": "You don't have an infinite amount of computers. ", "start_char_idx": 39610, "end_char_idx": 39658, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f6dea187-d1ab-40fe-8785-25acdf617b8d": {"__data__": {"id_": "f6dea187-d1ab-40fe-8785-25acdf617b8d", "embedding": null, "metadata": {"window": "I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory. ", "original_text": "How do you even represent a \npoint that lies in an infinite dimensional sp ace? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "41540f32-0ae6-4666-b963-634be7e46146", "node_type": "1", "metadata": {"window": "Our plots here are two-dime nsional space.  I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning. ", "original_text": "You don't have an infinite amount of computers. "}, "hash": "e8137a0db6057487260f3b0d60c52cd2e82a85b670b179cae80e4424b093b7ea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "144e7f35-12a9-446f-93da-e71c4e088046", "node_type": "1", "metadata": {"window": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? ", "original_text": "We'll talk about that when we get to \nsupport vector machines, okay?  \n"}, "hash": "dc5676023a4c780889fb08b2506227b025f56a2fc49cbda8e6aefec52c9e74f6", "class_name": "RelatedNodeInfo"}}, "hash": "a9f97362c8d9f4fef407970d45212e9bb7b60e494fa4bc0283cbf2a3daf3bc60", "text": "How do you even represent a \npoint that lies in an infinite dimensional sp ace? ", "start_char_idx": 39658, "end_char_idx": 39738, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "144e7f35-12a9-446f-93da-e71c4e088046": {"__data__": {"id_": "144e7f35-12a9-446f-93da-e71c4e088046", "embedding": null, "metadata": {"window": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? ", "original_text": "We'll talk about that when we get to \nsupport vector machines, okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6dea187-d1ab-40fe-8785-25acdf617b8d", "node_type": "1", "metadata": {"window": "I can't plot you an infinite \ndimensional space, right?  And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory. ", "original_text": "How do you even represent a \npoint that lies in an infinite dimensional sp ace? "}, "hash": "a9f97362c8d9f4fef407970d45212e9bb7b60e494fa4bc0283cbf2a3daf3bc60", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8550c8e9-fd10-457b-a1b0-bd30e395d05d", "node_type": "1", "metadata": {"window": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. ", "original_text": "So let's see. "}, "hash": "d5b9ead188aa957d53c28487fca0be1a9b7aa2958446d60f6340c76eb106edcc", "class_name": "RelatedNodeInfo"}}, "hash": "dc5676023a4c780889fb08b2506227b025f56a2fc49cbda8e6aefec52c9e74f6", "text": "We'll talk about that when we get to \nsupport vector machines, okay?  \n", "start_char_idx": 39738, "end_char_idx": 39809, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8550c8e9-fd10-457b-a1b0-bd30e395d05d": {"__data__": {"id_": "8550c8e9-fd10-457b-a1b0-bd30e395d05d", "embedding": null, "metadata": {"window": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. ", "original_text": "So let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "144e7f35-12a9-446f-93da-e71c4e088046", "node_type": "1", "metadata": {"window": "And so it turns out that one of the most successful classes of \nmachine learning algorithms \u2014 some may call support vector machines \u2014 actually takes \ndata and maps data to an infinite dimensi onal space and then does classification using not \ntwo features like I've done  here, but an infinite number of features.  \n And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? ", "original_text": "We'll talk about that when we get to \nsupport vector machines, okay?  \n"}, "hash": "dc5676023a4c780889fb08b2506227b025f56a2fc49cbda8e6aefec52c9e74f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "36ecde01-ba9b-4092-99be-c9577624eacb", "node_type": "1", "metadata": {"window": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n", "original_text": "So that was supervised learning. "}, "hash": "4e53a77b54ee8e828849ac8d0b28227c15f7c3d6fa02b4664edabcc8d5dbc146", "class_name": "RelatedNodeInfo"}}, "hash": "d5b9ead188aa957d53c28487fca0be1a9b7aa2958446d60f6340c76eb106edcc", "text": "So let's see. ", "start_char_idx": 27181, "end_char_idx": 27195, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "36ecde01-ba9b-4092-99be-c9577624eacb": {"__data__": {"id_": "36ecde01-ba9b-4092-99be-c9577624eacb", "embedding": null, "metadata": {"window": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n", "original_text": "So that was supervised learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8550c8e9-fd10-457b-a1b0-bd30e395d05d", "node_type": "1", "metadata": {"window": "And that will actually be one of the most fa scinating things we talk about when we go \ndeeply into classification al gorithms.  And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. ", "original_text": "So let's see. "}, "hash": "d5b9ead188aa957d53c28487fca0be1a9b7aa2958446d60f6340c76eb106edcc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "24d7b725-95bb-431f-a966-3641b5ada72e", "node_type": "1", "metadata": {"window": "You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty. ", "original_text": "The second of the four major topics of this \nclass will be learning theory. "}, "hash": "edfb22834a546e27d2bd106c4345a0f040948b61540708d080e7cad866339303", "class_name": "RelatedNodeInfo"}}, "hash": "4e53a77b54ee8e828849ac8d0b28227c15f7c3d6fa02b4664edabcc8d5dbc146", "text": "So that was supervised learning. ", "start_char_idx": 39823, "end_char_idx": 39856, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24d7b725-95bb-431f-a966-3641b5ada72e": {"__data__": {"id_": "24d7b725-95bb-431f-a966-3641b5ada72e", "embedding": null, "metadata": {"window": "You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty. ", "original_text": "The second of the four major topics of this \nclass will be learning theory. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36ecde01-ba9b-4092-99be-c9577624eacb", "node_type": "1", "metadata": {"window": "And it's actually an in teresting question, right, so \nthink about how do you even represent an in finite dimensional vector in computer \nmemory?  You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n", "original_text": "So that was supervised learning. "}, "hash": "4e53a77b54ee8e828849ac8d0b28227c15f7c3d6fa02b4664edabcc8d5dbc146", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "339b4c76-d2dd-4929-ae07-ddd75afcf4bd", "node_type": "1", "metadata": {"window": "How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n", "original_text": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? "}, "hash": "64ad6e01bec688ec42fed333fa9ca77e3f68e66c1a682b96bc0e692a6e52f7d6", "class_name": "RelatedNodeInfo"}}, "hash": "edfb22834a546e27d2bd106c4345a0f040948b61540708d080e7cad866339303", "text": "The second of the four major topics of this \nclass will be learning theory. ", "start_char_idx": 39856, "end_char_idx": 39932, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "339b4c76-d2dd-4929-ae07-ddd75afcf4bd": {"__data__": {"id_": "339b4c76-d2dd-4929-ae07-ddd75afcf4bd", "embedding": null, "metadata": {"window": "How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n", "original_text": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "24d7b725-95bb-431f-a966-3641b5ada72e", "node_type": "1", "metadata": {"window": "You don't have an infinite amount of computers.  How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty. ", "original_text": "The second of the four major topics of this \nclass will be learning theory. "}, "hash": "edfb22834a546e27d2bd106c4345a0f040948b61540708d080e7cad866339303", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef2b315b-f5e5-4764-9346-44401deaa9e6", "node_type": "1", "metadata": {"window": "We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? ", "original_text": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. "}, "hash": "329c11a7fd5e2321ed084c10c843b0b10e7f77e56dd13d3690642ad65605af21", "class_name": "RelatedNodeInfo"}}, "hash": "64ad6e01bec688ec42fed333fa9ca77e3f68e66c1a682b96bc0e692a6e52f7d6", "text": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? ", "start_char_idx": 39932, "end_char_idx": 40145, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ef2b315b-f5e5-4764-9346-44401deaa9e6": {"__data__": {"id_": "ef2b315b-f5e5-4764-9346-44401deaa9e6", "embedding": null, "metadata": {"window": "We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? ", "original_text": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "339b4c76-d2dd-4929-ae07-ddd75afcf4bd", "node_type": "1", "metadata": {"window": "How do you even represent a \npoint that lies in an infinite dimensional sp ace?  We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n", "original_text": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right? "}, "hash": "64ad6e01bec688ec42fed333fa9ca77e3f68e66c1a682b96bc0e692a6e52f7d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "926d456f-2d6d-4932-be8f-22be58c213a9", "node_type": "1", "metadata": {"window": "So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes. ", "original_text": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n"}, "hash": "ac3c1f742d717b891e7c2a8a06103a877d4e6f71b1b8b9bd15c8b64f8667dd91", "class_name": "RelatedNodeInfo"}}, "hash": "329c11a7fd5e2321ed084c10c843b0b10e7f77e56dd13d3690642ad65605af21", "text": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. ", "start_char_idx": 40145, "end_char_idx": 40339, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "926d456f-2d6d-4932-be8f-22be58c213a9": {"__data__": {"id_": "926d456f-2d6d-4932-be8f-22be58c213a9", "embedding": null, "metadata": {"window": "So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes. ", "original_text": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef2b315b-f5e5-4764-9346-44401deaa9e6", "node_type": "1", "metadata": {"window": "We'll talk about that when we get to \nsupport vector machines, okay?  \n So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? ", "original_text": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe. "}, "hash": "329c11a7fd5e2321ed084c10c843b0b10e7f77e56dd13d3690642ad65605af21", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d64b4e76-312b-4831-b984-b3408a12cea6", "node_type": "1", "metadata": {"window": "So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? ", "original_text": "In this class, I'm not gonna do any truth and beauty. "}, "hash": "b99824bbe7c8201f9ea8c89ba70a5f1d3c021d214cf2f4362ca3b5ef794de5b9", "class_name": "RelatedNodeInfo"}}, "hash": "ac3c1f742d717b891e7c2a8a06103a877d4e6f71b1b8b9bd15c8b64f8667dd91", "text": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n", "start_char_idx": 40339, "end_char_idx": 40567, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d64b4e76-312b-4831-b984-b3408a12cea6": {"__data__": {"id_": "d64b4e76-312b-4831-b984-b3408a12cea6", "embedding": null, "metadata": {"window": "So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? ", "original_text": "In this class, I'm not gonna do any truth and beauty. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "926d456f-2d6d-4932-be8f-22be58c213a9", "node_type": "1", "metadata": {"window": "So let's see.  So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes. ", "original_text": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n"}, "hash": "ac3c1f742d717b891e7c2a8a06103a877d4e6f71b1b8b9bd15c8b64f8667dd91", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8a8a46e6-01fd-4ee0-8bab-6cb098725c9d", "node_type": "1", "metadata": {"window": "The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising. ", "original_text": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n"}, "hash": "6a8972033710004847fac1051cddcab12b7c453d099adebb9ac6c11b3ccf5f1e", "class_name": "RelatedNodeInfo"}}, "hash": "b99824bbe7c8201f9ea8c89ba70a5f1d3c021d214cf2f4362ca3b5ef794de5b9", "text": "In this class, I'm not gonna do any truth and beauty. ", "start_char_idx": 40567, "end_char_idx": 40621, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a8a46e6-01fd-4ee0-8bab-6cb098725c9d": {"__data__": {"id_": "8a8a46e6-01fd-4ee0-8bab-6cb098725c9d", "embedding": null, "metadata": {"window": "The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising. ", "original_text": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d64b4e76-312b-4831-b984-b3408a12cea6", "node_type": "1", "metadata": {"window": "So that was supervised learning.  The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? ", "original_text": "In this class, I'm not gonna do any truth and beauty. "}, "hash": "b99824bbe7c8201f9ea8c89ba70a5f1d3c021d214cf2f4362ca3b5ef794de5b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d92d143b-ccbf-4462-9a95-3b9973b48b87", "node_type": "1", "metadata": {"window": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n", "original_text": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? "}, "hash": "c78c3ce7afe417844d0cecf861c604b83547efd0322e0c0bf95fdc98f719ff63", "class_name": "RelatedNodeInfo"}}, "hash": "6a8972033710004847fac1051cddcab12b7c453d099adebb9ac6c11b3ccf5f1e", "text": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n", "start_char_idx": 40621, "end_char_idx": 40836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d92d143b-ccbf-4462-9a95-3b9973b48b87": {"__data__": {"id_": "d92d143b-ccbf-4462-9a95-3b9973b48b87", "embedding": null, "metadata": {"window": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n", "original_text": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8a8a46e6-01fd-4ee0-8bab-6cb098725c9d", "node_type": "1", "metadata": {"window": "The second of the four major topics of this \nclass will be learning theory.  So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising. ", "original_text": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n"}, "hash": "6a8972033710004847fac1051cddcab12b7c453d099adebb9ac6c11b3ccf5f1e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2242af92-bb44-4207-807c-a9027e2c9585", "node_type": "1", "metadata": {"window": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? ", "original_text": "So think about a learning \n\nalgorithm for reading zip codes. "}, "hash": "83808c8ba1412d021170c1934006b2cbaceed5c16eb1f947f9c9c7b3547dc8db", "class_name": "RelatedNodeInfo"}}, "hash": "c78c3ce7afe417844d0cecf861c604b83547efd0322e0c0bf95fdc98f719ff63", "text": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? ", "start_char_idx": 40836, "end_char_idx": 40984, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2242af92-bb44-4207-807c-a9027e2c9585": {"__data__": {"id_": "2242af92-bb44-4207-807c-a9027e2c9585", "embedding": null, "metadata": {"window": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? ", "original_text": "So think about a learning \n\nalgorithm for reading zip codes. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d92d143b-ccbf-4462-9a95-3b9973b48b87", "node_type": "1", "metadata": {"window": "So I have a friend who teaches math at a different \nuniversity, not at Stanford, and when you talk to  him about his work and what he's really \nout to do, this friend of mine will \u2014 he's a ma th professor, right?  \u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n", "original_text": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right? "}, "hash": "c78c3ce7afe417844d0cecf861c604b83547efd0322e0c0bf95fdc98f719ff63", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ccd42ad-3d3f-4b86-9a3d-787f313b20c2", "node_type": "1", "metadata": {"window": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? ", "original_text": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? "}, "hash": "f7ec68c9e8afe4b37a186605b78589db2df0cfdb1e9366732ce5e60285b49be7", "class_name": "RelatedNodeInfo"}}, "hash": "83808c8ba1412d021170c1934006b2cbaceed5c16eb1f947f9c9c7b3547dc8db", "text": "So think about a learning \n\nalgorithm for reading zip codes. ", "start_char_idx": 40984, "end_char_idx": 41045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ccd42ad-3d3f-4b86-9a3d-787f313b20c2": {"__data__": {"id_": "0ccd42ad-3d3f-4b86-9a3d-787f313b20c2", "embedding": null, "metadata": {"window": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? ", "original_text": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2242af92-bb44-4207-807c-a9027e2c9585", "node_type": "1", "metadata": {"window": "\u2014 this friend of mine \nwill sort of get the look of wonder in his eyes, and he'll tell you about how in his \nmathematical work, he feels like he's disc overing truth and beauty in the universe.  And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? ", "original_text": "So think about a learning \n\nalgorithm for reading zip codes. "}, "hash": "83808c8ba1412d021170c1934006b2cbaceed5c16eb1f947f9c9c7b3547dc8db", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bcb6cf75-f2d2-4218-b9f8-71bc9ee53fcc", "node_type": "1", "metadata": {"window": "In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n", "original_text": "This is \nactually somewhat surprising. "}, "hash": "62889d0f6cd692b7a4af1eb44c05d28f0453d035144fe9c646edcde034ded73a", "class_name": "RelatedNodeInfo"}}, "hash": "f7ec68c9e8afe4b37a186605b78589db2df0cfdb1e9366732ce5e60285b49be7", "text": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? ", "start_char_idx": 41045, "end_char_idx": 41177, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bcb6cf75-f2d2-4218-b9f8-71bc9ee53fcc": {"__data__": {"id_": "bcb6cf75-f2d2-4218-b9f8-71bc9ee53fcc", "embedding": null, "metadata": {"window": "In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n", "original_text": "This is \nactually somewhat surprising. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ccd42ad-3d3f-4b86-9a3d-787f313b20c2", "node_type": "1", "metadata": {"window": "And \nhe says it in sort of a real ly touching, sincere way, and then  he has this \u2014 you can see it \nin his eyes \u2014 he has this deep appreciation of the truth and beauty  in the universe as \nrevealed to him by the math he does.  \n In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? ", "original_text": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes? "}, "hash": "f7ec68c9e8afe4b37a186605b78589db2df0cfdb1e9366732ce5e60285b49be7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "732acb59-a2ac-4a12-93bf-922b4ef5270c", "node_type": "1", "metadata": {"window": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n", "original_text": "We actually prove theorems showing when you can expect \nthat to hold.  \n"}, "hash": "969cd85f33162c2b9d71fc397762e40efe1f5888ca44098a756b103ecaff465f", "class_name": "RelatedNodeInfo"}}, "hash": "62889d0f6cd692b7a4af1eb44c05d28f0453d035144fe9c646edcde034ded73a", "text": "This is \nactually somewhat surprising. ", "start_char_idx": 41177, "end_char_idx": 41216, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "732acb59-a2ac-4a12-93bf-922b4ef5270c": {"__data__": {"id_": "732acb59-a2ac-4a12-93bf-922b4ef5270c", "embedding": null, "metadata": {"window": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n", "original_text": "We actually prove theorems showing when you can expect \nthat to hold.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bcb6cf75-f2d2-4218-b9f8-71bc9ee53fcc", "node_type": "1", "metadata": {"window": "In this class, I'm not gonna do any truth and beauty.  In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n", "original_text": "This is \nactually somewhat surprising. "}, "hash": "62889d0f6cd692b7a4af1eb44c05d28f0453d035144fe9c646edcde034ded73a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f439b10c-3b1e-43ea-ad96-ed2d44a0c3c8", "node_type": "1", "metadata": {"window": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n", "original_text": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? "}, "hash": "d1a0e8ccb0149ccd99943c047d111773019619e1c32a46cdb54e0867fd81b372", "class_name": "RelatedNodeInfo"}}, "hash": "969cd85f33162c2b9d71fc397762e40efe1f5888ca44098a756b103ecaff465f", "text": "We actually prove theorems showing when you can expect \nthat to hold.  \n", "start_char_idx": 41216, "end_char_idx": 41288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f439b10c-3b1e-43ea-ad96-ed2d44a0c3c8": {"__data__": {"id_": "f439b10c-3b1e-43ea-ad96-ed2d44a0c3c8", "embedding": null, "metadata": {"window": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n", "original_text": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "732acb59-a2ac-4a12-93bf-922b4ef5270c", "node_type": "1", "metadata": {"window": "In this class,  I'm gonna talk about \nlearning theory to try to convey to y ou an understanding of how and why learning \nalgorithms work so that we can apply these lear ning algorithms as effectively as possible.  \n So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n", "original_text": "We actually prove theorems showing when you can expect \nthat to hold.  \n"}, "hash": "969cd85f33162c2b9d71fc397762e40efe1f5888ca44098a756b103ecaff465f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "778bd68c-daa3-4cf3-8b51-766bac119c05", "node_type": "1", "metadata": {"window": "So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? ", "original_text": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? "}, "hash": "3e5f850d03e2d5e92d57b24487232b01bb0ecac5b037af68c24748891e4a46db", "class_name": "RelatedNodeInfo"}}, "hash": "d1a0e8ccb0149ccd99943c047d111773019619e1c32a46cdb54e0867fd81b372", "text": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? ", "start_char_idx": 41288, "end_char_idx": 41491, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "778bd68c-daa3-4cf3-8b51-766bac119c05": {"__data__": {"id_": "778bd68c-daa3-4cf3-8b51-766bac119c05", "embedding": null, "metadata": {"window": "So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? ", "original_text": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f439b10c-3b1e-43ea-ad96-ed2d44a0c3c8", "node_type": "1", "metadata": {"window": "So, for example, it turns out you can prove su rprisingly deep theorems on when you can \nguarantee that a learning algorithm will wo rk, all right?  So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n", "original_text": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need? "}, "hash": "d1a0e8ccb0149ccd99943c047d111773019619e1c32a46cdb54e0867fd81b372", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3bb5ad0a-fac3-48cd-b0ac-0451ddd824c2", "node_type": "1", "metadata": {"window": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry. ", "original_text": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n"}, "hash": "599a0294c2e4715f8eac4e9aca256a2b92174c4db8d05846f3911690e6cf52b0", "class_name": "RelatedNodeInfo"}}, "hash": "3e5f850d03e2d5e92d57b24487232b01bb0ecac5b037af68c24748891e4a46db", "text": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? ", "start_char_idx": 41491, "end_char_idx": 41659, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3bb5ad0a-fac3-48cd-b0ac-0451ddd824c2": {"__data__": {"id_": "3bb5ad0a-fac3-48cd-b0ac-0451ddd824c2", "embedding": null, "metadata": {"window": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry. ", "original_text": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "778bd68c-daa3-4cf3-8b51-766bac119c05", "node_type": "1", "metadata": {"window": "So think about a learning \n\nalgorithm for reading zip codes.  When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? ", "original_text": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price? "}, "hash": "3e5f850d03e2d5e92d57b24487232b01bb0ecac5b037af68c24748891e4a46db", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6132fbc7-d4fa-45a1-958b-9d1c4a7ac645", "node_type": "1", "metadata": {"window": "This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. ", "original_text": "Okay?  \n"}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "class_name": "RelatedNodeInfo"}}, "hash": "599a0294c2e4715f8eac4e9aca256a2b92174c4db8d05846f3911690e6cf52b0", "text": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n", "start_char_idx": 41659, "end_char_idx": 41914, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6132fbc7-d4fa-45a1-958b-9d1c4a7ac645": {"__data__": {"id_": "6132fbc7-d4fa-45a1-958b-9d1c4a7ac645", "embedding": null, "metadata": {"window": "This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. ", "original_text": "Okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3bb5ad0a-fac3-48cd-b0ac-0451ddd824c2", "node_type": "1", "metadata": {"window": "When can  you prove a theorem guaranteeing that a \nlearning algorithm will be at least 99.9 per cent accurate on reading zip codes?  This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry. ", "original_text": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n"}, "hash": "599a0294c2e4715f8eac4e9aca256a2b92174c4db8d05846f3911690e6cf52b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "df32954a-04ff-46cf-94e9-39fedc4845ad", "node_type": "1", "metadata": {"window": "We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room. ", "original_text": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n"}, "hash": "f7e9d8dcec7512dca2f82a1a3ec145fdfcfe75de52ce68f82922f748c7b05070", "class_name": "RelatedNodeInfo"}}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "text": "Okay?  \n", "start_char_idx": 41914, "end_char_idx": 41922, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "df32954a-04ff-46cf-94e9-39fedc4845ad": {"__data__": {"id_": "df32954a-04ff-46cf-94e9-39fedc4845ad", "embedding": null, "metadata": {"window": "We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room. ", "original_text": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6132fbc7-d4fa-45a1-958b-9d1c4a7ac645", "node_type": "1", "metadata": {"window": "This is \nactually somewhat surprising.  We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. ", "original_text": "Okay?  \n"}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ac2c8288-61dd-48d4-9ee2-e1880a4f0724", "node_type": "1", "metadata": {"window": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. ", "original_text": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? "}, "hash": "b02988ef6f4c4558353324f01b022d4a2bbf7c20265b3b9dc95075b387066a75", "class_name": "RelatedNodeInfo"}}, "hash": "f7e9d8dcec7512dca2f82a1a3ec145fdfcfe75de52ce68f82922f748c7b05070", "text": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n", "start_char_idx": 41922, "end_char_idx": 42296, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac2c8288-61dd-48d4-9ee2-e1880a4f0724": {"__data__": {"id_": "ac2c8288-61dd-48d4-9ee2-e1880a4f0724", "embedding": null, "metadata": {"window": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. ", "original_text": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "df32954a-04ff-46cf-94e9-39fedc4845ad", "node_type": "1", "metadata": {"window": "We actually prove theorems showing when you can expect \nthat to hold.  \n We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room. ", "original_text": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n"}, "hash": "f7e9d8dcec7512dca2f82a1a3ec145fdfcfe75de52ce68f82922f748c7b05070", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1270da3a-094f-4006-b59c-08a4892d32ee", "node_type": "1", "metadata": {"window": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too. ", "original_text": "If you go to a carpentry school, they can give you the \ntools of carpentry. "}, "hash": "b0d81a90c4321e9e5bb024c8f7034fc17f42d2200b348ddc8d5fe3f73a48a5f1", "class_name": "RelatedNodeInfo"}}, "hash": "b02988ef6f4c4558353324f01b022d4a2bbf7c20265b3b9dc95075b387066a75", "text": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? ", "start_char_idx": 42296, "end_char_idx": 42421, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1270da3a-094f-4006-b59c-08a4892d32ee": {"__data__": {"id_": "1270da3a-094f-4006-b59c-08a4892d32ee", "embedding": null, "metadata": {"window": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too. ", "original_text": "If you go to a carpentry school, they can give you the \ntools of carpentry. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac2c8288-61dd-48d4-9ee2-e1880a4f0724", "node_type": "1", "metadata": {"window": "We'll also sort of delve into learning theo ry to try to understand what algorithms can \napproximate different functions well and also  try to understand things like how much \ntraining data do you need?  So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. ", "original_text": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right? "}, "hash": "b02988ef6f4c4558353324f01b022d4a2bbf7c20265b3b9dc95075b387066a75", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0054ff19-4620-4fbc-8091-0abff10bcab1", "node_type": "1", "metadata": {"window": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n", "original_text": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. "}, "hash": "eb9bc42ede1c2e2cdfbe0fa2af4e70e4f932d94c30f5f9fde94203c8f991e475", "class_name": "RelatedNodeInfo"}}, "hash": "b0d81a90c4321e9e5bb024c8f7034fc17f42d2200b348ddc8d5fe3f73a48a5f1", "text": "If you go to a carpentry school, they can give you the \ntools of carpentry. ", "start_char_idx": 42421, "end_char_idx": 42497, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0054ff19-4620-4fbc-8091-0abff10bcab1": {"__data__": {"id_": "0054ff19-4620-4fbc-8091-0abff10bcab1", "embedding": null, "metadata": {"window": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n", "original_text": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1270da3a-094f-4006-b59c-08a4892d32ee", "node_type": "1", "metadata": {"window": "So how many exampl es of houses do I need in order for your \nlearning algorithm to recognize the pattern be tween the square footage of a house and its \nhousing price?  And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too. ", "original_text": "If you go to a carpentry school, they can give you the \ntools of carpentry. "}, "hash": "b0d81a90c4321e9e5bb024c8f7034fc17f42d2200b348ddc8d5fe3f73a48a5f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e10d4641-e92a-494e-ae7b-6f1ec7ad560b", "node_type": "1", "metadata": {"window": "Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. ", "original_text": "But a master carpenter will be able to  use those tools far better than most of us \nin this room. "}, "hash": "2faf84063737da66f7b3a657b14cbaeeb34f3053477e88ca7e256681986bca1b", "class_name": "RelatedNodeInfo"}}, "hash": "eb9bc42ede1c2e2cdfbe0fa2af4e70e4f932d94c30f5f9fde94203c8f991e475", "text": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. ", "start_char_idx": 42497, "end_char_idx": 42571, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e10d4641-e92a-494e-ae7b-6f1ec7ad560b": {"__data__": {"id_": "e10d4641-e92a-494e-ae7b-6f1ec7ad560b", "embedding": null, "metadata": {"window": "Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. ", "original_text": "But a master carpenter will be able to  use those tools far better than most of us \nin this room. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0054ff19-4620-4fbc-8091-0abff10bcab1", "node_type": "1", "metadata": {"window": "And this will help  us answer questions like if you're trying to design a \nlearning algorithm, should you be spending more time collecting more data or is it a case \nthat you already have enough data; it would be  a waste of time to try to collect more. \n Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n", "original_text": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever. "}, "hash": "eb9bc42ede1c2e2cdfbe0fa2af4e70e4f932d94c30f5f9fde94203c8f991e475", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d15d05d-6121-40f1-ab35-1f843a840ee0", "node_type": "1", "metadata": {"window": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree . ", "original_text": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. "}, "hash": "b9caf13abb84ad164072ca97e857dfda44c94defaedd29332d1c720caeedf9aa", "class_name": "RelatedNodeInfo"}}, "hash": "2faf84063737da66f7b3a657b14cbaeeb34f3053477e88ca7e256681986bca1b", "text": "But a master carpenter will be able to  use those tools far better than most of us \nin this room. ", "start_char_idx": 42571, "end_char_idx": 42669, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9d15d05d-6121-40f1-ab35-1f843a840ee0": {"__data__": {"id_": "9d15d05d-6121-40f1-ab35-1f843a840ee0", "embedding": null, "metadata": {"window": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree . ", "original_text": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e10d4641-e92a-494e-ae7b-6f1ec7ad560b", "node_type": "1", "metadata": {"window": "Okay?  \n So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. ", "original_text": "But a master carpenter will be able to  use those tools far better than most of us \nin this room. "}, "hash": "2faf84063737da66f7b3a657b14cbaeeb34f3053477e88ca7e256681986bca1b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d542a4a1-b4f2-4d74-a155-a44eeaee796d", "node_type": "1", "metadata": {"window": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. ", "original_text": "And it's actually a littl e bit like that in machine learning, too. "}, "hash": "da58b73141274a1d6ec0e74ffb650db62ae95a409bcf2e710a4354f3af0b8137", "class_name": "RelatedNodeInfo"}}, "hash": "b9caf13abb84ad164072ca97e857dfda44c94defaedd29332d1c720caeedf9aa", "text": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. ", "start_char_idx": 42669, "end_char_idx": 42753, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d542a4a1-b4f2-4d74-a155-a44eeaee796d": {"__data__": {"id_": "d542a4a1-b4f2-4d74-a155-a44eeaee796d", "embedding": null, "metadata": {"window": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. ", "original_text": "And it's actually a littl e bit like that in machine learning, too. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d15d05d-6121-40f1-ab35-1f843a840ee0", "node_type": "1", "metadata": {"window": "So I think learning algorithms are a very powerful tool that  as I walk around sort of \nindustry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \nfind that there's often a huge differen ce between how well so meone who really \nunderstands this stuff can appl y a learning algorithm versus so meone who sort of gets it \nbut sort of doesn't.  \n The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree . ", "original_text": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly. "}, "hash": "b9caf13abb84ad164072ca97e857dfda44c94defaedd29332d1c720caeedf9aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b648b065-f0df-4a40-b864-022526b37a0c", "node_type": "1", "metadata": {"window": "If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n", "original_text": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n"}, "hash": "cdc0236678f456942559f9a6b7a49add382387c1fff1aeb877df06b954973859", "class_name": "RelatedNodeInfo"}}, "hash": "da58b73141274a1d6ec0e74ffb650db62ae95a409bcf2e710a4354f3af0b8137", "text": "And it's actually a littl e bit like that in machine learning, too. ", "start_char_idx": 42753, "end_char_idx": 42821, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b648b065-f0df-4a40-b864-022526b37a0c": {"__data__": {"id_": "b648b065-f0df-4a40-b864-022526b37a0c", "embedding": null, "metadata": {"window": "If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n", "original_text": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d542a4a1-b4f2-4d74-a155-a44eeaee796d", "node_type": "1", "metadata": {"window": "The analogy I like to think of  is imagine you were going to a carpentry school instead of \na machine learning class, right?  If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. ", "original_text": "And it's actually a littl e bit like that in machine learning, too. "}, "hash": "da58b73141274a1d6ec0e74ffb650db62ae95a409bcf2e710a4354f3af0b8137", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41c42bab-5810-41ff-9fbe-8709b36ff151", "node_type": "1", "metadata": {"window": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n", "original_text": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. "}, "hash": "4794a954cdd430f05bc0274e63e8f02c5226aa902e6011ffb03379fa09378cd4", "class_name": "RelatedNodeInfo"}}, "hash": "cdc0236678f456942559f9a6b7a49add382387c1fff1aeb877df06b954973859", "text": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n", "start_char_idx": 42821, "end_char_idx": 42977, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "41c42bab-5810-41ff-9fbe-8709b36ff151": {"__data__": {"id_": "41c42bab-5810-41ff-9fbe-8709b36ff151", "embedding": null, "metadata": {"window": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n", "original_text": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b648b065-f0df-4a40-b864-022526b37a0c", "node_type": "1", "metadata": {"window": "If you go to a carpentry school, they can give you the \ntools of carpentry.  They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n", "original_text": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n"}, "hash": "cdc0236678f456942559f9a6b7a49add382387c1fff1aeb877df06b954973859", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a299e07c-d0ff-41bf-83cd-195bf2c73ddd", "node_type": "1", "metadata": {"window": "But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. ", "original_text": "Maybe a carpenter will disagree . "}, "hash": "876724f0067f8e5ee94e59cb982f31a46073e2875234effcf702fb15bef9c824", "class_name": "RelatedNodeInfo"}}, "hash": "4794a954cdd430f05bc0274e63e8f02c5226aa902e6011ffb03379fa09378cd4", "text": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. ", "start_char_idx": 42977, "end_char_idx": 43103, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a299e07c-d0ff-41bf-83cd-195bf2c73ddd": {"__data__": {"id_": "a299e07c-d0ff-41bf-83cd-195bf2c73ddd", "embedding": null, "metadata": {"window": "But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. ", "original_text": "Maybe a carpenter will disagree . "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "41c42bab-5810-41ff-9fbe-8709b36ff151", "node_type": "1", "metadata": {"window": "They'll give you a hamme r, a bunch of nails, a screwdriver or \nwhatever.  But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n", "original_text": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry. "}, "hash": "4794a954cdd430f05bc0274e63e8f02c5226aa902e6011ffb03379fa09378cd4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66b23811-3342-4c37-b6bc-fc6655ba2ecd", "node_type": "1", "metadata": {"window": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach. ", "original_text": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. "}, "hash": "78b7794d4832e61cb43bf9d9f9561fad7b5997187836292e3d36558ad4cc8e7f", "class_name": "RelatedNodeInfo"}}, "hash": "876724f0067f8e5ee94e59cb982f31a46073e2875234effcf702fb15bef9c824", "text": "Maybe a carpenter will disagree . ", "start_char_idx": 43103, "end_char_idx": 43137, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66b23811-3342-4c37-b6bc-fc6655ba2ecd": {"__data__": {"id_": "66b23811-3342-4c37-b6bc-fc6655ba2ecd", "embedding": null, "metadata": {"window": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach. ", "original_text": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a299e07c-d0ff-41bf-83cd-195bf2c73ddd", "node_type": "1", "metadata": {"window": "But a master carpenter will be able to  use those tools far better than most of us \nin this room.  I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. ", "original_text": "Maybe a carpenter will disagree . "}, "hash": "876724f0067f8e5ee94e59cb982f31a46073e2875234effcf702fb15bef9c824", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "286d4f42-1413-44f5-91e0-b955d067f53c", "node_type": "1", "metadata": {"window": "And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. ", "original_text": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n"}, "hash": "3bdc268af92c2b05d4fa98faa9f82fd3fde99c6e63ec95c3c7c04bb4b88caaee", "class_name": "RelatedNodeInfo"}}, "hash": "78b7794d4832e61cb43bf9d9f9561fad7b5997187836292e3d36558ad4cc8e7f", "text": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. ", "start_char_idx": 43137, "end_char_idx": 43261, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "286d4f42-1413-44f5-91e0-b955d067f53c": {"__data__": {"id_": "286d4f42-1413-44f5-91e0-b955d067f53c", "embedding": null, "metadata": {"window": "And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. ", "original_text": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66b23811-3342-4c37-b6bc-fc6655ba2ecd", "node_type": "1", "metadata": {"window": "I know a carpen ter can do things with a hammer and nail that I couldn't \npossibly.  And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach. ", "original_text": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on. "}, "hash": "78b7794d4832e61cb43bf9d9f9561fad7b5997187836292e3d36558ad4cc8e7f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "085cda97-eded-4233-aecd-96744be432c4", "node_type": "1", "metadata": {"window": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. ", "original_text": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n"}, "hash": "8fdc1277ccf8c758da4a768a43d249b092d6eda86f226d5d538e2d82a791439d", "class_name": "RelatedNodeInfo"}}, "hash": "3bdc268af92c2b05d4fa98faa9f82fd3fde99c6e63ec95c3c7c04bb4b88caaee", "text": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n", "start_char_idx": 43261, "end_char_idx": 43569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "085cda97-eded-4233-aecd-96744be432c4": {"__data__": {"id_": "085cda97-eded-4233-aecd-96744be432c4", "embedding": null, "metadata": {"window": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. ", "original_text": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "286d4f42-1413-44f5-91e0-b955d067f53c", "node_type": "1", "metadata": {"window": "And it's actually a littl e bit like that in machine learning, too.  One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. ", "original_text": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n"}, "hash": "3bdc268af92c2b05d4fa98faa9f82fd3fde99c6e63ec95c3c7c04bb4b88caaee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e58933d3-afb0-463a-8a67-f0f7cd95ab59", "node_type": "1", "metadata": {"window": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n", "original_text": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. "}, "hash": "6fe16fe0b3b9eb25aa56cf9031daae88789342ce0d6e5c715a4f027195d5ff36", "class_name": "RelatedNodeInfo"}}, "hash": "8fdc1277ccf8c758da4a768a43d249b092d6eda86f226d5d538e2d82a791439d", "text": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n", "start_char_idx": 43569, "end_char_idx": 43988, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e58933d3-afb0-463a-8a67-f0f7cd95ab59": {"__data__": {"id_": "e58933d3-afb0-463a-8a67-f0f7cd95ab59", "embedding": null, "metadata": {"window": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n", "original_text": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "085cda97-eded-4233-aecd-96744be432c4", "node_type": "1", "metadata": {"window": "One thing that's \nsadly not taught in many courses on machine l earning is how to take the tools of machine \nlearning and really, really apply them well.  \n So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. ", "original_text": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n"}, "hash": "8fdc1277ccf8c758da4a768a43d249b092d6eda86f226d5d538e2d82a791439d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9beea8fc-0965-4aca-8f16-d0d0fed58602", "node_type": "1", "metadata": {"window": "Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see. ", "original_text": "And I've noticed this  is something that really not many other \n\nclasses teach. "}, "hash": "04662661afa3ad11b2f4f0d0a2a46fb62bfbacdc0eeaa5896f3ba22ecb8bce4f", "class_name": "RelatedNodeInfo"}}, "hash": "6fe16fe0b3b9eb25aa56cf9031daae88789342ce0d6e5c715a4f027195d5ff36", "text": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. ", "start_char_idx": 43988, "end_char_idx": 44191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9beea8fc-0965-4aca-8f16-d0d0fed58602": {"__data__": {"id_": "9beea8fc-0965-4aca-8f16-d0d0fed58602", "embedding": null, "metadata": {"window": "Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see. ", "original_text": "And I've noticed this  is something that really not many other \n\nclasses teach. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e58933d3-afb0-463a-8a67-f0f7cd95ab59", "node_type": "1", "metadata": {"window": "So in the same way, so the tools of machin e learning are I wanna say quite a bit more \nadvanced than the tools of carpentry.  Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n", "original_text": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well. "}, "hash": "6fe16fe0b3b9eb25aa56cf9031daae88789342ce0d6e5c715a4f027195d5ff36", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d778fa72-34b2-4eea-9e9e-080da81f538e", "node_type": "1", "metadata": {"window": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board. ", "original_text": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. "}, "hash": "b235ea683fd164b5b509138430c78affde70b1b96eaa37ace0ef0aec5a7f8908", "class_name": "RelatedNodeInfo"}}, "hash": "04662661afa3ad11b2f4f0d0a2a46fb62bfbacdc0eeaa5896f3ba22ecb8bce4f", "text": "And I've noticed this  is something that really not many other \n\nclasses teach. ", "start_char_idx": 44191, "end_char_idx": 44271, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d778fa72-34b2-4eea-9e9e-080da81f538e": {"__data__": {"id_": "d778fa72-34b2-4eea-9e9e-080da81f538e", "embedding": null, "metadata": {"window": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board. ", "original_text": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9beea8fc-0965-4aca-8f16-d0d0fed58602", "node_type": "1", "metadata": {"window": "Maybe a carpenter will disagree .  But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see. ", "original_text": "And I've noticed this  is something that really not many other \n\nclasses teach. "}, "hash": "04662661afa3ad11b2f4f0d0a2a46fb62bfbacdc0eeaa5896f3ba22ecb8bce4f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "18ddd055-d736-471f-8e9f-1fa061893ddf", "node_type": "1", "metadata": {"window": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. ", "original_text": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. "}, "hash": "1754b6017a6a02d29f4a03f6d8301e0754ac8e447267f5f452951e112c1c99fc", "class_name": "RelatedNodeInfo"}}, "hash": "b235ea683fd164b5b509138430c78affde70b1b96eaa37ace0ef0aec5a7f8908", "text": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. ", "start_char_idx": 44271, "end_char_idx": 44410, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "18ddd055-d736-471f-8e9f-1fa061893ddf": {"__data__": {"id_": "18ddd055-d736-471f-8e9f-1fa061893ddf", "embedding": null, "metadata": {"window": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. ", "original_text": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d778fa72-34b2-4eea-9e9e-080da81f538e", "node_type": "1", "metadata": {"window": "But a large part of \nthis class will be just givi ng you the raw tools of machine learning, just the algorithms \nand so on.  But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board. ", "original_text": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters. "}, "hash": "b235ea683fd164b5b509138430c78affde70b1b96eaa37ace0ef0aec5a7f8908", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b5f1d69-b790-4686-8a2d-2e5081daf461", "node_type": "1", "metadata": {"window": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. ", "original_text": "Okay?  \n"}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "class_name": "RelatedNodeInfo"}}, "hash": "1754b6017a6a02d29f4a03f6d8301e0754ac8e447267f5f452951e112c1c99fc", "text": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. ", "start_char_idx": 44410, "end_char_idx": 44547, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b5f1d69-b790-4686-8a2d-2e5081daf461": {"__data__": {"id_": "4b5f1d69-b790-4686-8a2d-2e5081daf461", "embedding": null, "metadata": {"window": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. ", "original_text": "Okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18ddd055-d736-471f-8e9f-1fa061893ddf", "node_type": "1", "metadata": {"window": "But what I plan to do throughout this entire quarter, not just in the segment of \nlearning theory, but actually as a theme r unning through everything I do this quarter, will \nbe to try to convey to you the skills to real ly take the learning al gorithm ideas and really \nto get them to work on a problem.  \n It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. ", "original_text": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems. "}, "hash": "1754b6017a6a02d29f4a03f6d8301e0754ac8e447267f5f452951e112c1c99fc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3c7c31fd-7bf5-464e-bf47-42024ac494c7", "node_type": "1", "metadata": {"window": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. ", "original_text": "Let's see. "}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "class_name": "RelatedNodeInfo"}}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "text": "Okay?  \n", "start_char_idx": 41914, "end_char_idx": 41922, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3c7c31fd-7bf5-464e-bf47-42024ac494c7": {"__data__": {"id_": "3c7c31fd-7bf5-464e-bf47-42024ac494c7", "embedding": null, "metadata": {"window": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. ", "original_text": "Let's see. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b5f1d69-b790-4686-8a2d-2e5081daf461", "node_type": "1", "metadata": {"window": "It's sort of hard for me to stand here and say how big a deal that is, but when I walk \naround companies in Silicon Valley, it's co mpletely not uncommon for me to see \nsomeone using some machine learning algorith m and then explain to me what they've \nbeen doing for the last six months, and I go, oh, gee, it should have been obvious from \nthe start that the last six months, you've been wa sting your time, right?  \n And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. ", "original_text": "Okay?  \n"}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb70804b-2a0f-4d5d-947e-2e284b97a90e", "node_type": "1", "metadata": {"window": "And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. ", "original_text": "So [inaudible] the board. "}, "hash": "9ec100e9137f487f6fb0ca6cd29d07140ea7535d4aefac208bb40325f8262af7", "class_name": "RelatedNodeInfo"}}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "text": "Let's see. ", "start_char_idx": 13312, "end_char_idx": 13323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eb70804b-2a0f-4d5d-947e-2e284b97a90e": {"__data__": {"id_": "eb70804b-2a0f-4d5d-947e-2e284b97a90e", "embedding": null, "metadata": {"window": "And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. ", "original_text": "So [inaudible] the board. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3c7c31fd-7bf5-464e-bf47-42024ac494c7", "node_type": "1", "metadata": {"window": "And so my goal in this class, running th rough the entire quarter , not just on learning \ntheory, is actually not only to give you the tools of m achine learning, but to teach you \nhow to use them well.  And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. ", "original_text": "Let's see. "}, "hash": "47858d70bf8d793c145b2a83ccb11390ecfc4c5b4f3c6a78695ba2875170f221", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "36a946af-4b99-4ff2-b58d-f61b55d087e4", "node_type": "1", "metadata": {"window": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n", "original_text": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. "}, "hash": "712717584dc1cad6affaada21a8ee27035aa3910d15c5b1637508f3500a17156", "class_name": "RelatedNodeInfo"}}, "hash": "9ec100e9137f487f6fb0ca6cd29d07140ea7535d4aefac208bb40325f8262af7", "text": "So [inaudible] the board. ", "start_char_idx": 44566, "end_char_idx": 44592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "36a946af-4b99-4ff2-b58d-f61b55d087e4": {"__data__": {"id_": "36a946af-4b99-4ff2-b58d-f61b55d087e4", "embedding": null, "metadata": {"window": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n", "original_text": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb70804b-2a0f-4d5d-947e-2e284b97a90e", "node_type": "1", "metadata": {"window": "And I've noticed this  is something that really not many other \n\nclasses teach.  And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. ", "original_text": "So [inaudible] the board. "}, "hash": "9ec100e9137f487f6fb0ca6cd29d07140ea7535d4aefac208bb40325f8262af7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "be7ee631-fb27-4901-947b-b325fbcb59cd", "node_type": "1", "metadata": {"window": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n", "original_text": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. "}, "hash": "f70115f0256f299cf3a54ea497857cf8b1ea5f391b18e50c063ab9aee435ce9e", "class_name": "RelatedNodeInfo"}}, "hash": "712717584dc1cad6affaada21a8ee27035aa3910d15c5b1637508f3500a17156", "text": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. ", "start_char_idx": 44592, "end_char_idx": 44735, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "be7ee631-fb27-4901-947b-b325fbcb59cd": {"__data__": {"id_": "be7ee631-fb27-4901-947b-b325fbcb59cd", "embedding": null, "metadata": {"window": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n", "original_text": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36a946af-4b99-4ff2-b58d-f61b55d087e4", "node_type": "1", "metadata": {"window": "And this is something I'm rea lly convinced is a huge deal, and so by the \nend of this class, I hope all of you will be master carpenters.  I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n", "original_text": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning. "}, "hash": "712717584dc1cad6affaada21a8ee27035aa3910d15c5b1637508f3500a17156", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7fa810e-a159-4df5-8cc0-b2e0f3a40cac", "node_type": "1", "metadata": {"window": "Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. ", "original_text": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. "}, "hash": "b1967fe32c93a3f9f17cfd687f1042524b847fc01c200b0977d2ae29fec5f7af", "class_name": "RelatedNodeInfo"}}, "hash": "f70115f0256f299cf3a54ea497857cf8b1ea5f391b18e50c063ab9aee435ce9e", "text": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. ", "start_char_idx": 44735, "end_char_idx": 44941, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d7fa810e-a159-4df5-8cc0-b2e0f3a40cac": {"__data__": {"id_": "d7fa810e-a159-4df5-8cc0-b2e0f3a40cac", "embedding": null, "metadata": {"window": "Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. ", "original_text": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "be7ee631-fb27-4901-947b-b325fbcb59cd", "node_type": "1", "metadata": {"window": "I hope all of you will be \nreally good at applying these learning algor ithms and getting them to work amazingly \nwell in many problems.  Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n", "original_text": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever. "}, "hash": "f70115f0256f299cf3a54ea497857cf8b1ea5f391b18e50c063ab9aee435ce9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41ad974d-bf03-4445-8cb0-e22fb0095360", "node_type": "1", "metadata": {"window": "Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" ", "original_text": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. "}, "hash": "fdb4260c3e62967a8f0b5dfd61d90113ab044b8c89f4a76a08650ad2a2650b4e", "class_name": "RelatedNodeInfo"}}, "hash": "b1967fe32c93a3f9f17cfd687f1042524b847fc01c200b0977d2ae29fec5f7af", "text": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. ", "start_char_idx": 44941, "end_char_idx": 45080, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "41ad974d-bf03-4445-8cb0-e22fb0095360": {"__data__": {"id_": "41ad974d-bf03-4445-8cb0-e22fb0095360", "embedding": null, "metadata": {"window": "Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" ", "original_text": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7fa810e-a159-4df5-8cc0-b2e0f3a40cac", "node_type": "1", "metadata": {"window": "Okay?  \n Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. ", "original_text": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients. "}, "hash": "b1967fe32c93a3f9f17cfd687f1042524b847fc01c200b0977d2ae29fec5f7af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c2549741-0810-455b-8770-30048844b9b2", "node_type": "1", "metadata": {"window": "So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n", "original_text": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n"}, "hash": "237aa0c62a167aae7f5c55eb59c95781ba01dfea4d5b370cac1ad5855d7ee5d6", "class_name": "RelatedNodeInfo"}}, "hash": "fdb4260c3e62967a8f0b5dfd61d90113ab044b8c89f4a76a08650ad2a2650b4e", "text": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. ", "start_char_idx": 45080, "end_char_idx": 45170, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c2549741-0810-455b-8770-30048844b9b2": {"__data__": {"id_": "c2549741-0810-455b-8770-30048844b9b2", "embedding": null, "metadata": {"window": "So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n", "original_text": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "41ad974d-bf03-4445-8cb0-e22fb0095360", "node_type": "1", "metadata": {"window": "Let's see.  So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" ", "original_text": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor. "}, "hash": "fdb4260c3e62967a8f0b5dfd61d90113ab044b8c89f4a76a08650ad2a2650b4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ec52283-91d0-4f75-a040-2e9e507e4c5f", "node_type": "1", "metadata": {"window": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n", "original_text": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n"}, "hash": "520e6df8e215200d9047c4dcdcdb65786ea0de090a0d25212e2330012aaa4897", "class_name": "RelatedNodeInfo"}}, "hash": "237aa0c62a167aae7f5c55eb59c95781ba01dfea4d5b370cac1ad5855d7ee5d6", "text": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n", "start_char_idx": 45170, "end_char_idx": 45265, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ec52283-91d0-4f75-a040-2e9e507e4c5f": {"__data__": {"id_": "0ec52283-91d0-4f75-a040-2e9e507e4c5f", "embedding": null, "metadata": {"window": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n", "original_text": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c2549741-0810-455b-8770-30048844b9b2", "node_type": "1", "metadata": {"window": "So [inaudible] the board.  After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n", "original_text": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n"}, "hash": "237aa0c62a167aae7f5c55eb59c95781ba01dfea4d5b370cac1ad5855d7ee5d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49935200-0531-4650-aa00-97cf76483a78", "node_type": "1", "metadata": {"window": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this. ", "original_text": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. "}, "hash": "4ff80fad36417596e4631fc6aca91b55af386c741c8f954be0a877fd033ee4f4", "class_name": "RelatedNodeInfo"}}, "hash": "520e6df8e215200d9047c4dcdcdb65786ea0de090a0d25212e2330012aaa4897", "text": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n", "start_char_idx": 45265, "end_char_idx": 45357, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49935200-0531-4650-aa00-97cf76483a78": {"__data__": {"id_": "49935200-0531-4650-aa00-97cf76483a78", "embedding": null, "metadata": {"window": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this. ", "original_text": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ec52283-91d0-4f75-a040-2e9e507e4c5f", "node_type": "1", "metadata": {"window": "After lear ning theory, there's a nother class of learning \nalgorithms that I then want to teach you a bout, and that's unsupervised learning.  So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n", "original_text": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n"}, "hash": "520e6df8e215200d9047c4dcdcdb65786ea0de090a0d25212e2330012aaa4897", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d21e7529-693e-484e-8246-2611c2e54a50", "node_type": "1", "metadata": {"window": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. ", "original_text": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" "}, "hash": "de4c8aef74243cacd2d995782541b6f1d93873fa38a5b002f92774fd8aae4c7a", "class_name": "RelatedNodeInfo"}}, "hash": "4ff80fad36417596e4631fc6aca91b55af386c741c8f954be0a877fd033ee4f4", "text": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. ", "start_char_idx": 45357, "end_char_idx": 45481, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d21e7529-693e-484e-8246-2611c2e54a50": {"__data__": {"id_": "d21e7529-693e-484e-8246-2611c2e54a50", "embedding": null, "metadata": {"window": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. ", "original_text": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49935200-0531-4650-aa00-97cf76483a78", "node_type": "1", "metadata": {"window": "So you \nrecall, right, a little ea rlier I drew an example like this , right, where you have a couple of \nfeatures, a couple of input vari ables and sort of malignant tumors and benign tumors or \nwhatever.  And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this. ", "original_text": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data. "}, "hash": "4ff80fad36417596e4631fc6aca91b55af386c741c8f954be0a877fd033ee4f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89ed93e3-813e-4abb-9c87-c749b2e4a427", "node_type": "1", "metadata": {"window": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n", "original_text": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n"}, "hash": "6f0885b565e8e5cbba43db26ac9c279278e692d78f285b94a29f48d74c664d72", "class_name": "RelatedNodeInfo"}}, "hash": "de4c8aef74243cacd2d995782541b6f1d93873fa38a5b002f92774fd8aae4c7a", "text": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" ", "start_char_idx": 45481, "end_char_idx": 45599, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89ed93e3-813e-4abb-9c87-c749b2e4a427": {"__data__": {"id_": "89ed93e3-813e-4abb-9c87-c749b2e4a427", "embedding": null, "metadata": {"window": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n", "original_text": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d21e7529-693e-484e-8246-2611c2e54a50", "node_type": "1", "metadata": {"window": "And that was an example of a s upervised learning problem because the data \nyou have gives you the right answer for each of your patients.  The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. ", "original_text": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\" "}, "hash": "de4c8aef74243cacd2d995782541b6f1d93873fa38a5b002f92774fd8aae4c7a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "40433071-83e9-4793-a71a-9185fde18a16", "node_type": "1", "metadata": {"window": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. ", "original_text": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n"}, "hash": "ec93af5e770e227bde224aa29f09d11de4d831bfc03ce0da6513e3a0339b2c16", "class_name": "RelatedNodeInfo"}}, "hash": "6f0885b565e8e5cbba43db26ac9c279278e692d78f285b94a29f48d74c664d72", "text": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n", "start_char_idx": 45599, "end_char_idx": 45710, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40433071-83e9-4793-a71a-9185fde18a16": {"__data__": {"id_": "40433071-83e9-4793-a71a-9185fde18a16", "embedding": null, "metadata": {"window": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. ", "original_text": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89ed93e3-813e-4abb-9c87-c749b2e4a427", "node_type": "1", "metadata": {"window": "The data tells you this \npatient has a malignant tumor;  this patient has a benign tumor.  So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n", "original_text": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n"}, "hash": "6f0885b565e8e5cbba43db26ac9c279278e692d78f285b94a29f48d74c664d72", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "668ae3d0-60a9-4bd8-aca5-1c07db435bba", "node_type": "1", "metadata": {"window": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n", "original_text": "So I hope you can see this. "}, "hash": "b977490a5edf3febf606f84dd7ec9f4388c891eaf435d8b0eb34282c13bca45c", "class_name": "RelatedNodeInfo"}}, "hash": "ec93af5e770e227bde224aa29f09d11de4d831bfc03ce0da6513e3a0339b2c16", "text": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n", "start_char_idx": 45710, "end_char_idx": 45911, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "668ae3d0-60a9-4bd8-aca5-1c07db435bba": {"__data__": {"id_": "668ae3d0-60a9-4bd8-aca5-1c07db435bba", "embedding": null, "metadata": {"window": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n", "original_text": "So I hope you can see this. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "40433071-83e9-4793-a71a-9185fde18a16", "node_type": "1", "metadata": {"window": "So it had the right \nanswers, and you wanted the algorithm to just produce more of the same.  \n In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. ", "original_text": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n"}, "hash": "ec93af5e770e227bde224aa29f09d11de4d831bfc03ce0da6513e3a0339b2c16", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e14ae856-39fc-47b4-95df-90f9b12ec9e1", "node_type": "1", "metadata": {"window": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. ", "original_text": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. "}, "hash": "c9de5ee4c59f098a34324a4861609c0081c31608863c7f66c9fe20fc7dba5ec2", "class_name": "RelatedNodeInfo"}}, "hash": "b977490a5edf3febf606f84dd7ec9f4388c891eaf435d8b0eb34282c13bca45c", "text": "So I hope you can see this. ", "start_char_idx": 45911, "end_char_idx": 45939, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e14ae856-39fc-47b4-95df-90f9b12ec9e1": {"__data__": {"id_": "e14ae856-39fc-47b4-95df-90f9b12ec9e1", "embedding": null, "metadata": {"window": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. ", "original_text": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "668ae3d0-60a9-4bd8-aca5-1c07db435bba", "node_type": "1", "metadata": {"window": "In contrast, in an unsupervised learning problem , this is the sort of data you get, okay? \n Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n", "original_text": "So I hope you can see this. "}, "hash": "b977490a5edf3febf606f84dd7ec9f4388c891eaf435d8b0eb34282c13bca45c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f19f2877-7b3c-4649-8670-80a7125c9f13", "node_type": "1", "metadata": {"window": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right. ", "original_text": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n"}, "hash": "dc65df04b4b0da51cfd1250d1d3bc581e475aeeec40956a68fdf30f1eb0db8b3", "class_name": "RelatedNodeInfo"}}, "hash": "c9de5ee4c59f098a34324a4861609c0081c31608863c7f66c9fe20fc7dba5ec2", "text": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. ", "start_char_idx": 45939, "end_char_idx": 46039, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f19f2877-7b3c-4649-8670-80a7125c9f13": {"__data__": {"id_": "f19f2877-7b3c-4649-8670-80a7125c9f13", "embedding": null, "metadata": {"window": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right. ", "original_text": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e14ae856-39fc-47b4-95df-90f9b12ec9e1", "node_type": "1", "metadata": {"window": "Where speaking loosely, you're given a data se t, and I'm not gonna tell you what the right \nanswer is on any of your data.  I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. ", "original_text": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems. "}, "hash": "c9de5ee4c59f098a34324a4861609c0081c31608863c7f66c9fe20fc7dba5ec2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c70af8e-8005-420e-86e3-b5b1a05056ff", "node_type": "1", "metadata": {"window": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n", "original_text": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. "}, "hash": "094f5f5fe3e61cf7a43306de2bd724c153c1fd82d36e79d78e34f5bf571902e6", "class_name": "RelatedNodeInfo"}}, "hash": "dc65df04b4b0da51cfd1250d1d3bc581e475aeeec40956a68fdf30f1eb0db8b3", "text": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n", "start_char_idx": 46039, "end_char_idx": 46417, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c70af8e-8005-420e-86e3-b5b1a05056ff": {"__data__": {"id_": "9c70af8e-8005-420e-86e3-b5b1a05056ff", "embedding": null, "metadata": {"window": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n", "original_text": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f19f2877-7b3c-4649-8670-80a7125c9f13", "node_type": "1", "metadata": {"window": "I'm just gonna give you a data set and I'm gonna say, \"Would you please find interesting structure in this data set?\"  So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right. ", "original_text": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n"}, "hash": "dc65df04b4b0da51cfd1250d1d3bc581e475aeeec40956a68fdf30f1eb0db8b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "32b52772-c87d-44b7-b26b-bd304a448f62", "node_type": "1", "metadata": {"window": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n", "original_text": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n"}, "hash": "49234b89091676bc8d7725197db28a705b5e1a1ca1628338997fb89e6a914185", "class_name": "RelatedNodeInfo"}}, "hash": "094f5f5fe3e61cf7a43306de2bd724c153c1fd82d36e79d78e34f5bf571902e6", "text": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. ", "start_char_idx": 46417, "end_char_idx": 46589, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "32b52772-c87d-44b7-b26b-bd304a448f62": {"__data__": {"id_": "32b52772-c87d-44b7-b26b-bd304a448f62", "embedding": null, "metadata": {"window": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n", "original_text": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c70af8e-8005-420e-86e3-b5b1a05056ff", "node_type": "1", "metadata": {"window": "So that's the unsupervised \nlearning problem where you're sort of not given the right answer for everything.  \n So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n", "original_text": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student. "}, "hash": "094f5f5fe3e61cf7a43306de2bd724c153c1fd82d36e79d78e34f5bf571902e6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7443d33-d878-4b74-8a32-920171f26844", "node_type": "1", "metadata": {"window": "So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? ", "original_text": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. "}, "hash": "c4319e6ace791be9fab4488dd7aa6092e9ed2865918fc9bf85d0ab40ee00dcdf", "class_name": "RelatedNodeInfo"}}, "hash": "49234b89091676bc8d7725197db28a705b5e1a1ca1628338997fb89e6a914185", "text": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n", "start_char_idx": 46589, "end_char_idx": 46872, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c7443d33-d878-4b74-8a32-920171f26844": {"__data__": {"id_": "c7443d33-d878-4b74-8a32-920171f26844", "embedding": null, "metadata": {"window": "So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? ", "original_text": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32b52772-c87d-44b7-b26b-bd304a448f62", "node_type": "1", "metadata": {"window": "So, for example, an algorithm may find structure in the data in the form of the data being \npartitioned into two clusters, or clustering is  sort of one example of an unsupervised \nlearning problem.  \n So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n", "original_text": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n"}, "hash": "49234b89091676bc8d7725197db28a705b5e1a1ca1628338997fb89e6a914185", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c37c76a-9ec5-4ce0-843e-fddd965e5ca7", "node_type": "1", "metadata": {"window": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus. ", "original_text": "On a small di splay, it might be easier to just look at the \nimage on the right. "}, "hash": "eae1c7ea9d2520b189c50dc97a6bb716d10cb5d0384a1d64cb4eb52d477c76f1", "class_name": "RelatedNodeInfo"}}, "hash": "c4319e6ace791be9fab4488dd7aa6092e9ed2865918fc9bf85d0ab40ee00dcdf", "text": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. ", "start_char_idx": 46872, "end_char_idx": 47082, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2c37c76a-9ec5-4ce0-843e-fddd965e5ca7": {"__data__": {"id_": "2c37c76a-9ec5-4ce0-843e-fddd965e5ca7", "embedding": null, "metadata": {"window": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus. ", "original_text": "On a small di splay, it might be easier to just look at the \nimage on the right. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7443d33-d878-4b74-8a32-920171f26844", "node_type": "1", "metadata": {"window": "So I hope you can see this.  It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? ", "original_text": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together. "}, "hash": "c4319e6ace791be9fab4488dd7aa6092e9ed2865918fc9bf85d0ab40ee00dcdf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "016e716e-d121-422f-8d45-48233f6b8769", "node_type": "1", "metadata": {"window": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. ", "original_text": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n"}, "hash": "1520fbb8001424d80d4be0511b723caedfab1e76110a94f2307f4d8a4235ff87", "class_name": "RelatedNodeInfo"}}, "hash": "eae1c7ea9d2520b189c50dc97a6bb716d10cb5d0384a1d64cb4eb52d477c76f1", "text": "On a small di splay, it might be easier to just look at the \nimage on the right. ", "start_char_idx": 47082, "end_char_idx": 47163, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "016e716e-d121-422f-8d45-48233f6b8769": {"__data__": {"id_": "016e716e-d121-422f-8d45-48233f6b8769", "embedding": null, "metadata": {"window": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. ", "original_text": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c37c76a-9ec5-4ce0-843e-fddd965e5ca7", "node_type": "1", "metadata": {"window": "It turns out that th ese sort of unsupervised  learning algorithms \nare also used in many problems.  This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus. ", "original_text": "On a small di splay, it might be easier to just look at the \nimage on the right. "}, "hash": "eae1c7ea9d2520b189c50dc97a6bb716d10cb5d0384a1d64cb4eb52d477c76f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8cdca243-2939-4fcd-8b27-9f82fd1ea045", "node_type": "1", "metadata": {"window": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly. ", "original_text": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n"}, "hash": "7cb079561b9595c84f366b2841a778ceb2f8760cd96c8ad5d8d3f8c763d97f20", "class_name": "RelatedNodeInfo"}}, "hash": "1520fbb8001424d80d4be0511b723caedfab1e76110a94f2307f4d8a4235ff87", "text": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n", "start_char_idx": 47163, "end_char_idx": 47299, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8cdca243-2939-4fcd-8b27-9f82fd1ea045": {"__data__": {"id_": "8cdca243-2939-4fcd-8b27-9f82fd1ea045", "embedding": null, "metadata": {"window": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly. ", "original_text": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "016e716e-d121-422f-8d45-48233f6b8769", "node_type": "1", "metadata": {"window": "This is a scr een shot \u2014 this is a picture I got from Sue \nEmvee, who's a PhD student here, who is a pplying unsupervised learning algorithms to \ntry to understand gene data, so is trying to  look at genes as individuals and group them \ninto clusters based on properties of what ge nes they respond to \u2014 based on properties of \nhow the genes respond to different experiments.  \n Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. ", "original_text": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n"}, "hash": "1520fbb8001424d80d4be0511b723caedfab1e76110a94f2307f4d8a4235ff87", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b656cb2-4d3d-4a95-a705-e6e29bda12d0", "node_type": "1", "metadata": {"window": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay. ", "original_text": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? "}, "hash": "f5f1b79b36cde8dc264706cf88cdbf4a063b970ce17a2b25a8fad9f891ed7d40", "class_name": "RelatedNodeInfo"}}, "hash": "7cb079561b9595c84f366b2841a778ceb2f8760cd96c8ad5d8d3f8c763d97f20", "text": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n", "start_char_idx": 47299, "end_char_idx": 47549, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b656cb2-4d3d-4a95-a705-e6e29bda12d0": {"__data__": {"id_": "0b656cb2-4d3d-4a95-a705-e6e29bda12d0", "embedding": null, "metadata": {"window": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay. ", "original_text": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8cdca243-2939-4fcd-8b27-9f82fd1ea045", "node_type": "1", "metadata": {"window": "Another interesting application of [inaudible] sorts of clus tering algorithms is actually \nimage processing, this which I got from Steve Gules, who's another PhD student.  It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly. ", "original_text": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n"}, "hash": "7cb079561b9595c84f366b2841a778ceb2f8760cd96c8ad5d8d3f8c763d97f20", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc4ca96c-758b-4816-830e-c30ed5de9340", "node_type": "1", "metadata": {"window": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n", "original_text": "This is actually a \npicture taken of the Stanford campus. "}, "hash": "cc57e25eed17ffcb3a86beb5191111265c5693d463a66f5053edc07ebdaf5dcd", "class_name": "RelatedNodeInfo"}}, "hash": "f5f1b79b36cde8dc264706cf88cdbf4a063b970ce17a2b25a8fad9f891ed7d40", "text": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? ", "start_char_idx": 47549, "end_char_idx": 47712, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc4ca96c-758b-4816-830e-c30ed5de9340": {"__data__": {"id_": "bc4ca96c-758b-4816-830e-c30ed5de9340", "embedding": null, "metadata": {"window": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n", "original_text": "This is actually a \npicture taken of the Stanford campus. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b656cb2-4d3d-4a95-a705-e6e29bda12d0", "node_type": "1", "metadata": {"window": "It turns \nout what you can do is if you give this sort of  data, say an image, to certain unsupervised \nlearning algorithms, they will then learn to group pixels together and say, gee, this sort of \npixel seems to belong together , and that sort of pixel seems to belong together.  \n And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay. ", "original_text": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right? "}, "hash": "f5f1b79b36cde8dc264706cf88cdbf4a063b970ce17a2b25a8fad9f891ed7d40", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "47532ce1-e3d7-444d-9685-9e5a8b7d3f83", "node_type": "1", "metadata": {"window": "On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? ", "original_text": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. "}, "hash": "aedf8ead2d08d9d9258e280e35e42271f7ff0a01745b4153eed5123f8b948c13", "class_name": "RelatedNodeInfo"}}, "hash": "cc57e25eed17ffcb3a86beb5191111265c5693d463a66f5053edc07ebdaf5dcd", "text": "This is actually a \npicture taken of the Stanford campus. ", "start_char_idx": 47712, "end_char_idx": 47770, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "47532ce1-e3d7-444d-9685-9e5a8b7d3f83": {"__data__": {"id_": "47532ce1-e3d7-444d-9685-9e5a8b7d3f83", "embedding": null, "metadata": {"window": "On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? ", "original_text": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc4ca96c-758b-4816-830e-c30ed5de9340", "node_type": "1", "metadata": {"window": "And so the images you see on the bottom \u2014 I guess you can just barely see them on there \n\u2014 so the images you see on the bottom are groupings \u2014 are what the algorithm has done \nto group certain pixels together.  On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n", "original_text": "This is actually a \npicture taken of the Stanford campus. "}, "hash": "cc57e25eed17ffcb3a86beb5191111265c5693d463a66f5053edc07ebdaf5dcd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb36cdcb-67b4-42a3-b8d0-51145d5438ef", "node_type": "1", "metadata": {"window": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? ", "original_text": "Let me actually blow that up so that you can see it more \nclearly. "}, "hash": "d37c714072f0ff1bba1ae8cd304ba9ba89cc6968e61eef1d1556dfc2fb19b24b", "class_name": "RelatedNodeInfo"}}, "hash": "aedf8ead2d08d9d9258e280e35e42271f7ff0a01745b4153eed5123f8b948c13", "text": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. ", "start_char_idx": 47770, "end_char_idx": 47856, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eb36cdcb-67b4-42a3-b8d0-51145d5438ef": {"__data__": {"id_": "eb36cdcb-67b4-42a3-b8d0-51145d5438ef", "embedding": null, "metadata": {"window": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? ", "original_text": "Let me actually blow that up so that you can see it more \nclearly. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "47532ce1-e3d7-444d-9685-9e5a8b7d3f83", "node_type": "1", "metadata": {"window": "On a small di splay, it might be easier to just look at the \nimage on the right.  The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? ", "original_text": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. "}, "hash": "aedf8ead2d08d9d9258e280e35e42271f7ff0a01745b4153eed5123f8b948c13", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4e19a358-74fd-4fc5-9c6d-269a181be261", "node_type": "1", "metadata": {"window": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "d37c714072f0ff1bba1ae8cd304ba9ba89cc6968e61eef1d1556dfc2fb19b24b", "text": "Let me actually blow that up so that you can see it more \nclearly. ", "start_char_idx": 47856, "end_char_idx": 47923, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4e19a358-74fd-4fc5-9c6d-269a181be261": {"__data__": {"id_": "4e19a358-74fd-4fc5-9c6d-269a181be261", "embedding": null, "metadata": {"window": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. ", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb36cdcb-67b4-42a3-b8d0-51145d5438ef", "node_type": "1", "metadata": {"window": "The two images on the botto m are two sort of identical visualizations \nof the same grouping of the pixe ls into [inaudible] regions.  \n And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? ", "original_text": "Let me actually blow that up so that you can see it more \nclearly. "}, "hash": "d37c714072f0ff1bba1ae8cd304ba9ba89cc6968e61eef1d1556dfc2fb19b24b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f60e269e-b019-4b20-8208-9b0505915eb4", "node_type": "1", "metadata": {"window": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n", "original_text": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n"}, "hash": "cfb1ab1f852095280005011f0e31b36b8bf1ae24f1731588b2916bb7754a871e", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f60e269e-b019-4b20-8208-9b0505915eb4": {"__data__": {"id_": "f60e269e-b019-4b20-8208-9b0505915eb4", "embedding": null, "metadata": {"window": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n", "original_text": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e19a358-74fd-4fc5-9c6d-269a181be261", "node_type": "1", "metadata": {"window": "And so it turns out that this sort of clustering algorithm or this sort of unsupervised \nlearning algorithm, which learns  to group pixels together, it turns out to be useful for \nmany applications in vision, in co mputer vision image processing.  \n\n I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b67a7c17-88cc-437f-aebb-2d98cabbc956", "node_type": "1", "metadata": {"window": "This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example. ", "original_text": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? "}, "hash": "3be103ba54b43510033d286fac3894b8cff51735ca627fabe83f1f7259339152", "class_name": "RelatedNodeInfo"}}, "hash": "cfb1ab1f852095280005011f0e31b36b8bf1ae24f1731588b2916bb7754a871e", "text": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n", "start_char_idx": 47929, "end_char_idx": 48051, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b67a7c17-88cc-437f-aebb-2d98cabbc956": {"__data__": {"id_": "b67a7c17-88cc-437f-aebb-2d98cabbc956", "embedding": null, "metadata": {"window": "This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example. ", "original_text": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f60e269e-b019-4b20-8208-9b0505915eb4", "node_type": "1", "metadata": {"window": "I'll just show you one example, and this is a rather cool one that two students, Ashutosh \nSaxena and Min Sun here did, wh ich is given an image like this, right?  This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n", "original_text": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n"}, "hash": "cfb1ab1f852095280005011f0e31b36b8bf1ae24f1731588b2916bb7754a871e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "821d00ce-3ffb-4a6b-b5e4-d4328e55ab9d", "node_type": "1", "metadata": {"window": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. ", "original_text": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? "}, "hash": "663af597180a96119b3e166e212745b3df1b549b902dc54978a91a70919a696f", "class_name": "RelatedNodeInfo"}}, "hash": "3be103ba54b43510033d286fac3894b8cff51735ca627fabe83f1f7259339152", "text": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? ", "start_char_idx": 48051, "end_char_idx": 48209, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "821d00ce-3ffb-4a6b-b5e4-d4328e55ab9d": {"__data__": {"id_": "821d00ce-3ffb-4a6b-b5e4-d4328e55ab9d", "embedding": null, "metadata": {"window": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. ", "original_text": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b67a7c17-88cc-437f-aebb-2d98cabbc956", "node_type": "1", "metadata": {"window": "This is actually a \npicture taken of the Stanford campus.  You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example. ", "original_text": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? "}, "hash": "3be103ba54b43510033d286fac3894b8cff51735ca627fabe83f1f7259339152", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a025ee01-765a-4fe7-b987-70773f892c75", "node_type": "1", "metadata": {"window": "Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. ", "original_text": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. "}, "hash": "628fee9eeac2652f0e3d51e1a1d04d8efc5f33b14784075ac71d515145e0401a", "class_name": "RelatedNodeInfo"}}, "hash": "663af597180a96119b3e166e212745b3df1b549b902dc54978a91a70919a696f", "text": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? ", "start_char_idx": 48209, "end_char_idx": 48419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a025ee01-765a-4fe7-b987-70773f892c75": {"__data__": {"id_": "a025ee01-765a-4fe7-b987-70773f892c75", "embedding": null, "metadata": {"window": "Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. ", "original_text": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "821d00ce-3ffb-4a6b-b5e4-d4328e55ab9d", "node_type": "1", "metadata": {"window": "You can apply that sort of cl ustering algorithm and \ngroup the picture into regions.  Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. ", "original_text": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? "}, "hash": "663af597180a96119b3e166e212745b3df1b549b902dc54978a91a70919a696f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80b64f2e-cc2c-485c-a303-99c05e29be66", "node_type": "1", "metadata": {"window": "Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  ", "original_text": "They were able to.  \n"}, "hash": "6c9422041a1a16c6671ccc50b5df455ce4a26e444efbda7d632c230607b943c6", "class_name": "RelatedNodeInfo"}}, "hash": "628fee9eeac2652f0e3d51e1a1d04d8efc5f33b14784075ac71d515145e0401a", "text": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. ", "start_char_idx": 48419, "end_char_idx": 48609, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "80b64f2e-cc2c-485c-a303-99c05e29be66": {"__data__": {"id_": "80b64f2e-cc2c-485c-a303-99c05e29be66", "embedding": null, "metadata": {"window": "Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  ", "original_text": "They were able to.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a025ee01-765a-4fe7-b987-70773f892c75", "node_type": "1", "metadata": {"window": "Let me actually blow that up so that you can see it more \nclearly.  Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. ", "original_text": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. "}, "hash": "628fee9eeac2652f0e3d51e1a1d04d8efc5f33b14784075ac71d515145e0401a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "34f167fc-3499-4134-acba-1988337f4014", "node_type": "1", "metadata": {"window": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus. ", "original_text": "I'll just show you one more example. "}, "hash": "a84f01eaaad1980ba17345264e7c554fa5ae259b8e25c38cf7488e13762a332c", "class_name": "RelatedNodeInfo"}}, "hash": "6c9422041a1a16c6671ccc50b5df455ce4a26e444efbda7d632c230607b943c6", "text": "They were able to.  \n", "start_char_idx": 48609, "end_char_idx": 48630, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "34f167fc-3499-4134-acba-1988337f4014": {"__data__": {"id_": "34f167fc-3499-4134-acba-1988337f4014", "embedding": null, "metadata": {"window": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus. ", "original_text": "I'll just show you one more example. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80b64f2e-cc2c-485c-a303-99c05e29be66", "node_type": "1", "metadata": {"window": "Okay.  So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  ", "original_text": "They were able to.  \n"}, "hash": "6c9422041a1a16c6671ccc50b5df455ce4a26e444efbda7d632c230607b943c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8948b952-3e7c-4e3c-990b-821406c6ba8d", "node_type": "1", "metadata": {"window": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay? ", "original_text": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. "}, "hash": "c476dabc8ab6294be6190aa8d0ee3713d3f607eb24b110de615a32e679ecfa3d", "class_name": "RelatedNodeInfo"}}, "hash": "a84f01eaaad1980ba17345264e7c554fa5ae259b8e25c38cf7488e13762a332c", "text": "I'll just show you one more example. ", "start_char_idx": 48630, "end_char_idx": 48667, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8948b952-3e7c-4e3c-990b-821406c6ba8d": {"__data__": {"id_": "8948b952-3e7c-4e3c-990b-821406c6ba8d", "embedding": null, "metadata": {"window": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay? ", "original_text": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "34f167fc-3499-4134-acba-1988337f4014", "node_type": "1", "metadata": {"window": "So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \n And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus. ", "original_text": "I'll just show you one more example. "}, "hash": "a84f01eaaad1980ba17345264e7c554fa5ae259b8e25c38cf7488e13762a332c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f5e04ee3-8481-4d7b-9b84-4cd8a4615601", "node_type": "1", "metadata": {"window": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n", "original_text": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. "}, "hash": "4478fed26e581e48ff49f14d4748d3485df536270592ebc184d52e10b12c3d70", "class_name": "RelatedNodeInfo"}}, "hash": "c476dabc8ab6294be6190aa8d0ee3713d3f607eb24b110de615a32e679ecfa3d", "text": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. ", "start_char_idx": 48667, "end_char_idx": 48752, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f5e04ee3-8481-4d7b-9b84-4cd8a4615601": {"__data__": {"id_": "f5e04ee3-8481-4d7b-9b84-4cd8a4615601", "embedding": null, "metadata": {"window": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n", "original_text": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8948b952-3e7c-4e3c-990b-821406c6ba8d", "node_type": "1", "metadata": {"window": "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world?  And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay? ", "original_text": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus. "}, "hash": "c476dabc8ab6294be6190aa8d0ee3713d3f607eb24b110de615a32e679ecfa3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "003ce0ec-b725-45ec-969c-7dc9ac2945dc", "node_type": "1", "metadata": {"window": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. ", "original_text": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  "}, "hash": "4664edb799eb32e1ad2c625e5284af0ceffad28a2d15423bb4b8946f2696191d", "class_name": "RelatedNodeInfo"}}, "hash": "4478fed26e581e48ff49f14d4748d3485df536270592ebc184d52e10b12c3d70", "text": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. ", "start_char_idx": 48752, "end_char_idx": 48919, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "003ce0ec-b725-45ec-969c-7dc9ac2945dc": {"__data__": {"id_": "003ce0ec-b725-45ec-969c-7dc9ac2945dc", "embedding": null, "metadata": {"window": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. ", "original_text": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5e04ee3-8481-4d7b-9b84-4cd8a4615601", "node_type": "1", "metadata": {"window": "And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay?  Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n", "original_text": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. "}, "hash": "4478fed26e581e48ff49f14d4748d3485df536270592ebc184d52e10b12c3d70", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a56689fe-cb60-48f5-9974-2b31636bfb4e", "node_type": "1", "metadata": {"window": "They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n", "original_text": "You can sort of walk  into the ceiling, look \naround the campus. "}, "hash": "9cab8dc571715a53c852ecfbfd1f371e50b635c42fd3c18f25f2cae0986b2b52", "class_name": "RelatedNodeInfo"}}, "hash": "4664edb799eb32e1ad2c625e5284af0ceffad28a2d15423bb4b8946f2696191d", "text": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  ", "start_char_idx": 48919, "end_char_idx": 49045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a56689fe-cb60-48f5-9974-2b31636bfb4e": {"__data__": {"id_": "a56689fe-cb60-48f5-9974-2b31636bfb4e", "embedding": null, "metadata": {"window": "They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n", "original_text": "You can sort of walk  into the ceiling, look \naround the campus. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "003ce0ec-b725-45ec-969c-7dc9ac2945dc", "node_type": "1", "metadata": {"window": "Although many people used to th ink it's not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step.  They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. ", "original_text": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  "}, "hash": "4664edb799eb32e1ad2c625e5284af0ceffad28a2d15423bb4b8946f2696191d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0133695e-aa59-4eae-b537-737685d8e209", "node_type": "1", "metadata": {"window": "I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. ", "original_text": "Okay? "}, "hash": "4d3e68bca90ddaf8c09462831b3a76341205036ed73f7ae3fed29e9afa7e3224", "class_name": "RelatedNodeInfo"}}, "hash": "9cab8dc571715a53c852ecfbfd1f371e50b635c42fd3c18f25f2cae0986b2b52", "text": "You can sort of walk  into the ceiling, look \naround the campus. ", "start_char_idx": 49045, "end_char_idx": 49110, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0133695e-aa59-4eae-b537-737685d8e209": {"__data__": {"id_": "0133695e-aa59-4eae-b537-737685d8e209", "embedding": null, "metadata": {"window": "I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. ", "original_text": "Okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a56689fe-cb60-48f5-9974-2b31636bfb4e", "node_type": "1", "metadata": {"window": "They were able to.  \n I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n", "original_text": "You can sort of walk  into the ceiling, look \naround the campus. "}, "hash": "9cab8dc571715a53c852ecfbfd1f371e50b635c42fd3c18f25f2cae0986b2b52", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6387dec4-f4ab-4dda-86a5-23ebe90b7283", "node_type": "1", "metadata": {"window": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. ", "original_text": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n"}, "hash": "245f15fa6efb799d0399961fcd9d2e2b126a9d4d67df6dc7031bc9dab2451a54", "class_name": "RelatedNodeInfo"}}, "hash": "4d3e68bca90ddaf8c09462831b3a76341205036ed73f7ae3fed29e9afa7e3224", "text": "Okay? ", "start_char_idx": 41914, "end_char_idx": 41920, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6387dec4-f4ab-4dda-86a5-23ebe90b7283": {"__data__": {"id_": "6387dec4-f4ab-4dda-86a5-23ebe90b7283", "embedding": null, "metadata": {"window": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. ", "original_text": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0133695e-aa59-4eae-b537-737685d8e209", "node_type": "1", "metadata": {"window": "I'll just show you one more example.  I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. ", "original_text": "Okay? "}, "hash": "4d3e68bca90ddaf8c09462831b3a76341205036ed73f7ae3fed29e9afa7e3224", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "61599069-a903-44ea-a6ea-42cdfbe2a107", "node_type": "1", "metadata": {"window": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n", "original_text": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. "}, "hash": "e2c68395e1d3bce76e502a5884191e48d67e5681d74e925a188502405902d958", "class_name": "RelatedNodeInfo"}}, "hash": "245f15fa6efb799d0399961fcd9d2e2b126a9d4d67df6dc7031bc9dab2451a54", "text": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n", "start_char_idx": 49116, "end_char_idx": 49275, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61599069-a903-44ea-a6ea-42cdfbe2a107": {"__data__": {"id_": "61599069-a903-44ea-a6ea-42cdfbe2a107", "embedding": null, "metadata": {"window": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n", "original_text": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6387dec4-f4ab-4dda-86a5-23ebe90b7283", "node_type": "1", "metadata": {"window": "I like this  because it's a picture of Stanford with our \nbeautiful Stanford campus.  So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. ", "original_text": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n"}, "hash": "245f15fa6efb799d0399961fcd9d2e2b126a9d4d67df6dc7031bc9dab2451a54", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8d6e6d5b-cc78-4dcf-ba37-6427ebcaa824", "node_type": "1", "metadata": {"window": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people. ", "original_text": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n"}, "hash": "17e5a6256d7b7f241dabf9c5888a696408ddade62c93267b169c432274321880", "class_name": "RelatedNodeInfo"}}, "hash": "e2c68395e1d3bce76e502a5884191e48d67e5681d74e925a188502405902d958", "text": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. ", "start_char_idx": 49275, "end_char_idx": 49717, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8d6e6d5b-cc78-4dcf-ba37-6427ebcaa824": {"__data__": {"id_": "8d6e6d5b-cc78-4dcf-ba37-6427ebcaa824", "embedding": null, "metadata": {"window": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people. ", "original_text": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61599069-a903-44ea-a6ea-42cdfbe2a107", "node_type": "1", "metadata": {"window": "So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions.  And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n", "original_text": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed. "}, "hash": "e2c68395e1d3bce76e502a5884191e48d67e5681d74e925a188502405902d958", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4009c188-a9f7-4a4c-a539-88c403736979", "node_type": "1", "metadata": {"window": "You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n", "original_text": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. "}, "hash": "19d7803d4e92a1c49038c0fa16784713e36af8d7b027305291b204e2751e5721", "class_name": "RelatedNodeInfo"}}, "hash": "17e5a6256d7b7f241dabf9c5888a696408ddade62c93267b169c432274321880", "text": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n", "start_char_idx": 49717, "end_char_idx": 49885, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4009c188-a9f7-4a4c-a539-88c403736979": {"__data__": {"id_": "4009c188-a9f7-4a4c-a539-88c403736979", "embedding": null, "metadata": {"window": "You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n", "original_text": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8d6e6d5b-cc78-4dcf-ba37-6427ebcaa824", "node_type": "1", "metadata": {"window": "And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.   You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people. ", "original_text": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n"}, "hash": "17e5a6256d7b7f241dabf9c5888a696408ddade62c93267b169c432274321880", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d98686a-7ef4-4ae6-9679-a7b953702686", "node_type": "1", "metadata": {"window": "Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  ", "original_text": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. "}, "hash": "02654bbc9b21b836094ff408227b04df1ba53fab12df334b2fb2699f753dcd56", "class_name": "RelatedNodeInfo"}}, "hash": "19d7803d4e92a1c49038c0fa16784713e36af8d7b027305291b204e2751e5721", "text": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. ", "start_char_idx": 49885, "end_char_idx": 49991, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4d98686a-7ef4-4ae6-9679-a7b953702686": {"__data__": {"id_": "4d98686a-7ef4-4ae6-9679-a7b953702686", "embedding": null, "metadata": {"window": "Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  ", "original_text": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4009c188-a9f7-4a4c-a539-88c403736979", "node_type": "1", "metadata": {"window": "You can sort of walk  into the ceiling, look \naround the campus.  Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n", "original_text": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about. "}, "hash": "19d7803d4e92a1c49038c0fa16784713e36af8d7b027305291b204e2751e5721", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd65e785-b470-4072-a8d9-190ef2b55db4", "node_type": "1", "metadata": {"window": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay? ", "original_text": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n"}, "hash": "b64fb74b1a7074724578cf3b52ac8de8f32ce3acf8e6b232685f789127540ab6", "class_name": "RelatedNodeInfo"}}, "hash": "02654bbc9b21b836094ff408227b04df1ba53fab12df334b2fb2699f753dcd56", "text": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. ", "start_char_idx": 49991, "end_char_idx": 50185, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd65e785-b470-4072-a8d9-190ef2b55db4": {"__data__": {"id_": "bd65e785-b470-4072-a8d9-190ef2b55db4", "embedding": null, "metadata": {"window": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay? ", "original_text": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d98686a-7ef4-4ae6-9679-a7b953702686", "node_type": "1", "metadata": {"window": "Okay?  This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  ", "original_text": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over. "}, "hash": "02654bbc9b21b836094ff408227b04df1ba53fab12df334b2fb2699f753dcd56", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ba13b95-dee9-42f1-b93e-668a642afad5", "node_type": "1", "metadata": {"window": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n", "original_text": "So imagine a large cocktail party with lots of people. "}, "hash": "b101565de032ed58ebfbbae890574ecd6e4c08df3ee814f716a403ebb9bc2b60", "class_name": "RelatedNodeInfo"}}, "hash": "b64fb74b1a7074724578cf3b52ac8de8f32ce3acf8e6b232685f789127540ab6", "text": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n", "start_char_idx": 50185, "end_char_idx": 50338, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3ba13b95-dee9-42f1-b93e-668a642afad5": {"__data__": {"id_": "3ba13b95-dee9-42f1-b93e-668a642afad5", "embedding": null, "metadata": {"window": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n", "original_text": "So imagine a large cocktail party with lots of people. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd65e785-b470-4072-a8d9-190ef2b55db4", "node_type": "1", "metadata": {"window": "This actually turned out to be a mix of supervised and \nunsupervised learning, but the unsupervised lear ning, this sort of cl ustering was the first \nstep.  \n So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay? ", "original_text": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n"}, "hash": "b64fb74b1a7074724578cf3b52ac8de8f32ce3acf8e6b232685f789127540ab6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79052100-532a-4b26-9577-17897bf09126", "node_type": "1", "metadata": {"window": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? ", "original_text": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n"}, "hash": "dc39eafef4ccb98ca9afcbaffffdd728b87035f1b5aebfc84eca225c8d9c7626", "class_name": "RelatedNodeInfo"}}, "hash": "b101565de032ed58ebfbbae890574ecd6e4c08df3ee814f716a403ebb9bc2b60", "text": "So imagine a large cocktail party with lots of people. ", "start_char_idx": 50338, "end_char_idx": 50393, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "79052100-532a-4b26-9577-17897bf09126": {"__data__": {"id_": "79052100-532a-4b26-9577-17897bf09126", "embedding": null, "metadata": {"window": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? ", "original_text": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3ba13b95-dee9-42f1-b93e-668a642afad5", "node_type": "1", "metadata": {"window": "So it turns out these sorts of unsupervised \u2014 clustering algorithms are actually routinely \nused for many different problems, things like organizing computing clusters, social \nnetwork analysis, market segmentation, so if you're a marketer and you want to divide your market into different segments or diffe rent groups of people to market to them \nseparately; even for astronomical data an alysis and understanding how galaxies are \nformed.  These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n", "original_text": "So imagine a large cocktail party with lots of people. "}, "hash": "b101565de032ed58ebfbbae890574ecd6e4c08df3ee814f716a403ebb9bc2b60", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7c22f2e-5c90-463d-9074-d050017b3afa", "node_type": "1", "metadata": {"window": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. ", "original_text": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  "}, "hash": "75944f91bc00fe8df8ccb9a7bc7a24fc6404fca126883353d794516d0625a920", "class_name": "RelatedNodeInfo"}}, "hash": "dc39eafef4ccb98ca9afcbaffffdd728b87035f1b5aebfc84eca225c8d9c7626", "text": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n", "start_char_idx": 50393, "end_char_idx": 50572, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d7c22f2e-5c90-463d-9074-d050017b3afa": {"__data__": {"id_": "d7c22f2e-5c90-463d-9074-d050017b3afa", "embedding": null, "metadata": {"window": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. ", "original_text": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "79052100-532a-4b26-9577-17897bf09126", "node_type": "1", "metadata": {"window": "These are just a sort of small sample  of the applications of unsupervised learning \nalgorithms and clustering algorithms that we 'll talk about later in this class.  \n Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? ", "original_text": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n"}, "hash": "dc39eafef4ccb98ca9afcbaffffdd728b87035f1b5aebfc84eca225c8d9c7626", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cd5e0a38-7c94-4362-9fcd-a49b6ef3be69", "node_type": "1", "metadata": {"window": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. ", "original_text": "But what we're gonna do is we'll put two \nmicrophones in the room, okay? "}, "hash": "5f95dee6f3fc74f1eb7de33dc7df3515de30a267ecc242f3a4748d437ee18352", "class_name": "RelatedNodeInfo"}}, "hash": "75944f91bc00fe8df8ccb9a7bc7a24fc6404fca126883353d794516d0625a920", "text": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  ", "start_char_idx": 50572, "end_char_idx": 50711, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cd5e0a38-7c94-4362-9fcd-a49b6ef3be69": {"__data__": {"id_": "cd5e0a38-7c94-4362-9fcd-a49b6ef3be69", "embedding": null, "metadata": {"window": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. ", "original_text": "But what we're gonna do is we'll put two \nmicrophones in the room, okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7c22f2e-5c90-463d-9074-d050017b3afa", "node_type": "1", "metadata": {"window": "Just one particularly cool example of an uns upervised learning algorithm that I want to \ntell you about.  And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. ", "original_text": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.  "}, "hash": "75944f91bc00fe8df8ccb9a7bc7a24fc6404fca126883353d794516d0625a920", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad40ef08-fe7f-440f-ad47-6a9e7999266e", "node_type": "1", "metadata": {"window": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n"}, "hash": "a1b6faa6f1780401dfbf43a41296ae2c9df826d4fbdacc12c54262707e2cab4d", "class_name": "RelatedNodeInfo"}}, "hash": "5f95dee6f3fc74f1eb7de33dc7df3515de30a267ecc242f3a4748d437ee18352", "text": "But what we're gonna do is we'll put two \nmicrophones in the room, okay? ", "start_char_idx": 50711, "end_char_idx": 50784, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad40ef08-fe7f-440f-ad47-6a9e7999266e": {"__data__": {"id_": "ad40ef08-fe7f-440f-ad47-6a9e7999266e", "embedding": null, "metadata": {"window": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cd5e0a38-7c94-4362-9fcd-a49b6ef3be69", "node_type": "1", "metadata": {"window": "And to motivate that, I'm gonna  tell you about what's called the cocktail \nparty problem, which is imagine that you're at  some cocktail party a nd there are lots of \npeople standing all over.  And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. ", "original_text": "But what we're gonna do is we'll put two \nmicrophones in the room, okay? "}, "hash": "5f95dee6f3fc74f1eb7de33dc7df3515de30a267ecc242f3a4748d437ee18352", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9bd9e65a-9730-42a5-81ce-f0f08ba0d537", "node_type": "1", "metadata": {"window": "So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? "}, "hash": "e3c502311d5d164ce82240673a0ce2afd4e8e34d891372449163a581826b5998", "class_name": "RelatedNodeInfo"}}, "hash": "a1b6faa6f1780401dfbf43a41296ae2c9df826d4fbdacc12c54262707e2cab4d", "text": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n", "start_char_idx": 50784, "end_char_idx": 51192, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9bd9e65a-9730-42a5-81ce-f0f08ba0d537": {"__data__": {"id_": "9bd9e65a-9730-42a5-81ce-f0f08ba0d537", "embedding": null, "metadata": {"window": "So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad40ef08-fe7f-440f-ad47-6a9e7999266e", "node_type": "1", "metadata": {"window": "And you know how it is, right, if you're at a large party, \neveryone's talking, it can be sometimes very hard  to hear even the person in front of you. \n So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n"}, "hash": "a1b6faa6f1780401dfbf43a41296ae2c9df826d4fbdacc12c54262707e2cab4d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "31097176-a6bb-48e9-b7c4-080c23e41a19", "node_type": "1", "metadata": {"window": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. ", "original_text": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. "}, "hash": "937c8852282fd0cd963683da47806d8d9c3289c7c30199529ac921ad46e1b2f4", "class_name": "RelatedNodeInfo"}}, "hash": "e3c502311d5d164ce82240673a0ce2afd4e8e34d891372449163a581826b5998", "text": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? ", "start_char_idx": 51192, "end_char_idx": 51302, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "31097176-a6bb-48e9-b7c4-080c23e41a19": {"__data__": {"id_": "31097176-a6bb-48e9-b7c4-080c23e41a19", "embedding": null, "metadata": {"window": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. ", "original_text": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9bd9e65a-9730-42a5-81ce-f0f08ba0d537", "node_type": "1", "metadata": {"window": "So imagine a large cocktail party with lots of people.  So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices? "}, "hash": "e3c502311d5d164ce82240673a0ce2afd4e8e34d891372449163a581826b5998", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0967524-b167-4853-895c-f7ff2187318f", "node_type": "1", "metadata": {"window": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. "}, "hash": "9d59165d0ba84584fbbb332d43dd5371e2c4693fe270d1825896052f4927f361", "class_name": "RelatedNodeInfo"}}, "hash": "937c8852282fd0cd963683da47806d8d9c3289c7c30199529ac921ad46e1b2f4", "text": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. ", "start_char_idx": 51302, "end_char_idx": 51384, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d0967524-b167-4853-895c-f7ff2187318f": {"__data__": {"id_": "d0967524-b167-4853-895c-f7ff2187318f", "embedding": null, "metadata": {"window": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "31097176-a6bb-48e9-b7c4-080c23e41a19", "node_type": "1", "metadata": {"window": "So the problem is, is that all of these people talking, can you separate out the voice of just the person you're interested in \ntalking to with all this  loud background noise?  \n So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. ", "original_text": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD. "}, "hash": "937c8852282fd0cd963683da47806d8d9c3289c7c30199529ac921ad46e1b2f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f405114b-0c09-41b4-a745-c4caeb18244e", "node_type": "1", "metadata": {"window": "But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "aa2e4f5060c54eb6aee99c9ec55433a39745b98c2a79293af409eb5a605028da", "class_name": "RelatedNodeInfo"}}, "hash": "9d59165d0ba84584fbbb332d43dd5371e2c4693fe270d1825896052f4927f361", "text": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. ", "start_char_idx": 51384, "end_char_idx": 51482, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f405114b-0c09-41b4-a745-c4caeb18244e": {"__data__": {"id_": "f405114b-0c09-41b4-a745-c4caeb18244e", "embedding": null, "metadata": {"window": "But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d0967524-b167-4853-895c-f7ff2187318f", "node_type": "1", "metadata": {"window": "So I'll show you a specific example in a second, but here's a cocktail party that's I guess \nrather sparsely attended by just two people.   But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party. "}, "hash": "9d59165d0ba84584fbbb332d43dd5371e2c4693fe270d1825896052f4927f361", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6209543-41b5-4916-924e-4bef4e71bb49", "node_type": "1", "metadata": {"window": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay. ", "original_text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "class_name": "RelatedNodeInfo"}}, "hash": "aa2e4f5060c54eb6aee99c9ec55433a39745b98c2a79293af409eb5a605028da", "text": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "start_char_idx": 51482, "end_char_idx": 51590, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c6209543-41b5-4916-924e-4bef4e71bb49": {"__data__": {"id_": "c6209543-41b5-4916-924e-4bef4e71bb49", "embedding": null, "metadata": {"window": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay. ", "original_text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f405114b-0c09-41b4-a745-c4caeb18244e", "node_type": "1", "metadata": {"window": "But what we're gonna do is we'll put two \nmicrophones in the room, okay?  And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "aa2e4f5060c54eb6aee99c9ec55433a39745b98c2a79293af409eb5a605028da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6e831f2d-ccd0-4d5c-a6df-7d6606a8b5ac", "node_type": "1", "metadata": {"window": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right? ", "original_text": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. "}, "hash": "c572cab48c5c772689d1c71866ce65252ac6cdf2ec96f8fcbd4c7c37fd6e56e4", "class_name": "RelatedNodeInfo"}}, "hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "start_char_idx": 51590, "end_char_idx": 51671, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6e831f2d-ccd0-4d5c-a6df-7d6606a8b5ac": {"__data__": {"id_": "6e831f2d-ccd0-4d5c-a6df-7d6606a8b5ac", "embedding": null, "metadata": {"window": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right? ", "original_text": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6209543-41b5-4916-924e-4bef4e71bb49", "node_type": "1", "metadata": {"window": "And so becau se the microphones are just at slightly \ndifferent distances to the two people, and th e two people may speak in slightly different \nvolumes, each microphone will pick up an overl apping combination of these two people's \n\nvoices, so slightly different overlapping voice s. So Speaker 1's voice may be more loud \non Microphone 1, and Speaker 2's voice may be louder on Microphone 2, whatever.  \n But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay. ", "original_text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8af56677-6a79-412d-9a9c-98456dbf9933", "node_type": "1", "metadata": {"window": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? ", "original_text": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "ee326d0220abbd6886d5475e394780d138c3ac21e94f1d117a28364616e62d19", "class_name": "RelatedNodeInfo"}}, "hash": "c572cab48c5c772689d1c71866ce65252ac6cdf2ec96f8fcbd4c7c37fd6e56e4", "text": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. ", "start_char_idx": 51671, "end_char_idx": 51772, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8af56677-6a79-412d-9a9c-98456dbf9933": {"__data__": {"id_": "8af56677-6a79-412d-9a9c-98456dbf9933", "embedding": null, "metadata": {"window": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? ", "original_text": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6e831f2d-ccd0-4d5c-a6df-7d6606a8b5ac", "node_type": "1", "metadata": {"window": "But the question is, given these microphone reco rdings, can you separate out the original \nspeaker's voices?  So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right? ", "original_text": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten. "}, "hash": "c572cab48c5c772689d1c71866ce65252ac6cdf2ec96f8fcbd4c7c37fd6e56e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "057900af-1e3c-4afe-b627-4ac8660d9ddb", "node_type": "1", "metadata": {"window": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n", "original_text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "class_name": "RelatedNodeInfo"}}, "hash": "ee326d0220abbd6886d5475e394780d138c3ac21e94f1d117a28364616e62d19", "text": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "start_char_idx": 51772, "end_char_idx": 51882, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "057900af-1e3c-4afe-b627-4ac8660d9ddb": {"__data__": {"id_": "057900af-1e3c-4afe-b627-4ac8660d9ddb", "embedding": null, "metadata": {"window": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n", "original_text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8af56677-6a79-412d-9a9c-98456dbf9933", "node_type": "1", "metadata": {"window": "So I'm gonna play some audi o clips that were collected by Tai Yuan \nLee at UCSD.  I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? ", "original_text": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "ee326d0220abbd6886d5475e394780d138c3ac21e94f1d117a28364616e62d19", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ad35477-1f37-4b3b-8220-c27b99cdf6ed", "node_type": "1", "metadata": {"window": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. ", "original_text": "Instructor (Andrew Ng) : Okay. "}, "hash": "7f864011ca2abed74a63be9291179ecc648825bd5a9141b2d71a88e286a7fbeb", "class_name": "RelatedNodeInfo"}}, "hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "start_char_idx": 51590, "end_char_idx": 51671, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ad35477-1f37-4b3b-8220-c27b99cdf6ed": {"__data__": {"id_": "7ad35477-1f37-4b3b-8220-c27b99cdf6ed", "embedding": null, "metadata": {"window": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. ", "original_text": "Instructor (Andrew Ng) : Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "057900af-1e3c-4afe-b627-4ac8660d9ddb", "node_type": "1", "metadata": {"window": "I'm gonna actually play for you the original raw microphone recordings \nfrom this cocktail party.  So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n", "original_text": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "hash": "a588cddc82e645d49bc9dfac0df33e56b356a7cfbc827867d65cd621e893febf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3e7feb7b-06a7-47c9-aa1f-d8f8e62aa6b6", "node_type": "1", "metadata": {"window": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "So in supervised learning, we don't know what the \nright answer is, right? "}, "hash": "9b21a54c65a40dca2743e4efc2f6f05d4faad0cdfd77f2591a49161cf9f2c96c", "class_name": "RelatedNodeInfo"}}, "hash": "7f864011ca2abed74a63be9291179ecc648825bd5a9141b2d71a88e286a7fbeb", "text": "Instructor (Andrew Ng) : Okay. ", "start_char_idx": 51963, "end_char_idx": 51994, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3e7feb7b-06a7-47c9-aa1f-d8f8e62aa6b6": {"__data__": {"id_": "3e7feb7b-06a7-47c9-aa1f-d8f8e62aa6b6", "embedding": null, "metadata": {"window": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "So in supervised learning, we don't know what the \nright answer is, right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ad35477-1f37-4b3b-8220-c27b99cdf6ed", "node_type": "1", "metadata": {"window": "So this is the Microphone 1:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. ", "original_text": "Instructor (Andrew Ng) : Okay. "}, "hash": "7f864011ca2abed74a63be9291179ecc648825bd5a9141b2d71a88e286a7fbeb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86bc81b4-9486-4f9f-92da-607f8b0a168d", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? "}, "hash": "aa31f22de3377344bcf7684a12bf232bff241f46a665b3c36ebe9276b4cebf59", "class_name": "RelatedNodeInfo"}}, "hash": "9b21a54c65a40dca2743e4efc2f6f05d4faad0cdfd77f2591a49161cf9f2c96c", "text": "So in supervised learning, we don't know what the \nright answer is, right? ", "start_char_idx": 51994, "end_char_idx": 52069, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "86bc81b4-9486-4f9f-92da-607f8b0a168d": {"__data__": {"id_": "86bc81b4-9486-4f9f-92da-607f8b0a168d", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e7feb7b-06a7-47c9-aa1f-d8f8e62aa6b6", "node_type": "1", "metadata": {"window": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "So in supervised learning, we don't know what the \nright answer is, right? "}, "hash": "9b21a54c65a40dca2743e4efc2f6f05d4faad0cdfd77f2591a49161cf9f2c96c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "59275517-0fdc-4ef0-8bf2-22def175c743", "node_type": "1", "metadata": {"window": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. ", "original_text": "And we actually don't know what the right answer is offhand.  \n"}, "hash": "c64755992237cf053f479c9a28344970b59dcb634c004f99564860ea797f8390", "class_name": "RelatedNodeInfo"}}, "hash": "aa31f22de3377344bcf7684a12bf232bff241f46a665b3c36ebe9276b4cebf59", "text": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? ", "start_char_idx": 52069, "end_char_idx": 52334, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "59275517-0fdc-4ef0-8bf2-22def175c743": {"__data__": {"id_": "59275517-0fdc-4ef0-8bf2-22def175c743", "embedding": null, "metadata": {"window": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. ", "original_text": "And we actually don't know what the right answer is offhand.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "86bc81b4-9486-4f9f-92da-607f8b0a168d", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : So it's a fascinating cocktail party with people counting from \none to ten.  This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "original_text": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data? "}, "hash": "aa31f22de3377344bcf7684a12bf232bff241f46a665b3c36ebe9276b4cebf59", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b85a21f-58c7-4e0f-8bcd-9fc4dfcf4aed", "node_type": "1", "metadata": {"window": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example. ", "original_text": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. "}, "hash": "8547aac6d5ccba064a4fe45a620ff26737c97977ed6b332d8772c8b10b8e7279", "class_name": "RelatedNodeInfo"}}, "hash": "c64755992237cf053f479c9a28344970b59dcb634c004f99564860ea797f8390", "text": "And we actually don't know what the right answer is offhand.  \n", "start_char_idx": 52334, "end_char_idx": 52397, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b85a21f-58c7-4e0f-8bcd-9fc4dfcf4aed": {"__data__": {"id_": "8b85a21f-58c7-4e0f-8bcd-9fc4dfcf4aed", "embedding": null, "metadata": {"window": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example. ", "original_text": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "59275517-0fdc-4ef0-8bf2-22def175c743", "node_type": "1", "metadata": {"window": "This is the second microphone:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. ", "original_text": "And we actually don't know what the right answer is offhand.  \n"}, "hash": "c64755992237cf053f479c9a28344970b59dcb634c004f99564860ea797f8390", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10c1a307-f21a-40c1-a459-65f1d06d9c41", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "92737c1ad3978baf1e18470d893a7110e585475fece5a7193b786e86312082ad", "class_name": "RelatedNodeInfo"}}, "hash": "8547aac6d5ccba064a4fe45a620ff26737c97977ed6b332d8772c8b10b8e7279", "text": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. ", "start_char_idx": 52397, "end_char_idx": 52672, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10c1a307-f21a-40c1-a459-65f1d06d9c41": {"__data__": {"id_": "10c1a307-f21a-40c1-a459-65f1d06d9c41", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b85a21f-58c7-4e0f-8bcd-9fc4dfcf4aed", "node_type": "1", "metadata": {"window": "Microphone 2:  \nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example. ", "original_text": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou. "}, "hash": "8547aac6d5ccba064a4fe45a620ff26737c97977ed6b332d8772c8b10b8e7279", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2eb93384-2b05-4da1-b53b-4e73d02573d0", "node_type": "1", "metadata": {"window": "So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  ", "original_text": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "hash": "4f81e5e3e2ce89cc469a82f00c3782ed839727270b19e2d72dc599461ebf71da", "class_name": "RelatedNodeInfo"}}, "hash": "92737c1ad3978baf1e18470d893a7110e585475fece5a7193b786e86312082ad", "text": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "start_char_idx": 52672, "end_char_idx": 52788, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2eb93384-2b05-4da1-b53b-4e73d02573d0": {"__data__": {"id_": "2eb93384-2b05-4da1-b53b-4e73d02573d0", "embedding": null, "metadata": {"window": "So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  ", "original_text": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10c1a307-f21a-40c1-a459-65f1d06d9c41", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Okay.  So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "92737c1ad3978baf1e18470d893a7110e585475fece5a7193b786e86312082ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "83806ec3-73c2-4e87-aacc-517c3ab16877", "node_type": "1", "metadata": {"window": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party. ", "original_text": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. "}, "hash": "682495d85b155541a1da3d39d03dbb4cf98bb018ee385bcd6358b5a2e241c0be", "class_name": "RelatedNodeInfo"}}, "hash": "4f81e5e3e2ce89cc469a82f00c3782ed839727270b19e2d72dc599461ebf71da", "text": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n", "start_char_idx": 52788, "end_char_idx": 52931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "83806ec3-73c2-4e87-aacc-517c3ab16877": {"__data__": {"id_": "83806ec3-73c2-4e87-aacc-517c3ab16877", "embedding": null, "metadata": {"window": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party. ", "original_text": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2eb93384-2b05-4da1-b53b-4e73d02573d0", "node_type": "1", "metadata": {"window": "So in supervised learning, we don't know what the \nright answer is, right?  So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  ", "original_text": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n"}, "hash": "4f81e5e3e2ce89cc469a82f00c3782ed839727270b19e2d72dc599461ebf71da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d5008c32-f6b9-49cd-96b3-9c2d7cf4aab2", "node_type": "1", "metadata": {"window": "And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio. ", "original_text": "I'll \nshow you one more example. "}, "hash": "d9076c956840ca00c15564250e61bc2b69b45d4393e8407420d04332ceb86eb9", "class_name": "RelatedNodeInfo"}}, "hash": "682495d85b155541a1da3d39d03dbb4cf98bb018ee385bcd6358b5a2e241c0be", "text": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. ", "start_char_idx": 52931, "end_char_idx": 53101, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d5008c32-f6b9-49cd-96b3-9c2d7cf4aab2": {"__data__": {"id_": "d5008c32-f6b9-49cd-96b3-9c2d7cf4aab2", "embedding": null, "metadata": {"window": "And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio. ", "original_text": "I'll \nshow you one more example. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83806ec3-73c2-4e87-aacc-517c3ab16877", "node_type": "1", "metadata": {"window": "So what we're goi ng to do is take exactly the two microphone \nrecordings you just heard and give it to an  unsupervised learning algorithm and tell the \nalgorithm which of these discover structure in the data [inaudible] or  what structure is \nthere in this data?  And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party. ", "original_text": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are. "}, "hash": "682495d85b155541a1da3d39d03dbb4cf98bb018ee385bcd6358b5a2e241c0be", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8fbc366c-bc39-4f97-b859-33a79e7fd685", "node_type": "1", "metadata": {"window": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "81226f8affeb9de5cf0526f969138cda58ccea3a8db94fbe4def8f09714dd632", "class_name": "RelatedNodeInfo"}}, "hash": "d9076c956840ca00c15564250e61bc2b69b45d4393e8407420d04332ceb86eb9", "text": "I'll \nshow you one more example. ", "start_char_idx": 53101, "end_char_idx": 53134, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fbc366c-bc39-4f97-b859-33a79e7fd685": {"__data__": {"id_": "8fbc366c-bc39-4f97-b859-33a79e7fd685", "embedding": null, "metadata": {"window": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d5008c32-f6b9-49cd-96b3-9c2d7cf4aab2", "node_type": "1", "metadata": {"window": "And we actually don't know what the right answer is offhand.  \n So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio. ", "original_text": "I'll \nshow you one more example. "}, "hash": "d9076c956840ca00c15564250e61bc2b69b45d4393e8407420d04332ceb86eb9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a411b52b-bb58-4382-870e-217bcb5b81fa", "node_type": "1", "metadata": {"window": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n", "original_text": "Microphone 2:  \n[Music playing.]  "}, "hash": "e7482d764881734d5d751dadc6539e681ff580448d63d9b9e6fc077b636abaa8", "class_name": "RelatedNodeInfo"}}, "hash": "81226f8affeb9de5cf0526f969138cda58ccea3a8db94fbe4def8f09714dd632", "text": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "start_char_idx": 53134, "end_char_idx": 53298, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a411b52b-bb58-4382-870e-217bcb5b81fa": {"__data__": {"id_": "a411b52b-bb58-4382-870e-217bcb5b81fa", "embedding": null, "metadata": {"window": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n", "original_text": "Microphone 2:  \n[Music playing.]  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8fbc366c-bc39-4f97-b859-33a79e7fd685", "node_type": "1", "metadata": {"window": "So give this data to an unsupervised lear ning algorithm, and what the algorithm does in \nthis case, it will discover that this data can actually be explained by two independent \nspeakers speaking at the same time, and it can  further separate out the two speakers for \nyou.  So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "81226f8affeb9de5cf0526f969138cda58ccea3a8db94fbe4def8f09714dd632", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ddea6a0-05e2-4e12-afd3-85e6ce38e757", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right. ", "original_text": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party. "}, "hash": "a8e8ce4dad57f94e25bd2abab1fa3f4334d425b189565cac5a5f710e6e64d6c5", "class_name": "RelatedNodeInfo"}}, "hash": "e7482d764881734d5d751dadc6539e681ff580448d63d9b9e6fc077b636abaa8", "text": "Microphone 2:  \n[Music playing.]  ", "start_char_idx": 53298, "end_char_idx": 53332, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ddea6a0-05e2-4e12-afd3-85e6ce38e757": {"__data__": {"id_": "0ddea6a0-05e2-4e12-afd3-85e6ce38e757", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right. ", "original_text": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a411b52b-bb58-4382-870e-217bcb5b81fa", "node_type": "1", "metadata": {"window": "So here's Output 1 of the algorithm:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n", "original_text": "Microphone 2:  \n[Music playing.]  "}, "hash": "e7482d764881734d5d751dadc6539e681ff580448d63d9b9e6fc077b636abaa8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4397cb9a-e019-4716-a1d0-428e8e4e65c8", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data. ", "original_text": "He's talking to his \nradio. "}, "hash": "03dd9ad89da3909cbe8ff47d28cc4c12465518b70dd97ad99a292c19ca9cf1e4", "class_name": "RelatedNodeInfo"}}, "hash": "a8e8ce4dad57f94e25bd2abab1fa3f4334d425b189565cac5a5f710e6e64d6c5", "text": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party. ", "start_char_idx": 53332, "end_char_idx": 53400, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4397cb9a-e019-4716-a1d0-428e8e4e65c8": {"__data__": {"id_": "4397cb9a-e019-4716-a1d0-428e8e4e65c8", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data. ", "original_text": "He's talking to his \nradio. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ddea6a0-05e2-4e12-afd3-85e6ce38e757", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : And there's the second algorithm:  \nMicrophone 2:  \n\nUno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.  \n Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right. ", "original_text": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party. "}, "hash": "a8e8ce4dad57f94e25bd2abab1fa3f4334d425b189565cac5a5f710e6e64d6c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d7e4190-fbbe-49cf-b68b-0bef30ca18e6", "node_type": "1", "metadata": {"window": "I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm. ", "original_text": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "e300fc5f9ce90594e6550d6922fc4d856abfccf8f445b5b716c2556c21be1573", "class_name": "RelatedNodeInfo"}}, "hash": "03dd9ad89da3909cbe8ff47d28cc4c12465518b70dd97ad99a292c19ca9cf1e4", "text": "He's talking to his \nradio. ", "start_char_idx": 53400, "end_char_idx": 53428, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0d7e4190-fbbe-49cf-b68b-0bef30ca18e6": {"__data__": {"id_": "0d7e4190-fbbe-49cf-b68b-0bef30ca18e6", "embedding": null, "metadata": {"window": "I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm. ", "original_text": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4397cb9a-e019-4716-a1d0-428e8e4e65c8", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): And so the algorithm discovers  that, gee, the structure \nunderlying the data is really th at there are two sources of so und, and here they are.  I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data. ", "original_text": "He's talking to his \nradio. "}, "hash": "03dd9ad89da3909cbe8ff47d28cc4c12465518b70dd97ad99a292c19ca9cf1e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10e30a37-a5d2-4d63-9bed-5b23c4c2b229", "node_type": "1", "metadata": {"window": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. ", "original_text": "Microphone 2:  \n[Music playing.]  \n"}, "hash": "1ff59c6a4f3423fae6daf08f5adcd4a678a81a971d5f7ed2436a94d8fdb548cd", "class_name": "RelatedNodeInfo"}}, "hash": "e300fc5f9ce90594e6550d6922fc4d856abfccf8f445b5b716c2556c21be1573", "text": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "start_char_idx": 53428, "end_char_idx": 53537, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10e30a37-a5d2-4d63-9bed-5b23c4c2b229": {"__data__": {"id_": "10e30a37-a5d2-4d63-9bed-5b23c4c2b229", "embedding": null, "metadata": {"window": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. ", "original_text": "Microphone 2:  \n[Music playing.]  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d7e4190-fbbe-49cf-b68b-0bef30ca18e6", "node_type": "1", "metadata": {"window": "I'll \nshow you one more example.  This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm. ", "original_text": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "e300fc5f9ce90594e6550d6922fc4d856abfccf8f445b5b716c2556c21be1573", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "61d4ac09-1616-4ef6-9da4-bc667b80fc36", "node_type": "1", "metadata": {"window": "Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "Instructor (Andrew Ng) : Right. "}, "hash": "e9ecb12431527e7f50bc2370d31d88feab8a8adcfc6e79c7af5b7611b31b3a24", "class_name": "RelatedNodeInfo"}}, "hash": "1ff59c6a4f3423fae6daf08f5adcd4a678a81a971d5f7ed2436a94d8fdb548cd", "text": "Microphone 2:  \n[Music playing.]  \n", "start_char_idx": 53537, "end_char_idx": 53572, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61d4ac09-1616-4ef6-9da4-bc667b80fc36": {"__data__": {"id_": "61d4ac09-1616-4ef6-9da4-bc667b80fc36", "embedding": null, "metadata": {"window": "Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "Instructor (Andrew Ng) : Right. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10e30a37-a5d2-4d63-9bed-5b23c4c2b229", "node_type": "1", "metadata": {"window": "This is a, well, th is is a second sort of different pair of \nmicrophone recordings:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. ", "original_text": "Microphone 2:  \n[Music playing.]  \n"}, "hash": "1ff59c6a4f3423fae6daf08f5adcd4a678a81a971d5f7ed2436a94d8fdb548cd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6dcb669-6062-4697-b33c-a6dc178c6209", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n", "original_text": "And we get this data. "}, "hash": "4a148e137b6e61602e4114cf17cad834c02eaf2e94f83912caf69bdafdc34e8e", "class_name": "RelatedNodeInfo"}}, "hash": "e9ecb12431527e7f50bc2370d31d88feab8a8adcfc6e79c7af5b7611b31b3a24", "text": "Instructor (Andrew Ng) : Right. ", "start_char_idx": 53572, "end_char_idx": 53604, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c6dcb669-6062-4697-b33c-a6dc178c6209": {"__data__": {"id_": "c6dcb669-6062-4697-b33c-a6dc178c6209", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n", "original_text": "And we get this data. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61d4ac09-1616-4ef6-9da4-bc667b80fc36", "node_type": "1", "metadata": {"window": "Microphone 2:  \n[Music playing.]   Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "original_text": "Instructor (Andrew Ng) : Right. "}, "hash": "e9ecb12431527e7f50bc2370d31d88feab8a8adcfc6e79c7af5b7611b31b3a24", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b90fe03-22d6-4391-abba-e5b2ba3160c2", "node_type": "1", "metadata": {"window": "He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay. ", "original_text": "It's the same unsupervised \nlearning algorithm. "}, "hash": "9377239efe936d1e99f0580cfbebb693d7147130c5e446c49ee30d484700883f", "class_name": "RelatedNodeInfo"}}, "hash": "4a148e137b6e61602e4114cf17cad834c02eaf2e94f83912caf69bdafdc34e8e", "text": "And we get this data. ", "start_char_idx": 53604, "end_char_idx": 53626, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b90fe03-22d6-4391-abba-e5b2ba3160c2": {"__data__": {"id_": "5b90fe03-22d6-4391-abba-e5b2ba3160c2", "embedding": null, "metadata": {"window": "He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay. ", "original_text": "It's the same unsupervised \nlearning algorithm. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6dcb669-6062-4697-b33c-a6dc178c6209", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): So the poor guy is not at a cocktail party.  He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n", "original_text": "And we get this data. "}, "hash": "4a148e137b6e61602e4114cf17cad834c02eaf2e94f83912caf69bdafdc34e8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ee1a5e4-982a-4375-a2cf-a37e7f76522a", "node_type": "1", "metadata": {"window": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. ", "original_text": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. "}, "hash": "b3117893aa8f8ad37d80331614e1f52c4334e4001de79ec17426767fd6d68f97", "class_name": "RelatedNodeInfo"}}, "hash": "9377239efe936d1e99f0580cfbebb693d7147130c5e446c49ee30d484700883f", "text": "It's the same unsupervised \nlearning algorithm. ", "start_char_idx": 53626, "end_char_idx": 53674, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ee1a5e4-982a-4375-a2cf-a37e7f76522a": {"__data__": {"id_": "0ee1a5e4-982a-4375-a2cf-a37e7f76522a", "embedding": null, "metadata": {"window": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. ", "original_text": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b90fe03-22d6-4391-abba-e5b2ba3160c2", "node_type": "1", "metadata": {"window": "He's talking to his \nradio.  There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay. ", "original_text": "It's the same unsupervised \nlearning algorithm. "}, "hash": "9377239efe936d1e99f0580cfbebb693d7147130c5e446c49ee30d484700883f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77c0091a-2c76-41f0-86f9-52936a868e64", "node_type": "1", "metadata": {"window": "Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n", "original_text": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "2e1aa23100fa28ed191e06f85a3c963ce5512858b773b039c09788b5e55fe000", "class_name": "RelatedNodeInfo"}}, "hash": "b3117893aa8f8ad37d80331614e1f52c4334e4001de79ec17426767fd6d68f97", "text": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. ", "start_char_idx": 53674, "end_char_idx": 53783, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77c0091a-2c76-41f0-86f9-52936a868e64": {"__data__": {"id_": "77c0091a-2c76-41f0-86f9-52936a868e64", "embedding": null, "metadata": {"window": "Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n", "original_text": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ee1a5e4-982a-4375-a2cf-a37e7f76522a", "node_type": "1", "metadata": {"window": "There's the second recording:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. ", "original_text": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why. "}, "hash": "b3117893aa8f8ad37d80331614e1f52c4334e4001de79ec17426767fd6d68f97", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "205c0f5c-4b3c-4c07-87bb-67b32a5395f4", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. ", "original_text": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n"}, "hash": "e3f826d1bc3f97276f8b6c466b4ece6ce4e8513f88df33d8f24d174df2b8bd93", "class_name": "RelatedNodeInfo"}}, "hash": "2e1aa23100fa28ed191e06f85a3c963ce5512858b773b039c09788b5e55fe000", "text": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n", "start_char_idx": 53783, "end_char_idx": 53895, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "205c0f5c-4b3c-4c07-87bb-67b32a5395f4": {"__data__": {"id_": "205c0f5c-4b3c-4c07-87bb-67b32a5395f4", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. ", "original_text": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77c0091a-2c76-41f0-86f9-52936a868e64", "node_type": "1", "metadata": {"window": "Microphone 2:  \n[Music playing.]  \n Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n", "original_text": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n"}, "hash": "2e1aa23100fa28ed191e06f85a3c963ce5512858b773b039c09788b5e55fe000", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "74e8ad44-9342-4678-bc38-f414260e273f", "node_type": "1", "metadata": {"window": "And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do. ", "original_text": "Instructor (Andrew Ng): Okay. "}, "hash": "ba11988e06a314516dc62c3225b2cd74676cd9eb55657f3194475abf2f499d22", "class_name": "RelatedNodeInfo"}}, "hash": "e3f826d1bc3f97276f8b6c466b4ece6ce4e8513f88df33d8f24d174df2b8bd93", "text": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n", "start_char_idx": 53895, "end_char_idx": 53983, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "74e8ad44-9342-4678-bc38-f414260e273f": {"__data__": {"id_": "74e8ad44-9342-4678-bc38-f414260e273f", "embedding": null, "metadata": {"window": "And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do. ", "original_text": "Instructor (Andrew Ng): Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "205c0f5c-4b3c-4c07-87bb-67b32a5395f4", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng) : Right.  And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. ", "original_text": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n"}, "hash": "e3f826d1bc3f97276f8b6c466b4ece6ce4e8513f88df33d8f24d174df2b8bd93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1b7f387-444d-4da5-bf75-b81db50a6899", "node_type": "1", "metadata": {"window": "It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this? ", "original_text": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. "}, "hash": "ce9046d01c231123e244039d8058a6cf37f23943fe29d8f8947dfbc42154b81c", "class_name": "RelatedNodeInfo"}}, "hash": "ba11988e06a314516dc62c3225b2cd74676cd9eb55657f3194475abf2f499d22", "text": "Instructor (Andrew Ng): Okay. ", "start_char_idx": 53983, "end_char_idx": 54013, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b1b7f387-444d-4da5-bf75-b81db50a6899": {"__data__": {"id_": "b1b7f387-444d-4da5-bf75-b81db50a6899", "embedding": null, "metadata": {"window": "It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this? ", "original_text": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "74e8ad44-9342-4678-bc38-f414260e273f", "node_type": "1", "metadata": {"window": "And we get this data.  It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do. ", "original_text": "Instructor (Andrew Ng): Okay. "}, "hash": "ba11988e06a314516dc62c3225b2cd74676cd9eb55657f3194475abf2f499d22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d207d505-8b33-4e1a-a4c8-e5eff83267a3", "node_type": "1", "metadata": {"window": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n", "original_text": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n"}, "hash": "f1267097af7f6c5f9a83417084c1b7e518afa9f8a47e01b323da91b55c9bff64", "class_name": "RelatedNodeInfo"}}, "hash": "ce9046d01c231123e244039d8058a6cf37f23943fe29d8f8947dfbc42154b81c", "text": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. ", "start_char_idx": 54013, "end_char_idx": 54321, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d207d505-8b33-4e1a-a4c8-e5eff83267a3": {"__data__": {"id_": "d207d505-8b33-4e1a-a4c8-e5eff83267a3", "embedding": null, "metadata": {"window": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n", "original_text": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1b7f387-444d-4da5-bf75-b81db50a6899", "node_type": "1", "metadata": {"window": "It's the same unsupervised \nlearning algorithm.  The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this? ", "original_text": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data. "}, "hash": "ce9046d01c231123e244039d8058a6cf37f23943fe29d8f8947dfbc42154b81c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7d60c778-b27b-48f5-aa33-542d52f91a53", "node_type": "1", "metadata": {"window": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. ", "original_text": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. "}, "hash": "c727d2cd285c0abdbe220dfa7ba6f70f652592f16328050a16c7a8ffae969c9c", "class_name": "RelatedNodeInfo"}}, "hash": "f1267097af7f6c5f9a83417084c1b7e518afa9f8a47e01b323da91b55c9bff64", "text": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n", "start_char_idx": 54321, "end_char_idx": 54455, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d60c778-b27b-48f5-aa33-542d52f91a53": {"__data__": {"id_": "7d60c778-b27b-48f5-aa33-542d52f91a53", "embedding": null, "metadata": {"window": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. ", "original_text": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d207d505-8b33-4e1a-a4c8-e5eff83267a3", "node_type": "1", "metadata": {"window": "The algorithm is actually called independent component analysis, and \nlater in this quarter, you'll see why.  And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n", "original_text": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n"}, "hash": "f1267097af7f6c5f9a83417084c1b7e518afa9f8a47e01b323da91b55c9bff64", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ada38f8e-2e9a-472a-ba94-d5ed986e9a91", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. ", "original_text": "It sounds like a pretty complicated thi ng to do. "}, "hash": "f33bddc19ec892452fe6e36e56e37812412a10e76a4475879a25f16ec7d05d72", "class_name": "RelatedNodeInfo"}}, "hash": "c727d2cd285c0abdbe220dfa7ba6f70f652592f16328050a16c7a8ffae969c9c", "text": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. ", "start_char_idx": 54455, "end_char_idx": 54634, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ada38f8e-2e9a-472a-ba94-d5ed986e9a91": {"__data__": {"id_": "ada38f8e-2e9a-472a-ba94-d5ed986e9a91", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. ", "original_text": "It sounds like a pretty complicated thi ng to do. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d60c778-b27b-48f5-aa33-542d52f91a53", "node_type": "1", "metadata": {"window": "And then output's the following:  \nMicrophone 1:  \nOne, two, three, four, five, six, seven, eight, nine, ten.  \n Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. ", "original_text": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout. "}, "hash": "c727d2cd285c0abdbe220dfa7ba6f70f652592f16328050a16c7a8ffae969c9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46428e41-91c4-4931-bd20-898cf1a558bf", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n", "original_text": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this? "}, "hash": "90ab486e095f1953bf73c17886286bcc92f778713420b9ebb7923f062958e2d1", "class_name": "RelatedNodeInfo"}}, "hash": "f33bddc19ec892452fe6e36e56e37812412a10e76a4475879a25f16ec7d05d72", "text": "It sounds like a pretty complicated thi ng to do. ", "start_char_idx": 54634, "end_char_idx": 54684, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "46428e41-91c4-4931-bd20-898cf1a558bf": {"__data__": {"id_": "46428e41-91c4-4931-bd20-898cf1a558bf", "embedding": null, "metadata": {"window": "Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n", "original_text": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ada38f8e-2e9a-472a-ba94-d5ed986e9a91", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): And that's the second one:  \nMicrophone 2:  \n[Music playing.]  \n Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. ", "original_text": "It sounds like a pretty complicated thi ng to do. "}, "hash": "f33bddc19ec892452fe6e36e56e37812412a10e76a4475879a25f16ec7d05d72", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d99e1ddb-7207-4abe-b602-8915661659c4", "node_type": "1", "metadata": {"window": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. ", "original_text": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n"}, "hash": "9fd81b1439174a6bc90081d52d9066e40f11e3acf861997a0a918ef9b813cdba", "class_name": "RelatedNodeInfo"}}, "hash": "90ab486e095f1953bf73c17886286bcc92f778713420b9ebb7923f062958e2d1", "text": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this? ", "start_char_idx": 54684, "end_char_idx": 54772, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d99e1ddb-7207-4abe-b602-8915661659c4": {"__data__": {"id_": "d99e1ddb-7207-4abe-b602-8915661659c4", "embedding": null, "metadata": {"window": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. ", "original_text": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46428e41-91c4-4931-bd20-898cf1a558bf", "node_type": "1", "metadata": {"window": "Instructor (Andrew Ng): Okay.  So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n", "original_text": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this? "}, "hash": "90ab486e095f1953bf73c17886286bcc92f778713420b9ebb7923f062958e2d1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e3a7263-28f4-4c21-9c51-651f8232d09b", "node_type": "1", "metadata": {"window": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making. ", "original_text": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. "}, "hash": "f979b15ce6e9bdb17629bc287609ef6cc222dcc24976e3dbc1a09113aac91dfe", "class_name": "RelatedNodeInfo"}}, "hash": "9fd81b1439174a6bc90081d52d9066e40f11e3acf861997a0a918ef9b813cdba", "text": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n", "start_char_idx": 54772, "end_char_idx": 54847, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7e3a7263-28f4-4c21-9c51-651f8232d09b": {"__data__": {"id_": "7e3a7263-28f4-4c21-9c51-651f8232d09b", "embedding": null, "metadata": {"window": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making. ", "original_text": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d99e1ddb-7207-4abe-b602-8915661659c4", "node_type": "1", "metadata": {"window": "So it turns out that be yond solving the cocktail party \nalgorithm, this specific cla ss of unsupervised learning algor ithms are also applied to a \nbunch of other problems, like in text proces sing or understanding f unctional grading and \nmachine data, like the magneto-encephalogram would be an EEG data.  We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. ", "original_text": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n"}, "hash": "9fd81b1439174a6bc90081d52d9066e40f11e3acf861997a0a918ef9b813cdba", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fca0d17e-7caf-4884-ac2f-26f79e5968f1", "node_type": "1", "metadata": {"window": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n", "original_text": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. "}, "hash": "14000368f0b85340560af0d71d1d572b8d4df429b80553bd36479bd97e33ac25", "class_name": "RelatedNodeInfo"}}, "hash": "f979b15ce6e9bdb17629bc287609ef6cc222dcc24976e3dbc1a09113aac91dfe", "text": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. ", "start_char_idx": 54847, "end_char_idx": 54993, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fca0d17e-7caf-4884-ac2f-26f79e5968f1": {"__data__": {"id_": "fca0d17e-7caf-4884-ac2f-26f79e5968f1", "embedding": null, "metadata": {"window": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n", "original_text": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e3a7263-28f4-4c21-9c51-651f8232d09b", "node_type": "1", "metadata": {"window": "We'll talk about \nthat more when we go and describe ICA or independent component analysis algorithms, \nwhich is what you just saw.  \n\n And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making. ", "original_text": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this. "}, "hash": "f979b15ce6e9bdb17629bc287609ef6cc222dcc24976e3dbc1a09113aac91dfe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c3ed4ce-6902-4813-bc31-154fedb8b376", "node_type": "1", "metadata": {"window": "It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? ", "original_text": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n"}, "hash": "79fed37ca5b3e7d7684d4f1f1c91e4d1d67af586721b7c8874d411afdf53ee01", "class_name": "RelatedNodeInfo"}}, "hash": "14000368f0b85340560af0d71d1d572b8d4df429b80553bd36479bd97e33ac25", "text": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. ", "start_char_idx": 54993, "end_char_idx": 55338, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7c3ed4ce-6902-4813-bc31-154fedb8b376": {"__data__": {"id_": "7c3ed4ce-6902-4813-bc31-154fedb8b376", "embedding": null, "metadata": {"window": "It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? ", "original_text": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fca0d17e-7caf-4884-ac2f-26f79e5968f1", "node_type": "1", "metadata": {"window": "And as an aside, this algorithm I just showed you, it seems like it must be a pretty \ncomplicated algorithm, right, to take this overlapping audio streams and separate them \nout.  It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n", "original_text": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code. "}, "hash": "14000368f0b85340560af0d71d1d572b8d4df429b80553bd36479bd97e33ac25", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "378fdc45-0a08-4097-b1a4-4fd1e6fab40a", "node_type": "1", "metadata": {"window": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence. ", "original_text": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. "}, "hash": "9d42084c2234bf1ad49fcaefe26817788a7045fc6bd99daece83c09d6b22f9c9", "class_name": "RelatedNodeInfo"}}, "hash": "79fed37ca5b3e7d7684d4f1f1c91e4d1d67af586721b7c8874d411afdf53ee01", "text": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n", "start_char_idx": 55338, "end_char_idx": 55465, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "378fdc45-0a08-4097-b1a4-4fd1e6fab40a": {"__data__": {"id_": "378fdc45-0a08-4097-b1a4-4fd1e6fab40a", "embedding": null, "metadata": {"window": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence. ", "original_text": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c3ed4ce-6902-4813-bc31-154fedb8b376", "node_type": "1", "metadata": {"window": "It sounds like a pretty complicated thi ng to do.  So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? ", "original_text": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n"}, "hash": "79fed37ca5b3e7d7684d4f1f1c91e4d1d67af586721b7c8874d411afdf53ee01", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a7385932-f9f8-4246-ad2e-00e0d61daa3d", "node_type": "1", "metadata": {"window": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong. ", "original_text": "And this  refers to problems where you don't do one-\nshot decision-making. "}, "hash": "4e16fb5ce729aeaf3625b216ebb89a4445121e72f05e2e274502a066ea91f4d5", "class_name": "RelatedNodeInfo"}}, "hash": "9d42084c2234bf1ad49fcaefe26817788a7045fc6bd99daece83c09d6b22f9c9", "text": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. ", "start_char_idx": 55465, "end_char_idx": 55594, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a7385932-f9f8-4246-ad2e-00e0d61daa3d": {"__data__": {"id_": "a7385932-f9f8-4246-ad2e-00e0d61daa3d", "embedding": null, "metadata": {"window": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong. ", "original_text": "And this  refers to problems where you don't do one-\nshot decision-making. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "378fdc45-0a08-4097-b1a4-4fd1e6fab40a", "node_type": "1", "metadata": {"window": "So you're gonna ask how complicated \nis it really to implement an  algorithm like this?  It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence. ", "original_text": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning. "}, "hash": "9d42084c2234bf1ad49fcaefe26817788a7045fc6bd99daece83c09d6b22f9c9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "37c6f2cb-2d49-42fa-b405-f66a5eb41b4c", "node_type": "1", "metadata": {"window": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n", "original_text": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n"}, "hash": "4ce786ec31347ff454348b07a1a9be523fbd91e558d5043bf2daffc839cfc08e", "class_name": "RelatedNodeInfo"}}, "hash": "4e16fb5ce729aeaf3625b216ebb89a4445121e72f05e2e274502a066ea91f4d5", "text": "And this  refers to problems where you don't do one-\nshot decision-making. ", "start_char_idx": 55594, "end_char_idx": 55669, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "37c6f2cb-2d49-42fa-b405-f66a5eb41b4c": {"__data__": {"id_": "37c6f2cb-2d49-42fa-b405-f66a5eb41b4c", "embedding": null, "metadata": {"window": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n", "original_text": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a7385932-f9f8-4246-ad2e-00e0d61daa3d", "node_type": "1", "metadata": {"window": "It turns out if you do it in MATLAB, you \ncan do it in one line of code.  \n So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong. ", "original_text": "And this  refers to problems where you don't do one-\nshot decision-making. "}, "hash": "4e16fb5ce729aeaf3625b216ebb89a4445121e72f05e2e274502a066ea91f4d5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d4c75c62-5f3a-487b-a71a-b750c850a13c", "node_type": "1", "metadata": {"window": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on. ", "original_text": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? "}, "hash": "adaa13d8f265638c8a3cc48e29f7c46372c83274ec5ef4b78eee3dfd7e88a1f8", "class_name": "RelatedNodeInfo"}}, "hash": "4ce786ec31347ff454348b07a1a9be523fbd91e558d5043bf2daffc839cfc08e", "text": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n", "start_char_idx": 55669, "end_char_idx": 55823, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d4c75c62-5f3a-487b-a71a-b750c850a13c": {"__data__": {"id_": "d4c75c62-5f3a-487b-a71a-b750c850a13c", "embedding": null, "metadata": {"window": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on. ", "original_text": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37c6f2cb-2d49-42fa-b405-f66a5eb41b4c", "node_type": "1", "metadata": {"window": "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \nactually used a more complicated ICA algorithm than this.  But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n", "original_text": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n"}, "hash": "4ce786ec31347ff454348b07a1a9be523fbd91e558d5043bf2daffc839cfc08e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "abfc6c53-f39f-4fdb-97cf-9b3f9b04e4d6", "node_type": "1", "metadata": {"window": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? ", "original_text": "So you make a decision and then there's a consequence. "}, "hash": "752aa588f163754efeb665347bb069b0808b11e4ea485dae1b5298b8d3be37c1", "class_name": "RelatedNodeInfo"}}, "hash": "adaa13d8f265638c8a3cc48e29f7c46372c83274ec5ef4b78eee3dfd7e88a1f8", "text": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? ", "start_char_idx": 55823, "end_char_idx": 55920, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "abfc6c53-f39f-4fdb-97cf-9b3f9b04e4d6": {"__data__": {"id_": "abfc6c53-f39f-4fdb-97cf-9b3f9b04e4d6", "embedding": null, "metadata": {"window": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? ", "original_text": "So you make a decision and then there's a consequence. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d4c75c62-5f3a-487b-a71a-b750c850a13c", "node_type": "1", "metadata": {"window": "But nonetheless, I guess this is \nwhy for this class I'm going to ask you to  do most of your programming in MATLAB and \nOctave because if you try to implement the sa me algorithm in C or Java or something, I \ncan tell you from personal, painful experien ce, you end up writing pages and pages of \ncode rather than relatively few lines of code.  I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on. ", "original_text": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright? "}, "hash": "adaa13d8f265638c8a3cc48e29f7c46372c83274ec5ef4b78eee3dfd7e88a1f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8fe18b2f-456f-4631-aa68-2f1e23205720", "node_type": "1", "metadata": {"window": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. ", "original_text": "You either got it right or \nwrong. "}, "hash": "1b3b9be60ef4612610424ae4c326b5b379f6f2dd3888d4c1b59c55f1da7739f9", "class_name": "RelatedNodeInfo"}}, "hash": "752aa588f163754efeb665347bb069b0808b11e4ea485dae1b5298b8d3be37c1", "text": "So you make a decision and then there's a consequence. ", "start_char_idx": 55920, "end_char_idx": 55975, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fe18b2f-456f-4631-aa68-2f1e23205720": {"__data__": {"id_": "8fe18b2f-456f-4631-aa68-2f1e23205720", "embedding": null, "metadata": {"window": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. ", "original_text": "You either got it right or \nwrong. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "abfc6c53-f39f-4fdb-97cf-9b3f9b04e4d6", "node_type": "1", "metadata": {"window": "I'll also mention that it did take researchers \nmany, many years to come up with that one line of code, so this is not easy.  \n So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? ", "original_text": "So you make a decision and then there's a consequence. "}, "hash": "752aa588f163754efeb665347bb069b0808b11e4ea485dae1b5298b8d3be37c1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d1ebddad-ddda-4fc3-8cc0-11b8e67229c1", "node_type": "1", "metadata": {"window": "And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. ", "original_text": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n"}, "hash": "001360b22d8e3c03e22f8fd7d326fd6744880726cb5290a64ace3455d909c368", "class_name": "RelatedNodeInfo"}}, "hash": "1b3b9be60ef4612610424ae4c326b5b379f6f2dd3888d4c1b59c55f1da7739f9", "text": "You either got it right or \nwrong. ", "start_char_idx": 55975, "end_char_idx": 56010, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1ebddad-ddda-4fc3-8cc0-11b8e67229c1": {"__data__": {"id_": "d1ebddad-ddda-4fc3-8cc0-11b8e67229c1", "embedding": null, "metadata": {"window": "And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. ", "original_text": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8fe18b2f-456f-4631-aa68-2f1e23205720", "node_type": "1", "metadata": {"window": "So that was unsupervised learning, and then the last of the four major topics I wanna tell \nyou about is reinforcement learning.  And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. ", "original_text": "You either got it right or \nwrong. "}, "hash": "1b3b9be60ef4612610424ae4c326b5b379f6f2dd3888d4c1b59c55f1da7739f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "868fe20c-5c21-4961-940a-94d6a66684ad", "node_type": "1", "metadata": {"window": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n", "original_text": "So, for example, this is something that my students and I work on. "}, "hash": "f13ae490fec51da5c3544f912fed786bd5a66c58cd9aceecc727a8802f0fee8e", "class_name": "RelatedNodeInfo"}}, "hash": "001360b22d8e3c03e22f8fd7d326fd6744880726cb5290a64ace3455d909c368", "text": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n", "start_char_idx": 56010, "end_char_idx": 56114, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "868fe20c-5c21-4961-940a-94d6a66684ad": {"__data__": {"id_": "868fe20c-5c21-4961-940a-94d6a66684ad", "embedding": null, "metadata": {"window": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n", "original_text": "So, for example, this is something that my students and I work on. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1ebddad-ddda-4fc3-8cc0-11b8e67229c1", "node_type": "1", "metadata": {"window": "And this  refers to problems where you don't do one-\nshot decision-making.  So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. ", "original_text": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n"}, "hash": "001360b22d8e3c03e22f8fd7d326fd6744880726cb5290a64ace3455d909c368", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1f63d707-276c-4af6-a184-21f04b083759", "node_type": "1", "metadata": {"window": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. ", "original_text": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? "}, "hash": "6a37fb29b741c92fe9de591de5cafd7373eb0f04dddd3cb30cdd6e4c1abc760d", "class_name": "RelatedNodeInfo"}}, "hash": "f13ae490fec51da5c3544f912fed786bd5a66c58cd9aceecc727a8802f0fee8e", "text": "So, for example, this is something that my students and I work on. ", "start_char_idx": 56114, "end_char_idx": 56181, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1f63d707-276c-4af6-a184-21f04b083759": {"__data__": {"id_": "1f63d707-276c-4af6-a184-21f04b083759", "embedding": null, "metadata": {"window": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. ", "original_text": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "868fe20c-5c21-4961-940a-94d6a66684ad", "node_type": "1", "metadata": {"window": "So, for example, in  the supervised learning cancer prediction \nproblem, you have a patient come in, you predict that the cancer is malignant or benign. \n And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n", "original_text": "So, for example, this is something that my students and I work on. "}, "hash": "f13ae490fec51da5c3544f912fed786bd5a66c58cd9aceecc727a8802f0fee8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7a06f9e-19e5-486a-b8cc-d20ffc6c7fab", "node_type": "1", "metadata": {"window": "So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. ", "original_text": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. "}, "hash": "5ce2db8d5024add74b12fd56481f60f1726ef152a0740b2640f92c8d06f79093", "class_name": "RelatedNodeInfo"}}, "hash": "6a37fb29b741c92fe9de591de5cafd7373eb0f04dddd3cb30cdd6e4c1abc760d", "text": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? ", "start_char_idx": 56181, "end_char_idx": 56341, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7a06f9e-19e5-486a-b8cc-d20ffc6c7fab": {"__data__": {"id_": "b7a06f9e-19e5-486a-b8cc-d20ffc6c7fab", "embedding": null, "metadata": {"window": "So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. ", "original_text": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f63d707-276c-4af6-a184-21f04b083759", "node_type": "1", "metadata": {"window": "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \nright?  So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. ", "original_text": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght? "}, "hash": "6a37fb29b741c92fe9de591de5cafd7373eb0f04dddd3cb30cdd6e4c1abc760d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a1b7b22-b773-4b0d-9077-9a09c567e1f1", "node_type": "1", "metadata": {"window": "You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. ", "original_text": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. "}, "hash": "bcd948f7aef699d0af2fc601e2bd8cc66b0ce0238e8e1b53fff9c3d36324f9f4", "class_name": "RelatedNodeInfo"}}, "hash": "5ce2db8d5024add74b12fd56481f60f1726ef152a0740b2640f92c8d06f79093", "text": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. ", "start_char_idx": 56341, "end_char_idx": 56468, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a1b7b22-b773-4b0d-9077-9a09c567e1f1": {"__data__": {"id_": "5a1b7b22-b773-4b0d-9077-9a09c567e1f1", "embedding": null, "metadata": {"window": "You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. ", "original_text": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7a06f9e-19e5-486a-b8cc-d20ffc6c7fab", "node_type": "1", "metadata": {"window": "So you make a decision and then there's a consequence.  You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. ", "original_text": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later. "}, "hash": "5ce2db8d5024add74b12fd56481f60f1726ef152a0740b2640f92c8d06f79093", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "94088853-bfbe-4607-942e-bf3e30f4a65a", "node_type": "1", "metadata": {"window": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky. ", "original_text": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n"}, "hash": "5d5b1658e95b6d8c02464576788051dc2680583045540ceb8ad0839f36f91369", "class_name": "RelatedNodeInfo"}}, "hash": "bcd948f7aef699d0af2fc601e2bd8cc66b0ce0238e8e1b53fff9c3d36324f9f4", "text": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. ", "start_char_idx": 56468, "end_char_idx": 56565, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "94088853-bfbe-4607-942e-bf3e30f4a65a": {"__data__": {"id_": "94088853-bfbe-4607-942e-bf3e30f4a65a", "embedding": null, "metadata": {"window": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky. ", "original_text": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5a1b7b22-b773-4b0d-9077-9a09c567e1f1", "node_type": "1", "metadata": {"window": "You either got it right or \nwrong.  In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. ", "original_text": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter. "}, "hash": "bcd948f7aef699d0af2fc601e2bd8cc66b0ce0238e8e1b53fff9c3d36324f9f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f42971d-cb97-4a6b-a41a-dedff4405a2c", "node_type": "1", "metadata": {"window": "So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. ", "original_text": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. "}, "hash": "5f27c8d95b0e6b772043750344549b81e5a1094880e818a6fde0ad5c68dbcfe2", "class_name": "RelatedNodeInfo"}}, "hash": "5d5b1658e95b6d8c02464576788051dc2680583045540ceb8ad0839f36f91369", "text": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n", "start_char_idx": 56565, "end_char_idx": 56685, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0f42971d-cb97-4a6b-a41a-dedff4405a2c": {"__data__": {"id_": "0f42971d-cb97-4a6b-a41a-dedff4405a2c", "embedding": null, "metadata": {"window": "So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. ", "original_text": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "94088853-bfbe-4607-942e-bf3e30f4a65a", "node_type": "1", "metadata": {"window": "In reinforcement learning problems, you are usually asked to make a sequence of \ndecisions over time.  \n So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky. ", "original_text": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n"}, "hash": "5d5b1658e95b6d8c02464576788051dc2680583045540ceb8ad0839f36f91369", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0ac6a687-10e9-424b-bbc8-320416230ee0", "node_type": "1", "metadata": {"window": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n", "original_text": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. "}, "hash": "c8f28045512fa038b542f778bdef718d51347be89ad1bbfedbc8482e38d2f696", "class_name": "RelatedNodeInfo"}}, "hash": "5f27c8d95b0e6b772043750344549b81e5a1094880e818a6fde0ad5c68dbcfe2", "text": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. ", "start_char_idx": 56685, "end_char_idx": 56767, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ac6a687-10e9-424b-bbc8-320416230ee0": {"__data__": {"id_": "0ac6a687-10e9-424b-bbc8-320416230ee0", "embedding": null, "metadata": {"window": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n", "original_text": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f42971d-cb97-4a6b-a41a-dedff4405a2c", "node_type": "1", "metadata": {"window": "So, for example, this is something that my students and I work on.  If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. ", "original_text": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters. "}, "hash": "5f27c8d95b0e6b772043750344549b81e5a1094880e818a6fde0ad5c68dbcfe2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86527023-a577-4b37-857b-2b01c4341e91", "node_type": "1", "metadata": {"window": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. ", "original_text": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. "}, "hash": "dc19b11e1b20db06c45418426c00b5552e04b7599bc691c872b449db0b2215b9", "class_name": "RelatedNodeInfo"}}, "hash": "c8f28045512fa038b542f778bdef718d51347be89ad1bbfedbc8482e38d2f696", "text": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. ", "start_char_idx": 56767, "end_char_idx": 56901, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "86527023-a577-4b37-857b-2b01c4341e91": {"__data__": {"id_": "86527023-a577-4b37-857b-2b01c4341e91", "embedding": null, "metadata": {"window": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. ", "original_text": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ac6a687-10e9-424b-bbc8-320416230ee0", "node_type": "1", "metadata": {"window": "If I give you the keys \nto an autonomous helicopter \u2014 we actually ha ve this helicopter here at Stanford, \u2014 how \ndo you write a program to make it fly, ri ght?  You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n", "original_text": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm. "}, "hash": "c8f28045512fa038b542f778bdef718d51347be89ad1bbfedbc8482e38d2f696", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54312aa7-044a-45c9-9bef-7f9448d4c8f8", "node_type": "1", "metadata": {"window": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog. ", "original_text": "You'll sort of see th e trees planted in the sky. "}, "hash": "76605558a9deedce0259f2417afe968c811254cb41458d346e57aa35a00e4519", "class_name": "RelatedNodeInfo"}}, "hash": "dc19b11e1b20db06c45418426c00b5552e04b7599bc691c872b449db0b2215b9", "text": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. ", "start_char_idx": 56901, "end_char_idx": 56995, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54312aa7-044a-45c9-9bef-7f9448d4c8f8": {"__data__": {"id_": "54312aa7-044a-45c9-9bef-7f9448d4c8f8", "embedding": null, "metadata": {"window": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog. ", "original_text": "You'll sort of see th e trees planted in the sky. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "86527023-a577-4b37-857b-2b01c4341e91", "node_type": "1", "metadata": {"window": "You notice that if you make a wrong \ndecision on a helicopter, the consequence of crashing it may not happen until much later.  And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. ", "original_text": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second. "}, "hash": "dc19b11e1b20db06c45418426c00b5552e04b7599bc691c872b449db0b2215b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f0686fe-7120-4088-9600-1b848170ced6", "node_type": "1", "metadata": {"window": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. ", "original_text": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. "}, "hash": "9b43f56a8849dde80fc18d8845a062c2e419ef33af77d99fbfc6fcdd183a64d7", "class_name": "RelatedNodeInfo"}}, "hash": "76605558a9deedce0259f2417afe968c811254cb41458d346e57aa35a00e4519", "text": "You'll sort of see th e trees planted in the sky. ", "start_char_idx": 56995, "end_char_idx": 57045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f0686fe-7120-4088-9600-1b848170ced6": {"__data__": {"id_": "5f0686fe-7120-4088-9600-1b848170ced6", "embedding": null, "metadata": {"window": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. ", "original_text": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54312aa7-044a-45c9-9bef-7f9448d4c8f8", "node_type": "1", "metadata": {"window": "And in fact, usually you need to make a w hole sequence of bad decisions to crash a \nhelicopter.  But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog. ", "original_text": "You'll sort of see th e trees planted in the sky. "}, "hash": "76605558a9deedce0259f2417afe968c811254cb41458d346e57aa35a00e4519", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "41a84c3c-194e-4521-8cc3-4dff3a796248", "node_type": "1", "metadata": {"window": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right? ", "original_text": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n"}, "hash": "c6f010cf3195243f9ed45992ca5ce07e52c17d5995fd8cd7cbb527fdb646770a", "class_name": "RelatedNodeInfo"}}, "hash": "9b43f56a8849dde80fc18d8845a062c2e419ef33af77d99fbfc6fcdd183a64d7", "text": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. ", "start_char_idx": 57045, "end_char_idx": 57159, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "41a84c3c-194e-4521-8cc3-4dff3a796248": {"__data__": {"id_": "41a84c3c-194e-4521-8cc3-4dff3a796248", "embedding": null, "metadata": {"window": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right? ", "original_text": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f0686fe-7120-4088-9600-1b848170ced6", "node_type": "1", "metadata": {"window": "But conversely, you al so need to make a whole sequence of good decisions in \norder to fly a helic opter really well.  \n So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. ", "original_text": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control. "}, "hash": "9b43f56a8849dde80fc18d8845a062c2e419ef33af77d99fbfc6fcdd183a64d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20df0bce-3140-4cd5-9034-e5782dc668e5", "node_type": "1", "metadata": {"window": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n", "original_text": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. "}, "hash": "005ceeebc64939ade63c127b182aaeb6566cf38b2dd67d1e5963687ea4377829", "class_name": "RelatedNodeInfo"}}, "hash": "c6f010cf3195243f9ed45992ca5ce07e52c17d5995fd8cd7cbb527fdb646770a", "text": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n", "start_char_idx": 57159, "end_char_idx": 57313, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20df0bce-3140-4cd5-9034-e5782dc668e5": {"__data__": {"id_": "20df0bce-3140-4cd5-9034-e5782dc668e5", "embedding": null, "metadata": {"window": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n", "original_text": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "41a84c3c-194e-4521-8cc3-4dff3a796248", "node_type": "1", "metadata": {"window": "So I'm gonna show you some fun videos of lear ning algorithms flying helicopters.  This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right? ", "original_text": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n"}, "hash": "c6f010cf3195243f9ed45992ca5ce07e52c17d5995fd8cd7cbb527fdb646770a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "37c3e884-8e26-4a06-a55a-c6d552852c60", "node_type": "1", "metadata": {"window": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n", "original_text": "What we have to think about is imagine you're \ntrying to train a dog. "}, "hash": "89ad07fa0fc275814ef88d450ffc35ac88b599bec03744e9eb732f2de729a60c", "class_name": "RelatedNodeInfo"}}, "hash": "005ceeebc64939ade63c127b182aaeb6566cf38b2dd67d1e5963687ea4377829", "text": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. ", "start_char_idx": 57313, "end_char_idx": 57446, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "37c3e884-8e26-4a06-a55a-c6d552852c60": {"__data__": {"id_": "37c3e884-8e26-4a06-a55a-c6d552852c60", "embedding": null, "metadata": {"window": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n", "original_text": "What we have to think about is imagine you're \ntrying to train a dog. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20df0bce-3140-4cd5-9034-e5782dc668e5", "node_type": "1", "metadata": {"window": "This is \na video of our helicopter at Stanford flying using a contro ller that was learned using a \nreinforcement learning algorithm.  So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n", "original_text": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function. "}, "hash": "005ceeebc64939ade63c127b182aaeb6566cf38b2dd67d1e5963687ea4377829", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d5b7b230-699e-45ca-ade8-54ef50c52135", "node_type": "1", "metadata": {"window": "You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. ", "original_text": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. "}, "hash": "5c884f715a29ffcf06b2c48f98c8e20b01bf40705c0d89d4f48e0298a1ec26ea", "class_name": "RelatedNodeInfo"}}, "hash": "89ad07fa0fc275814ef88d450ffc35ac88b599bec03744e9eb732f2de729a60c", "text": "What we have to think about is imagine you're \ntrying to train a dog. ", "start_char_idx": 57446, "end_char_idx": 57516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d5b7b230-699e-45ca-ade8-54ef50c52135": {"__data__": {"id_": "d5b7b230-699e-45ca-ade8-54ef50c52135", "embedding": null, "metadata": {"window": "You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. ", "original_text": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37c3e884-8e26-4a06-a55a-c6d552852c60", "node_type": "1", "metadata": {"window": "So this wa s done on the Stanford football field, and \nwe'll zoom out the camera in a second.  You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n", "original_text": "What we have to think about is imagine you're \ntrying to train a dog. "}, "hash": "89ad07fa0fc275814ef88d450ffc35ac88b599bec03744e9eb732f2de729a60c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "657e15f9-32ae-4dcf-9af6-f18dc5e6290f", "node_type": "1", "metadata": {"window": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n", "original_text": "Every time your dog does something bad, you go, \"Bad dog,\" right? "}, "hash": "41ee993c3399ce53d1525174388d940d1fdf65b8b4eae3f8cd03cdbf177a5520", "class_name": "RelatedNodeInfo"}}, "hash": "5c884f715a29ffcf06b2c48f98c8e20b01bf40705c0d89d4f48e0298a1ec26ea", "text": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. ", "start_char_idx": 57516, "end_char_idx": 57607, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "657e15f9-32ae-4dcf-9af6-f18dc5e6290f": {"__data__": {"id_": "657e15f9-32ae-4dcf-9af6-f18dc5e6290f", "embedding": null, "metadata": {"window": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n", "original_text": "Every time your dog does something bad, you go, \"Bad dog,\" right? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d5b7b230-699e-45ca-ade8-54ef50c52135", "node_type": "1", "metadata": {"window": "You'll sort of see th e trees planted in the sky.  So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. ", "original_text": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog. "}, "hash": "5c884f715a29ffcf06b2c48f98c8e20b01bf40705c0d89d4f48e0298a1ec26ea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "135007c4-1491-4d85-b67b-aad08d78a014", "node_type": "1", "metadata": {"window": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics. ", "original_text": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n"}, "hash": "5c793f7c9eceb10ab0deb5281fedd3ca7adee15cad3300b1e110ce5a554bedf1", "class_name": "RelatedNodeInfo"}}, "hash": "41ee993c3399ce53d1525174388d940d1fdf65b8b4eae3f8cd03cdbf177a5520", "text": "Every time your dog does something bad, you go, \"Bad dog,\" right? ", "start_char_idx": 57607, "end_char_idx": 57673, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "135007c4-1491-4d85-b67b-aad08d78a014": {"__data__": {"id_": "135007c4-1491-4d85-b67b-aad08d78a014", "embedding": null, "metadata": {"window": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics. ", "original_text": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "657e15f9-32ae-4dcf-9af6-f18dc5e6290f", "node_type": "1", "metadata": {"window": "So \nmaybe this is one of the most difficult aer obatic maneuvers flown on any helicopter under \ncomputer control.  And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n", "original_text": "Every time your dog does something bad, you go, \"Bad dog,\" right? "}, "hash": "41ee993c3399ce53d1525174388d940d1fdf65b8b4eae3f8cd03cdbf177a5520", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45be72a1-9844-4a61-83c7-b8f62b3b7fce", "node_type": "1", "metadata": {"window": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on. ", "original_text": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n"}, "hash": "a1527a2107f213758a35b6d3a30ceae6a01d829babf568d5b8a2d0a4a4d006d0", "class_name": "RelatedNodeInfo"}}, "hash": "5c793f7c9eceb10ab0deb5281fedd3ca7adee15cad3300b1e110ce5a554bedf1", "text": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n", "start_char_idx": 57673, "end_char_idx": 57944, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "45be72a1-9844-4a61-83c7-b8f62b3b7fce": {"__data__": {"id_": "45be72a1-9844-4a61-83c7-b8f62b3b7fce", "embedding": null, "metadata": {"window": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on. ", "original_text": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "135007c4-1491-4d85-b67b-aad08d78a014", "node_type": "1", "metadata": {"window": "And this controller, which is very, very hard for a human to sit down \nand write out, was learned using one of these reinforcement learning algorithms.  \n Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics. ", "original_text": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n"}, "hash": "5c793f7c9eceb10ab0deb5281fedd3ca7adee15cad3300b1e110ce5a554bedf1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4496f13d-01c2-424f-ada4-2402684b397c", "node_type": "1", "metadata": {"window": "What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them. ", "original_text": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. "}, "hash": "75913c94d4a582b4a7e06469c943fb524c02570858703853145fd3c2910fcc1c", "class_name": "RelatedNodeInfo"}}, "hash": "a1527a2107f213758a35b6d3a30ceae6a01d829babf568d5b8a2d0a4a4d006d0", "text": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n", "start_char_idx": 57944, "end_char_idx": 58167, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4496f13d-01c2-424f-ada4-2402684b397c": {"__data__": {"id_": "4496f13d-01c2-424f-ada4-2402684b397c", "embedding": null, "metadata": {"window": "What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them. ", "original_text": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45be72a1-9844-4a61-83c7-b8f62b3b7fce", "node_type": "1", "metadata": {"window": "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this \nidea of what's called a reward  function.  What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on. ", "original_text": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n"}, "hash": "a1527a2107f213758a35b6d3a30ceae6a01d829babf568d5b8a2d0a4a4d006d0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f3c9b8e-d4ec-40d7-a96a-ae88e8fba960", "node_type": "1", "metadata": {"window": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. ", "original_text": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n"}, "hash": "6bc6a20950722d78b552ac174abc9fbfd8dd20491c1518b2857a0e0cdc8fbf2f", "class_name": "RelatedNodeInfo"}}, "hash": "75913c94d4a582b4a7e06469c943fb524c02570858703853145fd3c2910fcc1c", "text": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. ", "start_char_idx": 58167, "end_char_idx": 58339, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f3c9b8e-d4ec-40d7-a96a-ae88e8fba960": {"__data__": {"id_": "5f3c9b8e-d4ec-40d7-a96a-ae88e8fba960", "embedding": null, "metadata": {"window": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. ", "original_text": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4496f13d-01c2-424f-ada4-2402684b397c", "node_type": "1", "metadata": {"window": "What we have to think about is imagine you're \ntrying to train a dog.  So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them. ", "original_text": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior. "}, "hash": "75913c94d4a582b4a7e06469c943fb524c02570858703853145fd3c2910fcc1c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7dd014dd-2c69-46b4-8de1-edb7ea78758c", "node_type": "1", "metadata": {"window": "Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. ", "original_text": "So it turns out reinforcement learning is applie d to other problems in robotics. "}, "hash": "028f8c9d60f8cde710c2bcaad14a7208d19214f5334312a5dd336e1fe16a5b2c", "class_name": "RelatedNodeInfo"}}, "hash": "6bc6a20950722d78b552ac174abc9fbfd8dd20491c1518b2857a0e0cdc8fbf2f", "text": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n", "start_char_idx": 58339, "end_char_idx": 58487, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7dd014dd-2c69-46b4-8de1-edb7ea78758c": {"__data__": {"id_": "7dd014dd-2c69-46b4-8de1-edb7ea78758c", "embedding": null, "metadata": {"window": "Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. ", "original_text": "So it turns out reinforcement learning is applie d to other problems in robotics. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f3c9b8e-d4ec-40d7-a96a-ae88e8fba960", "node_type": "1", "metadata": {"window": "So every time y our dog does something good, you say, \"Good dog,\" \nand you reward the dog.  Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. ", "original_text": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n"}, "hash": "6bc6a20950722d78b552ac174abc9fbfd8dd20491c1518b2857a0e0cdc8fbf2f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bbc42688-7a29-4884-9335-5916d9b8809d", "node_type": "1", "metadata": {"window": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n", "original_text": "It's applied \nto things in web crawling and so on. "}, "hash": "d7be0b52d6455369a353379c1d4cf38774c141f9a5749b373b47736e2620c82e", "class_name": "RelatedNodeInfo"}}, "hash": "028f8c9d60f8cde710c2bcaad14a7208d19214f5334312a5dd336e1fe16a5b2c", "text": "So it turns out reinforcement learning is applie d to other problems in robotics. ", "start_char_idx": 58487, "end_char_idx": 58569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bbc42688-7a29-4884-9335-5916d9b8809d": {"__data__": {"id_": "bbc42688-7a29-4884-9335-5916d9b8809d", "embedding": null, "metadata": {"window": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n", "original_text": "It's applied \nto things in web crawling and so on. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7dd014dd-2c69-46b4-8de1-edb7ea78758c", "node_type": "1", "metadata": {"window": "Every time your dog does something bad, you go, \"Bad dog,\" right?  And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. ", "original_text": "So it turns out reinforcement learning is applie d to other problems in robotics. "}, "hash": "028f8c9d60f8cde710c2bcaad14a7208d19214f5334312a5dd336e1fe16a5b2c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8260d82b-7803-4b19-b09e-991bf6eb32b4", "node_type": "1", "metadata": {"window": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n", "original_text": "But it's just  cool to show videos, so let me just show \na bunch of them. "}, "hash": "4be3058a898a7333048e0777677e4ecfc383f83a46e07d3a8802495297d71146", "class_name": "RelatedNodeInfo"}}, "hash": "d7be0b52d6455369a353379c1d4cf38774c141f9a5749b373b47736e2620c82e", "text": "It's applied \nto things in web crawling and so on. ", "start_char_idx": 58569, "end_char_idx": 58620, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8260d82b-7803-4b19-b09e-991bf6eb32b4": {"__data__": {"id_": "8260d82b-7803-4b19-b09e-991bf6eb32b4", "embedding": null, "metadata": {"window": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n", "original_text": "But it's just  cool to show videos, so let me just show \na bunch of them. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bbc42688-7a29-4884-9335-5916d9b8809d", "node_type": "1", "metadata": {"window": "And hopefully, over time, your dog will lear n to do the right things to get more of \nthe positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.\u201d  \n\nSo the way we teach a helicopter to fly or any of these robots is sort of the same thing. \n Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n", "original_text": "It's applied \nto things in web crawling and so on. "}, "hash": "d7be0b52d6455369a353379c1d4cf38774c141f9a5749b373b47736e2620c82e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc4880ab-e6d7-48e4-8815-5d1517ffd9e6", "node_type": "1", "metadata": {"window": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.  ", "original_text": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. "}, "hash": "c351be24d701fa89d8001797ba056e52d98290dbc35f977804e9a0d45f64138d", "class_name": "RelatedNodeInfo"}}, "hash": "4be3058a898a7333048e0777677e4ecfc383f83a46e07d3a8802495297d71146", "text": "But it's just  cool to show videos, so let me just show \na bunch of them. ", "start_char_idx": 58620, "end_char_idx": 58694, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc4880ab-e6d7-48e4-8815-5d1517ffd9e6": {"__data__": {"id_": "bc4880ab-e6d7-48e4-8815-5d1517ffd9e6", "embedding": null, "metadata": {"window": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.  ", "original_text": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8260d82b-7803-4b19-b09e-991bf6eb32b4", "node_type": "1", "metadata": {"window": "Every time the helicopter crashes, we go, \"B ad helicopter,\" and every time it does the \nright thing, we go, \"Good helicopter, \" and over time it learns how to control itself so as to \nget more of these positive rewards.  \n So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n", "original_text": "But it's just  cool to show videos, so let me just show \na bunch of them. "}, "hash": "4be3058a898a7333048e0777677e4ecfc383f83a46e07d3a8802495297d71146", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5758d178-bfae-4561-94a3-01142a9ac845", "node_type": "1", "metadata": {"window": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n", "original_text": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. "}, "hash": "66d33352950e6c0d46bf18eebee7895a5b08fe252205f8cfea69653d0abf29b2", "class_name": "RelatedNodeInfo"}}, "hash": "c351be24d701fa89d8001797ba056e52d98290dbc35f977804e9a0d45f64138d", "text": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. ", "start_char_idx": 58694, "end_char_idx": 58799, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5758d178-bfae-4561-94a3-01142a9ac845": {"__data__": {"id_": "5758d178-bfae-4561-94a3-01142a9ac845", "embedding": null, "metadata": {"window": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n", "original_text": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc4880ab-e6d7-48e4-8815-5d1517ffd9e6", "node_type": "1", "metadata": {"window": "So reinforcement learning is \u2014 I think of it as a way for you to specify what you want \ndone, so you have to specify what is a \"good dog\" and what is a \"bad dog\" behavior.  And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.  ", "original_text": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog. "}, "hash": "c351be24d701fa89d8001797ba056e52d98290dbc35f977804e9a0d45f64138d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "934d37e6-d4df-4a02-91e0-e563e477b146", "node_type": "1", "metadata": {"window": "So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. ", "original_text": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n"}, "hash": "7551886360bcb57219e48bb1cfc004e1a1038c1e251ef64bada1d50f073177d2", "class_name": "RelatedNodeInfo"}}, "hash": "66d33352950e6c0d46bf18eebee7895a5b08fe252205f8cfea69653d0abf29b2", "text": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. ", "start_char_idx": 58799, "end_char_idx": 58906, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "934d37e6-d4df-4a02-91e0-e563e477b146": {"__data__": {"id_": "934d37e6-d4df-4a02-91e0-e563e477b146", "embedding": null, "metadata": {"window": "So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. ", "original_text": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5758d178-bfae-4561-94a3-01142a9ac845", "node_type": "1", "metadata": {"window": "And \nthen it's up to the learning algorithm to  figure out how to maximize the \"good dog\" \nreward signals and minimize the \"bad dog\" punishments.  \n So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n", "original_text": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others. "}, "hash": "66d33352950e6c0d46bf18eebee7895a5b08fe252205f8cfea69653d0abf29b2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81ab4f59-1ea0-42df-ba57-edfbce96af8c", "node_type": "1", "metadata": {"window": "It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry. ", "original_text": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n"}, "hash": "52c5193f108dcab428ca3875e41d551d1f69a4e1041d11c2c187d262817e9a3a", "class_name": "RelatedNodeInfo"}}, "hash": "7551886360bcb57219e48bb1cfc004e1a1038c1e251ef64bada1d50f073177d2", "text": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n", "start_char_idx": 58906, "end_char_idx": 58979, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81ab4f59-1ea0-42df-ba57-edfbce96af8c": {"__data__": {"id_": "81ab4f59-1ea0-42df-ba57-edfbce96af8c", "embedding": null, "metadata": {"window": "It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry. ", "original_text": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "934d37e6-d4df-4a02-91e0-e563e477b146", "node_type": "1", "metadata": {"window": "So it turns out reinforcement learning is applie d to other problems in robotics.  It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. ", "original_text": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n"}, "hash": "7551886360bcb57219e48bb1cfc004e1a1038c1e251ef64bada1d50f073177d2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e056924c-4bad-48d7-993e-71c8abaad9f7", "node_type": "1", "metadata": {"window": "But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small. ", "original_text": "Below that, this is kind of a fun example.  "}, "hash": "d35ec3a9f714705d7c60c8dce02a6abfcfc4b8277468ac2e321e70216847cec2", "class_name": "RelatedNodeInfo"}}, "hash": "52c5193f108dcab428ca3875e41d551d1f69a4e1041d11c2c187d262817e9a3a", "text": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n", "start_char_idx": 58979, "end_char_idx": 59173, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e056924c-4bad-48d7-993e-71c8abaad9f7": {"__data__": {"id_": "e056924c-4bad-48d7-993e-71c8abaad9f7", "embedding": null, "metadata": {"window": "But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small. ", "original_text": "Below that, this is kind of a fun example.  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81ab4f59-1ea0-42df-ba57-edfbce96af8c", "node_type": "1", "metadata": {"window": "It's applied \nto things in web crawling and so on.  But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry. ", "original_text": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n"}, "hash": "52c5193f108dcab428ca3875e41d551d1f69a4e1041d11c2c187d262817e9a3a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3de7c9ba-d537-4ae8-bfaa-8c36c823645d", "node_type": "1", "metadata": {"window": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n", "original_text": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n"}, "hash": "529d9dca4509b1460abb387077a325fa3f8e51870e6610b5b9976bdae776c440", "class_name": "RelatedNodeInfo"}}, "hash": "d35ec3a9f714705d7c60c8dce02a6abfcfc4b8277468ac2e321e70216847cec2", "text": "Below that, this is kind of a fun example.  ", "start_char_idx": 59173, "end_char_idx": 59217, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3de7c9ba-d537-4ae8-bfaa-8c36c823645d": {"__data__": {"id_": "3de7c9ba-d537-4ae8-bfaa-8c36c823645d", "embedding": null, "metadata": {"window": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n", "original_text": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e056924c-4bad-48d7-993e-71c8abaad9f7", "node_type": "1", "metadata": {"window": "But it's just  cool to show videos, so let me just show \na bunch of them.  This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small. ", "original_text": "Below that, this is kind of a fun example.  "}, "hash": "d35ec3a9f714705d7c60c8dce02a6abfcfc4b8277468ac2e321e70216847cec2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "543cc845-65c0-4f36-976f-8874379558f5", "node_type": "1", "metadata": {"window": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n", "original_text": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. "}, "hash": "a3e70a55fdfe6ecd8981ab355904a1dd324063c72783480f9d907428690e7fe0", "class_name": "RelatedNodeInfo"}}, "hash": "529d9dca4509b1460abb387077a325fa3f8e51870e6610b5b9976bdae776c440", "text": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n", "start_char_idx": 59217, "end_char_idx": 59365, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "543cc845-65c0-4f36-976f-8874379558f5": {"__data__": {"id_": "543cc845-65c0-4f36-976f-8874379558f5", "embedding": null, "metadata": {"window": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n", "original_text": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3de7c9ba-d537-4ae8-bfaa-8c36c823645d", "node_type": "1", "metadata": {"window": "This learning algorithm was actually implemented by our head TA, Zico, of programming a four-legged dog.  I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n", "original_text": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n"}, "hash": "529d9dca4509b1460abb387077a325fa3f8e51870e6610b5b9976bdae776c440", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d90418e2-eb02-495c-9831-ce5fb5345745", "node_type": "1", "metadata": {"window": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. ", "original_text": "Sorry. "}, "hash": "977fdc3f47be50883e6c9e7f66c3a780e61aafdd3f5df1527754ee49a44cd5a0", "class_name": "RelatedNodeInfo"}}, "hash": "a3e70a55fdfe6ecd8981ab355904a1dd324063c72783480f9d907428690e7fe0", "text": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. ", "start_char_idx": 59365, "end_char_idx": 59562, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d90418e2-eb02-495c-9831-ce5fb5345745": {"__data__": {"id_": "d90418e2-eb02-495c-9831-ce5fb5345745", "embedding": null, "metadata": {"window": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. ", "original_text": "Sorry. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "543cc845-65c0-4f36-976f-8874379558f5", "node_type": "1", "metadata": {"window": "I guess Sam Shriver in this class also worked \non the project and Peter Renfrew and Mike and a few others.  But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n", "original_text": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle. "}, "hash": "a3e70a55fdfe6ecd8981ab355904a1dd324063c72783480f9d907428690e7fe0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ef1c983-f163-4f76-b56d-102b4cd2acbc", "node_type": "1", "metadata": {"window": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n", "original_text": "I know the video's kind of small. "}, "hash": "f0fec05f3729a862ae4ffde34d5873104a06fbf531d34a55681181e7b3296bcf", "class_name": "RelatedNodeInfo"}}, "hash": "977fdc3f47be50883e6c9e7f66c3a780e61aafdd3f5df1527754ee49a44cd5a0", "text": "Sorry. ", "start_char_idx": 59562, "end_char_idx": 59569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5ef1c983-f163-4f76-b56d-102b4cd2acbc": {"__data__": {"id_": "5ef1c983-f163-4f76-b56d-102b4cd2acbc", "embedding": null, "metadata": {"window": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n", "original_text": "I know the video's kind of small. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d90418e2-eb02-495c-9831-ce5fb5345745", "node_type": "1", "metadata": {"window": "But I guess this really is a \ngood dog/bad dog since it's a robot dog.  \n The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. ", "original_text": "Sorry. "}, "hash": "977fdc3f47be50883e6c9e7f66c3a780e61aafdd3f5df1527754ee49a44cd5a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b30b3ae-f213-42b3-b748-faa04ab06321", "node_type": "1", "metadata": {"window": "Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay. ", "original_text": "I hope you can sort of see it. \n"}, "hash": "fa51cda505fa1f07751378d6e668c1af90a9af408397624abb849cf3839e8abc", "class_name": "RelatedNodeInfo"}}, "hash": "f0fec05f3729a862ae4ffde34d5873104a06fbf531d34a55681181e7b3296bcf", "text": "I know the video's kind of small. ", "start_char_idx": 59569, "end_char_idx": 59603, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b30b3ae-f213-42b3-b748-faa04ab06321": {"__data__": {"id_": "0b30b3ae-f213-42b3-b748-faa04ab06321", "embedding": null, "metadata": {"window": "Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay. ", "original_text": "I hope you can sort of see it. \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5ef1c983-f163-4f76-b56d-102b4cd2acbc", "node_type": "1", "metadata": {"window": "The second video on the right, some of the st udents, I guess Peter, Zico, Tonca working \non a robotic snake, again using learning algorith ms to teach a snake robot to climb over \nobstacles.  \n Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n", "original_text": "I know the video's kind of small. "}, "hash": "f0fec05f3729a862ae4ffde34d5873104a06fbf531d34a55681181e7b3296bcf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a72d28d-202c-4423-9e52-805161ab2254", "node_type": "1", "metadata": {"window": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today. ", "original_text": "Okay?  \n"}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "class_name": "RelatedNodeInfo"}}, "hash": "fa51cda505fa1f07751378d6e668c1af90a9af408397624abb849cf3839e8abc", "text": "I hope you can sort of see it. \n", "start_char_idx": 59603, "end_char_idx": 59635, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a72d28d-202c-4423-9e52-805161ab2254": {"__data__": {"id_": "3a72d28d-202c-4423-9e52-805161ab2254", "embedding": null, "metadata": {"window": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today. ", "original_text": "Okay?  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b30b3ae-f213-42b3-b748-faa04ab06321", "node_type": "1", "metadata": {"window": "Below that, this is kind of a fun example.   Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay. ", "original_text": "I hope you can sort of see it. \n"}, "hash": "fa51cda505fa1f07751378d6e668c1af90a9af408397624abb849cf3839e8abc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "65f8b72e-041e-4a38-aabe-46781ddf6433", "node_type": "1", "metadata": {"window": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now. ", "original_text": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. "}, "hash": "c597cf8d8eb3ba32113a88d0113eef41e481a8664dfac68263a60fd2f7efe2d7", "class_name": "RelatedNodeInfo"}}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "text": "Okay?  \n", "start_char_idx": 41914, "end_char_idx": 41922, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "65f8b72e-041e-4a38-aabe-46781ddf6433": {"__data__": {"id_": "65f8b72e-041e-4a38-aabe-46781ddf6433", "embedding": null, "metadata": {"window": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now. ", "original_text": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a72d28d-202c-4423-9e52-805161ab2254", "node_type": "1", "metadata": {"window": "Ashutosh Saxena and Jeff Michaels used \nlearning algorithms to teach a car how to  drive at reasonably high speeds off roads \navoiding obstacles.  \n And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today. ", "original_text": "Okay?  \n"}, "hash": "78737845cd8a1b8805cb60ea051d31972916985f16b59d9d5f1ba4a6f023d029", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b50cd93-a97e-4f11-9666-d949a199c344", "node_type": "1", "metadata": {"window": "Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. ", "original_text": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n"}, "hash": "331fb33155ea7353641f88083e5c234bb6a31e6322d9c3bd7cf807211dc9f2d7", "class_name": "RelatedNodeInfo"}}, "hash": "c597cf8d8eb3ba32113a88d0113eef41e481a8664dfac68263a60fd2f7efe2d7", "text": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. ", "start_char_idx": 59643, "end_char_idx": 59791, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b50cd93-a97e-4f11-9666-d949a199c344": {"__data__": {"id_": "5b50cd93-a97e-4f11-9666-d949a199c344", "embedding": null, "metadata": {"window": "Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. ", "original_text": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65f8b72e-041e-4a38-aabe-46781ddf6433", "node_type": "1", "metadata": {"window": "And on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \nover an obstacle.  Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now. ", "original_text": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms. "}, "hash": "c597cf8d8eb3ba32113a88d0113eef41e481a8664dfac68263a60fd2f7efe2d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "99ef7dfc-d0a6-474f-8734-a6fada38b9eb", "node_type": "1", "metadata": {"window": "I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}}, "hash": "331fb33155ea7353641f88083e5c234bb6a31e6322d9c3bd7cf807211dc9f2d7", "text": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n", "start_char_idx": 59791, "end_char_idx": 59875, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "99ef7dfc-d0a6-474f-8734-a6fada38b9eb": {"__data__": {"id_": "99ef7dfc-d0a6-474f-8734-a6fada38b9eb", "embedding": null, "metadata": {"window": "I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? ", "original_text": "Okay. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b50cd93-a97e-4f11-9666-d949a199c344", "node_type": "1", "metadata": {"window": "Sorry.  I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. ", "original_text": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n"}, "hash": "331fb33155ea7353641f88083e5c234bb6a31e6322d9c3bd7cf807211dc9f2d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c3619c96-f3a0-4b4f-ba03-1c778d4fc32f", "node_type": "1", "metadata": {"window": "I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n", "original_text": "So that was most of what I wanted to say today. "}, "hash": "4709f7f0e221636ac0b6c38a22ab2b28df0192176a598807ae341f1a3b348125", "class_name": "RelatedNodeInfo"}}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "text": "Okay. ", "start_char_idx": 53, "end_char_idx": 59, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c3619c96-f3a0-4b4f-ba03-1c778d4fc32f": {"__data__": {"id_": "c3619c96-f3a0-4b4f-ba03-1c778d4fc32f", "embedding": null, "metadata": {"window": "I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n", "original_text": "So that was most of what I wanted to say today. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "99ef7dfc-d0a6-474f-8734-a6fada38b9eb", "node_type": "1", "metadata": {"window": "I know the video's kind of small.  I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? ", "original_text": "Okay. "}, "hash": "8c74d3d919ced2f9e07c0125aa17f32384910008e391f75cda12455e9483c35f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc8b0b8f-094f-4b46-a119-a208e768161d", "node_type": "1", "metadata": {"window": "Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you. ", "original_text": "Just a couple more last things, but \nlet me just check what questions you have righ t now. "}, "hash": "a1df4cdea06246322234fe44bdf25c7e1d83a3bbe0ea6dbaa937e4f9c4b12f7f", "class_name": "RelatedNodeInfo"}}, "hash": "4709f7f0e221636ac0b6c38a22ab2b28df0192176a598807ae341f1a3b348125", "text": "So that was most of what I wanted to say today. ", "start_char_idx": 59881, "end_char_idx": 59929, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dc8b0b8f-094f-4b46-a119-a208e768161d": {"__data__": {"id_": "dc8b0b8f-094f-4b46-a119-a208e768161d", "embedding": null, "metadata": {"window": "Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you. ", "original_text": "Just a couple more last things, but \nlet me just check what questions you have righ t now. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3619c96-f3a0-4b4f-ba03-1c778d4fc32f", "node_type": "1", "metadata": {"window": "I hope you can sort of see it. \n Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n", "original_text": "So that was most of what I wanted to say today. "}, "hash": "4709f7f0e221636ac0b6c38a22ab2b28df0192176a598807ae341f1a3b348125", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc9254bd-5a22-449a-9b26-14d19ad0eb34", "node_type": "1", "metadata": {"window": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n", "original_text": "So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. "}, "hash": "db3965551b39f16ffd01941f149d38e0deceda396fadf9f56603eb238c6f8220", "class_name": "RelatedNodeInfo"}}, "hash": "a1df4cdea06246322234fe44bdf25c7e1d83a3bbe0ea6dbaa937e4f9c4b12f7f", "text": "Just a couple more last things, but \nlet me just check what questions you have righ t now. ", "start_char_idx": 59929, "end_char_idx": 60020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc9254bd-5a22-449a-9b26-14d19ad0eb34": {"__data__": {"id_": "fc9254bd-5a22-449a-9b26-14d19ad0eb34", "embedding": null, "metadata": {"window": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n", "original_text": "So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc8b0b8f-094f-4b46-a119-a208e768161d", "node_type": "1", "metadata": {"window": "Okay?  \n So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you. ", "original_text": "Just a couple more last things, but \nlet me just check what questions you have righ t now. "}, "hash": "a1df4cdea06246322234fe44bdf25c7e1d83a3bbe0ea6dbaa937e4f9c4b12f7f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "23894e40-7abd-40ad-9130-26f1a4da2733", "node_type": "1", "metadata": {"window": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? "}, "hash": "a72d085feea5982cf88e4277f61d9df363d8f1fe82408338c8b3ab0507b5a401", "class_name": "RelatedNodeInfo"}}, "hash": "db3965551b39f16ffd01941f149d38e0deceda396fadf9f56603eb238c6f8220", "text": "So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. ", "start_char_idx": 60020, "end_char_idx": 60293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "23894e40-7abd-40ad-9130-26f1a4da2733": {"__data__": {"id_": "23894e40-7abd-40ad-9130-26f1a4da2733", "embedding": null, "metadata": {"window": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc9254bd-5a22-449a-9b26-14d19ad0eb34", "node_type": "1", "metadata": {"window": "So I think all of these are robots that I thi nk are very difficult to hand-code a controller \nfor by learning these sorts of l earning algorithms.  You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n", "original_text": "So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. "}, "hash": "db3965551b39f16ffd01941f149d38e0deceda396fadf9f56603eb238c6f8220", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "43cf5c8c-54b6-493b-8110-fbe582fb0bbe", "node_type": "1", "metadata": {"window": "Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "Form study groups, and try \nto find two other project partners.  \n"}, "hash": "c13f960147f8d10441401fe425a54fd478d301222a84b88df8b0832ec842bac3", "class_name": "RelatedNodeInfo"}}, "hash": "a72d085feea5982cf88e4277f61d9df363d8f1fe82408338c8b3ab0507b5a401", "text": "And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? ", "start_char_idx": 60293, "end_char_idx": 60490, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "43cf5c8c-54b6-493b-8110-fbe582fb0bbe": {"__data__": {"id_": "43cf5c8c-54b6-493b-8110-fbe582fb0bbe", "embedding": null, "metadata": {"window": "Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "Form study groups, and try \nto find two other project partners.  \n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "23894e40-7abd-40ad-9130-26f1a4da2733", "node_type": "1", "metadata": {"window": "You can in relatively short order get a \nrobot to do often pretty amazing things.  \n Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? "}, "hash": "a72d085feea5982cf88e4277f61d9df363d8f1fe82408338c8b3ab0507b5a401", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eceeb8d3-1590-4457-8134-e3fa44120cf4", "node_type": "1", "metadata": {"window": "So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "So thank you. "}, "hash": "6495019f065f70289fec47a67cfcc8fd16d80fa93b779edae7b7af2c83fe7f44", "class_name": "RelatedNodeInfo"}}, "hash": "c13f960147f8d10441401fe425a54fd478d301222a84b88df8b0832ec842bac3", "text": "Form study groups, and try \nto find two other project partners.  \n", "start_char_idx": 60490, "end_char_idx": 60556, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eceeb8d3-1590-4457-8134-e3fa44120cf4": {"__data__": {"id_": "eceeb8d3-1590-4457-8134-e3fa44120cf4", "embedding": null, "metadata": {"window": "So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "So thank you. "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "43cf5c8c-54b6-493b-8110-fbe582fb0bbe", "node_type": "1", "metadata": {"window": "Okay.  So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "Form study groups, and try \nto find two other project partners.  \n"}, "hash": "c13f960147f8d10441401fe425a54fd478d301222a84b88df8b0832ec842bac3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0971720b-a10f-4309-9d43-4b5f71952244", "node_type": "1", "metadata": {"window": "Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n"}, "hash": "80ea2e6c491f48a81650265b0dab88d7f35a24d69e7d0871c626b63edb738d5e", "class_name": "RelatedNodeInfo"}}, "hash": "6495019f065f70289fec47a67cfcc8fd16d80fa93b779edae7b7af2c83fe7f44", "text": "So thank you. ", "start_char_idx": 60556, "end_char_idx": 60570, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0971720b-a10f-4309-9d43-4b5f71952244": {"__data__": {"id_": "0971720b-a10f-4309-9d43-4b5f71952244", "embedding": null, "metadata": {"window": "Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n"}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eceeb8d3-1590-4457-8134-e3fa44120cf4", "node_type": "1", "metadata": {"window": "So that was most of what I wanted to say today.  Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "So thank you. "}, "hash": "6495019f065f70289fec47a67cfcc8fd16d80fa93b779edae7b7af2c83fe7f44", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1437fbb7-9acb-4554-84bd-cc80d45c722c", "node_type": "1", "metadata": {"window": "So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "[End of Audio]  \nDuration: 69 minutes  "}, "hash": "e02cdcdd660abc69207166afef7896d8fa4a4c071fe0e7a6e1d0e41c9db8c0eb", "class_name": "RelatedNodeInfo"}}, "hash": "80ea2e6c491f48a81650265b0dab88d7f35a24d69e7d0871c626b63edb738d5e", "text": "I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n", "start_char_idx": 60570, "end_char_idx": 60656, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1437fbb7-9acb-4554-84bd-cc80d45c722c": {"__data__": {"id_": "1437fbb7-9acb-4554-84bd-cc80d45c722c", "embedding": null, "metadata": {"window": "So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "[End of Audio]  \nDuration: 69 minutes  "}, "excluded_embed_metadata_keys": ["window", "original_text"], "excluded_llm_metadata_keys": ["window", "original_text"], "relationships": {"1": {"node_id": "23a01a5c-17be-4dd1-b7b5-6b15967f05f1", "node_type": "4", "metadata": {}, "hash": "e714ba7ef66f4173fc617800bffadd34bf42af25538984af7603084ac1df6db3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0971720b-a10f-4309-9d43-4b5f71952244", "node_type": "1", "metadata": {"window": "Just a couple more last things, but \nlet me just check what questions you have righ t now.  So if there are no questions, I'll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with.  And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay?  Form study groups, and try \nto find two other project partners.  \n So thank you.  I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n [End of Audio]  \nDuration: 69 minutes  ", "original_text": "I'm looking forward to teaching this class, and I'll see you in a couple of \ndays.  \n\n"}, "hash": "80ea2e6c491f48a81650265b0dab88d7f35a24d69e7d0871c626b63edb738d5e", "class_name": "RelatedNodeInfo"}}, "hash": "e02cdcdd660abc69207166afef7896d8fa4a4c071fe0e7a6e1d0e41c9db8c0eb", "text": "[End of Audio]  \nDuration: 69 minutes  ", "start_char_idx": 60656, "end_char_idx": 60695, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"23a01a5c-17be-4dd1-b7b5-6b15967f05f1": {"node_ids": ["fbf1ada9-b5fa-4bdb-9909-137b8f28e1e8", "1c6c1b0f-c818-44af-a4d5-6797baed1e72", "d69b7e17-ac48-40dd-8d20-6b2425044f2c", "73cc978a-73e4-4fd9-96a5-cef57959dc0e", "46176f33-de2a-41e4-9b60-ab672142c89e", "48ddae5c-ce38-4210-9ce0-2dce0b585376", "14182cd4-0589-4368-83ab-3cc5841caec0", "77fafd39-1cfc-4f58-9e2f-b84f19e2d8bb", "d39027f7-8f6c-4991-a104-f6cde2aa6d58", "89d47952-5df5-4ca4-bd99-eb2669de5e21", "ba08fbda-b05f-4fb2-b051-bb8c5d9f2852", "1557720e-3684-46ef-95bc-79b8c00fa8f8", "330d0e94-f923-454f-b8c2-a90fa48b7baa", "fadb5d61-d36b-4138-8d0c-b74c519348a3", "2782c7d2-28f4-4105-9e7f-402ac34a8a86", "d5198ce1-8410-4ae9-a311-38bc88e6b051", "ba2a2850-00ac-441c-be3a-85307791c162", "6b1e2466-31cd-4660-bbee-f4edf97f3af8", "371c53f3-de43-44bc-8eda-c6807ef8d67f", "ce37c297-3fff-4105-a18c-ee23461555db", "ba392562-f719-4af7-9fd1-947511931409", "df08fe46-57de-48e2-9ee6-b2e751bc026d", "aa537df5-57c0-4812-848d-d7aedc9ae24d", "12383c91-984d-4be1-96aa-23db2c0b63d7", "fb639edb-9f25-4fa5-b57a-80ebeb15d389", "4ae70e01-90d5-4f4e-9e42-e0bc6a26cc42", "d76a60ad-edc0-41f3-b74a-1c88f10046c9", "f5b2e791-1e16-4086-8897-386995a6082a", "a827aa0e-397f-4b0b-bb14-7358b7193722", "acb27c0f-39c3-48d6-9539-e59ef42a900a", "bb39c138-c38b-482e-aca8-5558676ba6bd", "14892dd0-f5bd-45c9-b3d9-cab15f14fa81", "1a66548c-d067-4aa0-8c6f-51ced06f0931", "9112c04e-f1c3-4c7a-8279-cf7cc673c07c", "de25c6d7-3445-4cee-a313-b679a0d47fb0", "2f5baa1d-e9d3-4152-8ffe-617d077e37ff", "4ac92cf2-7fbc-4679-87dc-76c58bef1f5f", "58ad6948-5d3c-410c-aafd-2c7e005318d9", "81ad316d-3411-426f-8fdf-6500d6554154", "409dae7a-87be-4b54-a369-ee20fe75fa0b", "9d48d5a6-2c27-4674-bb4e-7e0374c78464", "ece3f660-e1ee-4a0a-83a9-c9b04d373199", "7cdbe830-9cb7-4927-ad86-f37dd824a1ca", "edb3cb5e-dac4-4bf9-9dc2-155adecfa763", "d0e25a07-9982-43a7-bd8b-4ea383cfe81c", "3ec785d2-72ea-41d1-ae3e-868873270333", "a8789715-3a48-4d70-a63f-ce61b96ecdfe", "69d5a32f-7274-475e-b79c-f1ff184be0a9", "abc0e169-74ac-4aab-87c2-7f167b8e054b", "c63e20e3-7c3b-453a-9013-864088b107f0", "08fc9c23-e41d-4fa0-af6a-28126471dc0f", "1bab64b2-0091-4922-83a9-85b37582bdc8", "1245df91-a0f3-45be-833b-e3870540e8ae", "05784733-673b-4a76-931a-f45479a49ba7", "eeeae031-8f68-4318-bbdf-a0cedf24db28", "bd2b0e5a-5b68-4817-91c2-b83c066837df", "ecb917f1-9ae9-43dc-a978-5729d54d0fde", "d2a1ab1e-6d3c-47b8-9793-66d5a43413cb", "852f5349-fc66-4037-a43b-82fb37900f1c", "cfa56a96-82a1-4352-8e7f-653e80cb2bd0", "a2b8191f-e78f-424e-aee2-a9205c05d40e", "b5423250-608d-4fd0-a28b-dafe99e23a4b", "5521157b-1012-470a-bd03-83849e265f18", "079b3d1e-6872-480f-b4c3-25173d15daf8", "29614fb0-02ae-4f51-b53e-dd7291a02e19", "be4cb9e8-ac61-4e76-a136-68b99fb9aa59", "64d207b4-6214-45a0-bd3d-4ff7f9a949bd", "bc00279f-14a2-4f02-b314-0cadfa05ab92", "739917e5-73d7-447d-913b-b8ec8e81f009", "97a957d6-d9da-45fd-bdba-d4c6155bdc60", "a12dec1e-86bf-427f-9ee1-f5d811d912d2", "b3a99b78-b28e-4a45-b364-9ba95ec3e816", "f1ebacbc-defd-4059-8c27-02a46f9ba11c", "a69f557f-853f-4953-a46a-deb1f7ff7726", "3f7e73a5-69b8-45b6-9239-a576b1bc6acb", "c81b6ab2-bc6f-47f7-8da6-487fa4cc1f52", "806fbdf1-0dc1-438a-bcf6-1613e6d7fe0e", "97ce680d-4b8a-4e46-838a-d857b8f3bbbe", "d16acc9f-ef1f-451d-8cf0-e3dfb7bff45a", "28fed53b-6ee5-48ed-9cb4-a978cfbe7434", "1fce667c-c143-4167-9886-3eb9b8cafb5d", "b4ed09af-1b81-47df-9d6d-d6640b666d78", "832089fb-ae76-4182-a389-a539669d8a8f", "b0caad91-0adb-486b-8ac0-f6469d776d70", "15f3b207-bdb8-4a58-881a-22f28a8067da", "8c355ac2-e588-47e1-a35c-c4887640db32", "6d9bf82f-2a03-4ac5-b256-bdc87a16db79", "67e7e0f1-5c4c-4f35-ad12-a0eb46264e49", "ba529973-7093-4808-87ea-aa839f96716f", "ac19a687-8daa-4832-9534-85587ef13d60", "905a0c4f-785c-4642-8b4c-26aac4624f1e", "b79cd5dd-16d7-4d58-8e08-285d3d96c41f", "6a6f92a5-e827-40c4-a6b1-88a1e4e36cda", "50c8e165-a00a-4d10-b21f-8787dcfcf71d", "7e472862-192e-4b42-ac12-fa06aa0f55d0", "468274fc-2062-4428-b75e-ea271626ca50", "c815abe7-aa83-459d-a855-7c6d3146aa52", "310c4dc0-fdbe-4439-b842-93bb6b56fe40", "53612ea8-f03a-4003-b9ec-fefc2f8e6c90", "bdaa5ec9-5491-49f1-b6e2-1f3cfc2222b2", "f4d57d34-b415-45a2-b3f1-7f1cb877b243", "88b5d06b-4c20-4b09-b1c5-e0b555854488", "707e4f64-596f-4f5d-adf2-6c105cd2781c", "c8da8742-a327-4c2b-ba3d-cc81b8709673", "71c7e64a-e396-4147-8c62-754832b3ec70", "a8eea312-60f8-4b10-96ab-b6d2d920bf41", "90efa3a3-8eec-4bd5-a57e-10edd2b3fc91", "a568f1c5-01cf-4c4f-bb59-cbcf68c630ac", "736b0947-88bc-46ec-ac5f-8def163c6cdb", "e8059fbe-8c4e-4c28-a42d-b361ff0a0cb1", "e9356c27-9f45-469b-b3e8-92ccc77e8479", "0de43831-200d-4c50-b3b2-92a15040f35c", "329470c1-b402-4402-a19d-2180fa89a01b", "a5c15082-c1db-4f6d-95b1-9e53b9ccd2f2", "d9bccb95-1fa9-4a3a-9f4d-ea090ceb281a", "5b25156a-87c4-45cc-8da4-5f78ba11596f", "3a4ed568-3f83-4d91-b199-5fb596bafd79", "093c4841-0ea8-45e3-b0ca-fdffd036809e", "28a8b6a9-9b90-4ec5-9edb-a7d39175c033", "4be2f053-ba7d-401b-84f6-54efa75a7b78", "10664c78-cdd1-4c89-8fd7-39e4d9aab81f", "f6a722f7-69a9-4fec-a6ef-e3cef9737c8f", "2c8b557b-a681-4607-86c3-a7e16ea70f61", "7c79b0f3-6f6e-4afa-91ac-deef120efe4c", "20bd9b90-8e3b-496e-9379-ff6600fdc27b", "5f2095ed-0e7a-45a2-be37-2ae7e95f602e", "695b6bd6-23e5-4675-b640-3a3988140948", "193ec0eb-b51c-408a-8f27-ba22a38aa190", "f38b633b-21d5-432c-a636-71faa7f152c3", "b312024a-d71e-4a14-9d51-5a79e83e8883", "99d38753-bf42-4bfa-be49-bc069b1bf3c0", "9825dce6-857f-4691-9d0b-eda34ec5a59c", "32c0b547-6fc7-4d93-acdd-e27cb4e6713f", "9d9e08a0-c0c2-431d-8150-63dea9fced95", "75476202-adfe-4271-8c29-841dc4eb40e2", "a7e43216-402a-4e5f-8bc3-c8afd91a486e", "40b7204c-42fd-445e-a7d4-eb9c37349df3", "069a68a9-8c48-412c-a905-47fa844abe5c", "a94b49b2-0fa5-4553-8722-7eb606a5e0b3", "704467fd-d748-4ef7-8349-273e6ca7bd31", "caa31d19-4204-4f77-b059-0b6ece766507", "1de041b1-402d-4ff8-947b-55adf606e27a", "ac89c9b1-1603-4ab5-b97d-efb8cdc0c81c", "d7751d0e-2b82-40bf-a8a3-10a1b85712cc", "403d83c8-ac17-4031-8791-21ea76fdbd3e", "bb57749f-2246-406f-88c1-d804bbd5eacd", "236594cb-ed86-4d43-beea-006c536fc76a", "de431448-acb7-46f9-bd12-233cb1addd63", "87c0ab7d-357b-45d0-ab10-78eec8f77c7a", "1b473ec0-2c18-4de1-bec0-a980859fbec0", "a1ac08c1-0a3b-4efb-8221-78e598994e4e", "80320470-9e88-4c01-aef4-f675b2ca397b", "9b4fd04c-6bd3-4564-b51a-110e8edb324d", "a73d5032-2f9a-431a-9ae8-66b0963683cd", "a887d294-892f-44ca-9566-71b947afd593", "cfd90cfe-88da-440b-a9b2-4199146e60d0", "89b67a36-f4c2-4dcf-b2f9-ccfb2a290ee0", "49ad0228-e032-4666-8850-38a1f56bb08e", "f3718338-8d51-4ed1-afbf-1c4d4288b0d7", "a0cfd113-5c1b-4a88-88a4-0cfe35e267ef", "7809fb49-ecd4-4151-8796-56948da8da35", "634eaebd-c564-4fb2-86e4-3fd2ee3c9797", "a057f2ec-fd3d-4232-9a4c-6e9cc1efbf74", "3ce0d9d7-2762-4e1a-8392-c3f83c8ec350", "32440711-f759-4f1b-bb0c-ab6fe7feb73f", "525fde1b-aa29-4b7e-83ea-f4d320d339d9", "beef7256-e300-4986-b448-cf9d1ca31dd2", "e8b85381-adb6-46e7-b05b-90179f5acd35", "66e45215-e79e-4a67-bc8b-2242b3236779", "04dcedee-6a25-4d37-bac9-18ac5b0e27c3", "f3b3a4d4-f2a8-44b6-a6d4-93af015ee702", "0d1f7385-c314-4b80-84ee-e3267c675f91", "155a5b0e-d579-4055-9517-58dbfc56a5bb", "ded4819e-4ef9-4736-bd64-7fa62b5b253f", "3cb9d746-a900-4bd0-a68c-8385ef6f8865", "11763e29-7b0c-4871-8f24-4fe5d0eefe2e", "30eb16bd-ea86-4751-bfc0-982fd4368e67", "d70e34f2-f0d3-4b55-bc33-6936021a7071", "e07d5df5-5bb3-4e61-92de-071acc10e170", "3e059260-9d9a-41ec-95c8-c4031c2b24e4", "cc0fe5c8-ba3c-4185-b984-bb6373576732", "1de0d645-1f8e-469b-811b-1c9afc3dbb69", "61f4d134-c4d8-45ce-b8d2-638bae48b9ce", "828ff51a-7f12-4d8e-ac15-5e8c74b4ff19", "6d70b1cb-1f72-47c5-a8cc-f016938078dc", "8706beab-0055-44c0-9a77-08910e8adc56", "35ccc861-0059-4acf-a7a8-ef0a6c9c92e9", "910cac67-793c-4b24-a81e-9aa96c3bb663", "2fc42a5e-71e2-48e7-bb56-15d2cd04600e", "ea32b5e4-cbd7-4a1c-9e71-1acdd79c02c5", "a532e9b5-8c59-4fa3-9f09-bf0011d24a1d", "9ddbe670-4043-47da-aa02-6349f53851fb", "c70c51f2-bbf0-42a4-a9cd-acc9025d1474", "3623d2b6-9c56-455e-aefb-593f55f26e30", "77199c7c-349f-46ff-be92-58092e2ef7a3", "a9da18de-b3b4-43f6-b49e-12399dbf5493", "d972bf5a-6e28-46f9-9c83-bc47753f1ab5", "979503fd-7488-4d64-8817-13fbb161895a", "fdbf51a6-b01c-4d36-a5ac-e9b3761a9ed4", "4262fe4b-d936-4814-bf4d-de9fcf732949", "6279660c-0d22-4b21-bcc3-983340ac5d23", "fdb40385-4472-4484-ad57-29858ef66959", "3243e697-6745-4191-bd0c-444df7098494", "a8ab6cc4-216e-4ab6-a84b-e5e78533ad97", "96f06b1f-cff6-4862-befb-cd100a32f5a6", "b2962b0b-ff6f-43ed-a321-8287babaf40c", "97fa3c9c-f905-4039-bd16-bd3068d3c6ab", "b5e94c4f-fd73-4863-8977-1bf4fe6f4eae", "613b5561-62fb-41a7-96bc-502ff81d1468", "71b1670f-aa9a-421f-978c-3c43fa532100", "43307305-5e91-4c91-9af0-9df87e1a9fdd", "63b16e47-29ae-4093-8259-179f73b7c312", "cebdbc01-d8da-481d-b17d-aee7e42b4d9b", "2c2895b8-7e55-42d2-97c3-699682340e52", "4cb5359e-f761-4f67-a993-e880a9f9d331", "b7a5d215-beb8-43ea-adfa-d972d70c6698", "ba7b1151-d6f3-45d1-9864-79967049b725", "e678b697-79c9-4918-a2bf-1bc308aa74c6", "67fbcdf1-9470-4fff-83d4-bd83801a4c7e", "21b579f3-bbec-4d6e-a56c-de1e735d3964", "9c6ee044-318a-4e1c-8596-a40d8df09394", "04f31385-beeb-49ce-b950-f154c3af6749", "cbec7fb8-bbca-4e24-826e-4227f23e6410", "27fae339-fe59-43dd-a1bd-1f35d3caeaa1", "42a19f85-8cb4-48c2-8e5c-f448143db5cd", "dcf46624-2589-4f4f-a2ac-fdded3287b34", "51394643-2cad-41d5-8560-7ffe119b9a01", "c60f60a6-2f47-4b2f-9869-4f78404377b8", "e113a4a4-3c9f-49a9-8a9b-7d9514ce3758", "44f6b920-46d0-48b7-8926-fa1e3c5370d4", "35d38511-4694-410a-9bbd-fdb7e92f766b", "8363622d-49a1-4e80-8e76-901b73846325", "4068a141-349c-49c0-ae7a-4e7c91970b5e", "9909d7e4-bb59-4f6a-a329-225f699e70cc", "3bc30b87-869d-4ae6-8916-66e917294fc7", "ec29f5f1-2c36-4aff-a31f-edf7630f7b51", "a2102f03-d10a-4d44-ae00-fda7dc4edfeb", "54e5eff1-8ad2-4eda-8be0-7c8ba0e0ad59", "81f7c04a-7200-4495-8658-0be80b3aaaac", "af2459ad-e308-4c5a-ad5f-660a9d34682e", "b07d6d19-618e-4c11-9b18-e9a8c9911d63", "92d4c178-cc23-453d-abaa-97385495533f", "e764e927-e752-4a03-b86f-58634e751ff7", "84dcebc1-2b55-4ce5-80ca-612e9428e47b", "0bba52b5-54a7-4839-abdc-8d3a2f600998", "a8c5f989-1f9d-47cc-9dc3-a8f3f8c4dcd6", "ca62825f-4161-4bb9-a40e-e21735d0965b", "25874d31-a647-4518-b7d7-dfa7835bb3c8", "ee221613-118c-449c-8e60-693cf911487b", "08ab1390-5664-4c72-bb4e-eff0190b29d8", "67336796-0460-4d8d-80b8-ba0a3b52fd60", "e298afc5-aab8-49e8-ba0d-9ac3ff6472f8", "252be990-a8e3-4425-a48d-e92f12f7538a", "8218ce64-45e7-48d7-97ac-9463d7059266", "5401eef0-2bbe-4894-9bca-a6188088b6c1", "054971db-481f-42fd-876b-c393c2c7b897", "67e62451-bac5-423c-a8ad-c5aef43f199e", "d0ef445c-da19-41ac-ada4-0a7805d1f960", "6c87b7a3-ffb8-4e1f-9e6d-b620c2a40632", "8c77ecf5-c14e-4884-8812-cd2155b39201", "42de9c82-463c-4ebf-bbcc-41580abfeef2", "373dba26-600a-4ed4-875f-8bf326292e21", "adc72803-b12f-4b0b-aed0-4394228f8951", "50405a5d-6cc9-426f-a102-3ed604fff919", "bc524ca9-2cad-4760-ba2c-b99fe0406f9f", "ad439c6f-0873-411a-b4a6-c9bc9c6917e3", "7ce58424-61bb-4898-bb9b-7bd506cf4be0", "0e080014-3ecd-40cf-9cbb-d1960ee5cc31", "0eee668e-a6ba-4b39-86b7-3e3d99a50353", "0ef4c38a-4dca-49fa-be11-07db6b12bdd1", "c3734bd2-7746-47b2-a46e-803cfd4a079d", "0a958387-558f-4844-b2db-dab6b4551adc", "e1227ac8-7ad1-40e3-8f9c-068d250de59e", "6f969084-1db0-4ca8-b160-29778c662ad5", "b43632ed-ec41-45ec-985a-43a065cb005c", "56569be7-5fe0-4d83-8fb6-12215d31d229", "16695142-6e3b-40f2-b3e1-d0eba4e50ba1", "d7fa3de7-e1bf-4501-b46b-8b9a892e920d", "2093060e-029d-4fda-ba72-30d184000110", "e9264d9c-2877-460d-bf32-e40dd1c3ee00", "96d32e80-6438-460b-a9c6-5bd08d0ba45a", "e7666f87-c6a0-4619-aa9e-f7817982bb5c", "dfa109d8-42dc-4895-ba13-073baa55b5e7", "cf829cbc-0002-421d-a1fc-9b7b27d6f842", "5db2958a-c8b4-4678-93ee-7734fb878db8", "8e984d72-23c3-4a78-9c08-a196b7d673f3", "092c305b-839f-48d0-94c8-622d9580af9b", "510b9171-c206-40b0-85b7-b9f6022910df", "bf85a60c-9fbf-4e01-8f52-086b9a521948", "fbf2cb4e-998e-4b2e-8205-bd4bf073a697", "83f2e9c3-c196-4bc3-b702-b3860ecd7c2b", "342aab5d-7892-4b81-b850-077ebc8a2a6b", "f59754b6-d749-4251-a90d-996373696a7b", "59999ab1-a9af-4c8c-bca1-7ca826e6d79d", "202864df-a567-47c3-9d1d-aa3c7d251e98", "2189dffd-ac61-4087-aade-14a962618de4", "222d9279-f6fc-49d3-a9b3-b2f7c167c672", "c28a0364-cab9-4c21-95e1-f2723674570d", "088d796f-a556-4721-b0c5-33b4e74c0765", "ccd4e2f8-2b5b-4ed6-9d48-7e01aebce9ec", "ddc08779-eacf-47f9-bb6e-e635439bd951", "8526cdb7-54bb-40d4-9450-77c8f096783f", "7d15597e-f6d6-403c-bdc1-9afb9fd305d2", "a6f2a966-7781-466d-afd0-9a5ba4405863", "bc9b0375-2447-4653-a6d0-22a4af575a13", "167e91f4-3528-4f83-b480-877d996449cd", "633f72b6-a13f-4b79-93c8-95e408f14726", "b724a9ee-da0f-4b78-874b-a2d3ec1b8b3f", "e6fd3c46-e3b6-406c-a1ea-b9e23c1e97fe", "f2a1fe0a-d52b-4982-8d5c-249783e3aaa3", "42536a61-7fec-4ce6-8d17-68f22096d746", "86a5c506-2cf2-4c86-a456-6406eaf045cd", "3061d59a-5cdb-411f-b7c0-02758b27e31a", "8bc8da4d-88db-45f4-ac10-2a1d19a34075", "f1c568b3-641d-43aa-bd1d-f140fadd0032", "c1f5b154-1cb3-40f8-b5a6-5c9947c2dd56", "b8ee043c-5dfb-4cf9-b080-56dc31385179", "f5643665-1982-4f0b-802b-8ca1b05d6964", "92c50d46-b1b2-4017-baa1-ec721536d0ea", "01b92a2a-24d8-404f-b126-7eddc6c6a93d", "9192c182-3451-4d87-83c2-76a71dd483b1", "56f9ab29-1a2b-49d4-89e5-4073ee42b7d8", "c70e0e1e-73e4-4a64-af16-150b8aa13cfc", "3823b812-c038-409f-8e10-6e89752ccb85", "6ce1f887-dfce-4e46-89f0-01cdaba3a4af", "436f8801-c6bb-4343-ab0e-d2d0feddc612", "7b9ae755-5bc8-4e1c-b5dc-fdcc924de302", "173df658-519d-447e-9b4e-fab76b0f50eb", "fe36dd03-859c-4c65-bb1e-30774442eec6", "940653ce-c065-4558-ac0b-08b5c6c85974", "4b321be4-a0d4-4b5c-a13d-a15b99f964f3", "4d9c5d5f-b3f9-43c6-9c35-fc794c435a88", "1b63ba5b-d487-4c00-a9e5-aaf9a0436c44", "1b6491ac-10a1-4a1b-a2e4-6071e53b4337", "92787f47-1f73-4a61-8d9d-000c47ec75a0", "4f9d255d-30d6-4f1f-9694-a993ac9fb1c3", "5f92d030-6ba9-46d2-9756-52f544518590", "6ca2e4da-aecb-43fb-9185-247a5c059b67", "233127e7-1d18-42da-83d2-0f5b3169a373", "fb5e3eba-31b4-41da-96ea-cc4e2ea537db", "fc1447ff-258a-40e2-a1c7-635500249f04", "9f63144e-ec88-411a-a0fb-a886305105f7", "e405a364-12dc-45a2-972d-f4a81135e7f4", "7fc85ab9-e8ac-45a6-8861-35dd6dc25ff5", "81b6366b-4a6d-482b-8da2-dcef2cb4998b", "8fbe5fb7-5d72-458f-a803-318a4d623be7", "560fe639-663c-40c1-ad8f-4bd5cedea4a8", "5be39312-f6a1-45f5-bce9-40f55948454d", "d0e25442-e36c-4a65-a817-7c7ad165a7fb", "c258e92f-9976-47b2-bb00-85a1d4e4c87e", "bf3be2d7-0ffe-4c4e-821a-21ebb08c69d8", "6b6556c8-8c54-48c4-ad26-159e2713f3b3", "be5fc25b-491b-4caa-93fd-1543644d6d88", "20866efb-a8e8-4d1d-898e-96192bd3cb0f", "de64ba66-3be1-4902-a820-51ab63ac5643", "9aeaff09-d364-46dd-a6c9-a350dabf81a1", "087e092c-d370-4dfd-a980-6ab272206c3f", "da8efc37-025e-4b0a-9aa2-794a383b9d07", "72ad0e16-f164-4fa7-b74e-e089b6f92717", "57c667c7-0943-47ad-a4f7-ffde6251281f", "6692aadd-d554-4ee9-aef6-231be019b66c", "84de6c86-6af8-41a6-8181-6dd5916ca4a6", "18d709f6-df82-43db-bc32-711bacb2f7a8", "ca94a2cc-7c2a-4849-8ff1-87eb54daae6e", "692f7dd1-740b-42a7-aebb-42688ec8a792", "418d1b80-a717-4020-be1a-14a37375a174", "e680e814-8244-4e03-84fb-556ed89daa91", "5c9d8608-7408-429f-898b-cbe4de1c8846", "ab63e732-32d1-4e6b-a901-845538228cdc", "4f06b19c-3f90-4eb3-b89b-a1fa8cc7ebe0", "c24bce16-a880-448c-9a25-ea7c4e148edc", "3103ed96-c9cf-4e27-9f0b-b253d5a1dc94", "f0d9448c-3ff0-4712-90a5-5fad151780c4", "eeb60c27-6864-4a27-8bf2-8f2d857ba9ae", "c7afa542-95d0-421b-bd0c-56e3954aad6a", "11d94d92-0455-40a1-99ac-13c774d3355a", "41540f32-0ae6-4666-b963-634be7e46146", "f6dea187-d1ab-40fe-8785-25acdf617b8d", "144e7f35-12a9-446f-93da-e71c4e088046", "8550c8e9-fd10-457b-a1b0-bd30e395d05d", "36ecde01-ba9b-4092-99be-c9577624eacb", "24d7b725-95bb-431f-a966-3641b5ada72e", "339b4c76-d2dd-4929-ae07-ddd75afcf4bd", "ef2b315b-f5e5-4764-9346-44401deaa9e6", "926d456f-2d6d-4932-be8f-22be58c213a9", "d64b4e76-312b-4831-b984-b3408a12cea6", "8a8a46e6-01fd-4ee0-8bab-6cb098725c9d", "d92d143b-ccbf-4462-9a95-3b9973b48b87", "2242af92-bb44-4207-807c-a9027e2c9585", "0ccd42ad-3d3f-4b86-9a3d-787f313b20c2", "bcb6cf75-f2d2-4218-b9f8-71bc9ee53fcc", "732acb59-a2ac-4a12-93bf-922b4ef5270c", "f439b10c-3b1e-43ea-ad96-ed2d44a0c3c8", "778bd68c-daa3-4cf3-8b51-766bac119c05", "3bb5ad0a-fac3-48cd-b0ac-0451ddd824c2", "6132fbc7-d4fa-45a1-958b-9d1c4a7ac645", "df32954a-04ff-46cf-94e9-39fedc4845ad", "ac2c8288-61dd-48d4-9ee2-e1880a4f0724", "1270da3a-094f-4006-b59c-08a4892d32ee", "0054ff19-4620-4fbc-8091-0abff10bcab1", "e10d4641-e92a-494e-ae7b-6f1ec7ad560b", "9d15d05d-6121-40f1-ab35-1f843a840ee0", "d542a4a1-b4f2-4d74-a155-a44eeaee796d", "b648b065-f0df-4a40-b864-022526b37a0c", "41c42bab-5810-41ff-9fbe-8709b36ff151", "a299e07c-d0ff-41bf-83cd-195bf2c73ddd", "66b23811-3342-4c37-b6bc-fc6655ba2ecd", "286d4f42-1413-44f5-91e0-b955d067f53c", "085cda97-eded-4233-aecd-96744be432c4", "e58933d3-afb0-463a-8a67-f0f7cd95ab59", "9beea8fc-0965-4aca-8f16-d0d0fed58602", "d778fa72-34b2-4eea-9e9e-080da81f538e", "18ddd055-d736-471f-8e9f-1fa061893ddf", "4b5f1d69-b790-4686-8a2d-2e5081daf461", "3c7c31fd-7bf5-464e-bf47-42024ac494c7", "eb70804b-2a0f-4d5d-947e-2e284b97a90e", "36a946af-4b99-4ff2-b58d-f61b55d087e4", "be7ee631-fb27-4901-947b-b325fbcb59cd", "d7fa810e-a159-4df5-8cc0-b2e0f3a40cac", "41ad974d-bf03-4445-8cb0-e22fb0095360", "c2549741-0810-455b-8770-30048844b9b2", "0ec52283-91d0-4f75-a040-2e9e507e4c5f", "49935200-0531-4650-aa00-97cf76483a78", "d21e7529-693e-484e-8246-2611c2e54a50", "89ed93e3-813e-4abb-9c87-c749b2e4a427", "40433071-83e9-4793-a71a-9185fde18a16", "668ae3d0-60a9-4bd8-aca5-1c07db435bba", "e14ae856-39fc-47b4-95df-90f9b12ec9e1", "f19f2877-7b3c-4649-8670-80a7125c9f13", "9c70af8e-8005-420e-86e3-b5b1a05056ff", "32b52772-c87d-44b7-b26b-bd304a448f62", "c7443d33-d878-4b74-8a32-920171f26844", "2c37c76a-9ec5-4ce0-843e-fddd965e5ca7", "016e716e-d121-422f-8d45-48233f6b8769", "8cdca243-2939-4fcd-8b27-9f82fd1ea045", "0b656cb2-4d3d-4a95-a705-e6e29bda12d0", "bc4ca96c-758b-4816-830e-c30ed5de9340", "47532ce1-e3d7-444d-9685-9e5a8b7d3f83", "eb36cdcb-67b4-42a3-b8d0-51145d5438ef", "4e19a358-74fd-4fc5-9c6d-269a181be261", "f60e269e-b019-4b20-8208-9b0505915eb4", "b67a7c17-88cc-437f-aebb-2d98cabbc956", "821d00ce-3ffb-4a6b-b5e4-d4328e55ab9d", "a025ee01-765a-4fe7-b987-70773f892c75", "80b64f2e-cc2c-485c-a303-99c05e29be66", "34f167fc-3499-4134-acba-1988337f4014", "8948b952-3e7c-4e3c-990b-821406c6ba8d", "f5e04ee3-8481-4d7b-9b84-4cd8a4615601", "003ce0ec-b725-45ec-969c-7dc9ac2945dc", "a56689fe-cb60-48f5-9974-2b31636bfb4e", "0133695e-aa59-4eae-b537-737685d8e209", "6387dec4-f4ab-4dda-86a5-23ebe90b7283", "61599069-a903-44ea-a6ea-42cdfbe2a107", "8d6e6d5b-cc78-4dcf-ba37-6427ebcaa824", "4009c188-a9f7-4a4c-a539-88c403736979", "4d98686a-7ef4-4ae6-9679-a7b953702686", "bd65e785-b470-4072-a8d9-190ef2b55db4", "3ba13b95-dee9-42f1-b93e-668a642afad5", "79052100-532a-4b26-9577-17897bf09126", "d7c22f2e-5c90-463d-9074-d050017b3afa", "cd5e0a38-7c94-4362-9fcd-a49b6ef3be69", "ad40ef08-fe7f-440f-ad47-6a9e7999266e", "9bd9e65a-9730-42a5-81ce-f0f08ba0d537", "31097176-a6bb-48e9-b7c4-080c23e41a19", "d0967524-b167-4853-895c-f7ff2187318f", "f405114b-0c09-41b4-a745-c4caeb18244e", "c6209543-41b5-4916-924e-4bef4e71bb49", "6e831f2d-ccd0-4d5c-a6df-7d6606a8b5ac", "8af56677-6a79-412d-9a9c-98456dbf9933", "057900af-1e3c-4afe-b627-4ac8660d9ddb", "7ad35477-1f37-4b3b-8220-c27b99cdf6ed", "3e7feb7b-06a7-47c9-aa1f-d8f8e62aa6b6", "86bc81b4-9486-4f9f-92da-607f8b0a168d", "59275517-0fdc-4ef0-8bf2-22def175c743", "8b85a21f-58c7-4e0f-8bcd-9fc4dfcf4aed", "10c1a307-f21a-40c1-a459-65f1d06d9c41", "2eb93384-2b05-4da1-b53b-4e73d02573d0", "83806ec3-73c2-4e87-aacc-517c3ab16877", "d5008c32-f6b9-49cd-96b3-9c2d7cf4aab2", "8fbc366c-bc39-4f97-b859-33a79e7fd685", "a411b52b-bb58-4382-870e-217bcb5b81fa", "0ddea6a0-05e2-4e12-afd3-85e6ce38e757", "4397cb9a-e019-4716-a1d0-428e8e4e65c8", "0d7e4190-fbbe-49cf-b68b-0bef30ca18e6", "10e30a37-a5d2-4d63-9bed-5b23c4c2b229", "61d4ac09-1616-4ef6-9da4-bc667b80fc36", "c6dcb669-6062-4697-b33c-a6dc178c6209", "5b90fe03-22d6-4391-abba-e5b2ba3160c2", "0ee1a5e4-982a-4375-a2cf-a37e7f76522a", "77c0091a-2c76-41f0-86f9-52936a868e64", "205c0f5c-4b3c-4c07-87bb-67b32a5395f4", "74e8ad44-9342-4678-bc38-f414260e273f", "b1b7f387-444d-4da5-bf75-b81db50a6899", "d207d505-8b33-4e1a-a4c8-e5eff83267a3", "7d60c778-b27b-48f5-aa33-542d52f91a53", "ada38f8e-2e9a-472a-ba94-d5ed986e9a91", "46428e41-91c4-4931-bd20-898cf1a558bf", "d99e1ddb-7207-4abe-b602-8915661659c4", "7e3a7263-28f4-4c21-9c51-651f8232d09b", "fca0d17e-7caf-4884-ac2f-26f79e5968f1", "7c3ed4ce-6902-4813-bc31-154fedb8b376", "378fdc45-0a08-4097-b1a4-4fd1e6fab40a", "a7385932-f9f8-4246-ad2e-00e0d61daa3d", "37c6f2cb-2d49-42fa-b405-f66a5eb41b4c", "d4c75c62-5f3a-487b-a71a-b750c850a13c", "abfc6c53-f39f-4fdb-97cf-9b3f9b04e4d6", "8fe18b2f-456f-4631-aa68-2f1e23205720", "d1ebddad-ddda-4fc3-8cc0-11b8e67229c1", "868fe20c-5c21-4961-940a-94d6a66684ad", "1f63d707-276c-4af6-a184-21f04b083759", "b7a06f9e-19e5-486a-b8cc-d20ffc6c7fab", "5a1b7b22-b773-4b0d-9077-9a09c567e1f1", "94088853-bfbe-4607-942e-bf3e30f4a65a", "0f42971d-cb97-4a6b-a41a-dedff4405a2c", "0ac6a687-10e9-424b-bbc8-320416230ee0", "86527023-a577-4b37-857b-2b01c4341e91", "54312aa7-044a-45c9-9bef-7f9448d4c8f8", "5f0686fe-7120-4088-9600-1b848170ced6", "41a84c3c-194e-4521-8cc3-4dff3a796248", "20df0bce-3140-4cd5-9034-e5782dc668e5", "37c3e884-8e26-4a06-a55a-c6d552852c60", "d5b7b230-699e-45ca-ade8-54ef50c52135", "657e15f9-32ae-4dcf-9af6-f18dc5e6290f", "135007c4-1491-4d85-b67b-aad08d78a014", "45be72a1-9844-4a61-83c7-b8f62b3b7fce", "4496f13d-01c2-424f-ada4-2402684b397c", "5f3c9b8e-d4ec-40d7-a96a-ae88e8fba960", "7dd014dd-2c69-46b4-8de1-edb7ea78758c", "bbc42688-7a29-4884-9335-5916d9b8809d", "8260d82b-7803-4b19-b09e-991bf6eb32b4", "bc4880ab-e6d7-48e4-8815-5d1517ffd9e6", "5758d178-bfae-4561-94a3-01142a9ac845", "934d37e6-d4df-4a02-91e0-e563e477b146", "81ab4f59-1ea0-42df-ba57-edfbce96af8c", "e056924c-4bad-48d7-993e-71c8abaad9f7", "3de7c9ba-d537-4ae8-bfaa-8c36c823645d", "543cc845-65c0-4f36-976f-8874379558f5", "d90418e2-eb02-495c-9831-ce5fb5345745", "5ef1c983-f163-4f76-b56d-102b4cd2acbc", "0b30b3ae-f213-42b3-b748-faa04ab06321", "3a72d28d-202c-4423-9e52-805161ab2254", "65f8b72e-041e-4a38-aabe-46781ddf6433", "5b50cd93-a97e-4f11-9666-d949a199c344", "99ef7dfc-d0a6-474f-8734-a6fada38b9eb", "c3619c96-f3a0-4b4f-ba03-1c778d4fc32f", "dc8b0b8f-094f-4b46-a119-a208e768161d", "fc9254bd-5a22-449a-9b26-14d19ad0eb34", "23894e40-7abd-40ad-9130-26f1a4da2733", "43cf5c8c-54b6-493b-8110-fbe582fb0bbe", "eceeb8d3-1590-4457-8134-e3fa44120cf4", "0971720b-a10f-4309-9d43-4b5f71952244", "1437fbb7-9acb-4554-84bd-cc80d45c722c"], "metadata": {"window": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay.  Good morning.  Welcome to CS229, the machine \nlearning class.  So what I wanna do today is ju st spend a little time going over the logistics \nof the class, and then we'll start to  talk a bit about machine learning.  \n By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. ", "original_text": "MachineLearning-Lecture01  \nInstructor (Andrew Ng):  Okay. "}}}}